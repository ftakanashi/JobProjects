#就活笔记 #Linux

> 操作系统篇从最基础的操作系统视角记录了一些知识。这里Linux篇则是在Linux这个具体的操作系统中，记录一些具体化的东西。

# 泛Linux

## Linux发行版区别

常见的Linux发行版有Ubuntu，Debian，CentOS，RedHat，openSUSE，Fedora等。
所有发行版本的内核都是共同的，这是所有这些系统都能被称为Linux的原因。
另一方面，除了内核之外，各个发行版本对预装软件，以及一些比较靠近底层的组件的选择不同，导致了不同的发行版本。

发行版本之间名字很多，但是彼此间也还有千丝万缕的联系。比如：

- Debian系

  Debian是一个比较基础的版本，在此基础上有Ubuntu和Linux Mint等。
  即，Debian衍生出了Ubuntu和Linux Mint。
  Debian系是个人计算机Linux的代表。有较为成熟的GUI系统。

- RedHat系

  RedHat是一个尝试在Linux开源内核基础上进行一些闭源软件开发，并以此卖钱的系统。
  每次系统升级前，会推出一个相应版本的Fedora系统，让红帽社区去体验和验证一些崭新的不成熟的技术。
  而另一方面，将RedHat中一些和商业有关的元素如商标、闭源软件等去除后，得到的一个“免费版红帽”就是CentOS。
  RedHat衍生出了Fedora和CentOS。

不同发行版本的最主要区别在于下面几个方面：

- GUI以及桌面服务器不同（当然对于当成服务器来使用的Linux，通常不需要有GUI界面
- ==软件包管理器不同==（新装系统后第一件事就是要用包管理器装很多软件，这个不同。比如Debian系常用dpkg工具，Ubuntu使用的是改进版的dpkg，名为apt。CentOS则是使用RPM包管理器，使用yum命令。

### CentOS 6与7比较

生产环境服务器，一般都是用CentOS的。而细节上，使用最多的两个大版本就是6和7了。现在从各个维度对比一下这两个系统：

| 对比项               | CentOS 6   | CentOS 7                 |
| -------------------- | ---------- | ------------------------ |
| ==默认内核版本==     | Kernel 2.6 | Kernel 3.10              |
| 系统启动进程         | /etc/init  | /usr/lib/systemd/systemd |
| 系统启动方式         | 串行       | 并行                     |
| ==服务开关工具==     | service    | systemctl start/stop     |
| 服务自启动工具       | chkconfig  | systemctl enable/disable |
| 默认文件系统         | ext4       | xfs                      |
| ==防火墙==           | iptables   | firewalld                |
| 普通用户起始ID       | 501        | 1001                     |
| 自带的默认数据库类型 | MySQL      | MariaDB                  |

# 内存

## Buffer和Cache的区别

在Linux上运行`free -mh`可以看到各种内存分区的占用情况。其中有一个Buffer/Cache，乍一看都叫缓存，但是具体是什么样的呢？

Cache全称Page Cache。他可以说就是一般意义上认为的内存中存在的磁盘缓存。即读写文件时为了避免频繁的磁盘IO，先将要读写的内容加载到Cache中，然后再进行统一的读写，尽量一次IO就搞定。
当下Linux的Cache通常动不动就几个G。Linux的内核设计逻辑就是，尽量使用内存，所以Cache会被用的比较多，只要文件被请求过，那么其内容就会暂时性永久保存在Cache中，即使请求了这个文件的进程本身都已经退出了。
当然，Cache并不是系统运行必须的东西，因此当内存空间吃紧的时候，系统会自动将Cache中的一些内容换回磁盘上去，从而腾出空间来分配给其他进程。

==如果说Cache是文件内容的缓存区，那么Buffer就是那些cache中文件的meta信息的缓存区，比如存放路径、权限等。因为其存放的信息不太多，所以Buffer的空间一般都是几十M左右。==
在2.4版本的Linux内核以后，Buffer和Cache就被统一起来管理了。

## Swap分区

Swap分区是在安装系统时，安装人员在磁盘上划出的一块空间。通常来说，swap的分区作用是这样的：
当物理内存不够用了，而进程又需要更多内存时，系统将内存中一部分不再使用的内存页换出到swap磁盘分区上，腾出空间给进程使用。

### Swap分区与虚拟内存的联系与区别

如之前在什么地方说过的一样，虚拟内存有两种含义。

==虚拟内存的含义一，指一套技术机制，让计算机可以享用比实际物理内存更大的内存空间。这套机制在Linux上的实体组成部分，包括内存本身和磁盘上的Swap分区。同时这套机制还包括了请求式分页存储管理方式作为“软件”。
从这个意义上来说，Swap分区是组成了虚拟内存机制的一部分。==
另外除了分页内存管理中页面的调入调出（术语称Paging），Linux中的Swapping（即整个进程的调入调出）也使用到swap分区。

==虚拟内存的含义二，特指windows上的虚拟内存文件。==这个文件，功能和Linux的swap分区相同，即用来临时存放从内存调出的页。只不过在Windows上，虚拟内存文件不是一个独立的分区，而是放在C盘特定位置的一个文件。
从这个意义上来说，Swap和虚拟内存是本质上相同的两个东西。

另外网上很多人说Windows的虚拟内存和Linux的Swap分区另一点不同是虚拟内存文件在真内存还有空闲时也会被使用，但Swap只有物理内存被用完了才会被使用。
这个说法是不正确的。现在Linux内核，都通过`/proc/sys/vm/swappiness`参数进行Swap分区的使用时机设置。这个参数是一个0-100的整数。表示物理内存空余还剩下多少时开始启用Swap空间进行调页。只有当设置为0时才会有，物理内存用完了才开始Swap换页的情况。

# 文件系统

> 更多文件系统知识，见操作系统篇

## 软硬链接的区别

Linux中所有文件都由inode和block组成。
inode保存一些meta信息而block保存实际的文件信息。

创建硬链接，是指新建一个inode指向对应文件的block。因此删除原文件（本质上是删除原文件的inode）并不会影响硬链接对文件的访问。
因为相关block的引用计数也未归零所以系统不会删除block。
==硬链接不能跨越文件系统（因为你想不同文件系统的inode和block不一定兼容==

另一方面，==软链接本身就是一个独立的文件，只不过其文件内容是一个指向对应文件的绝对路径==。
所以，不要说删除原文件，就算是原文件改个名或者改个路径，软链接就找不到文件了。
因为这是表层的路径映射，软链接可以跨文件系统建立。
Windows中的快捷方式等同于软链接。

## 句柄数上限

有时会碰到`too many open files`异常，这是因为Linux对某个进程可以打开的句柄数有限制。这个限制可以通过`ulimit -a`查看。
通常默认值是1024。

临时的解决方法，可以通过类似`ulimit -n 2048`的办法来提升当前shell开启进程的最大句柄数。注意非root用户最高只能设置成4096。
更加根本的解决方法，修改`/etc/security/limits.conf`中内容，在最后加上

```
soft nofile 4096
hard nofile 4096
```

即可。
甚至还可以在这两行前面加上某个用户名，表示限制某个用户开启进程的最大句柄数。

# 进程系统

## Linux进程状态

> https://www.pianshen.com/article/36511724664/

Linux中，进程主要有如下几种状态：

| 状态                                 | 表示 | 解释                                                         |
| ------------------------------------ | ---- | ------------------------------------------------------------ |
| 运行（TASK_RUNNING）                 | R    | 表示正在执行或者处于就绪态可执行的进程状态                   |
| 可中断睡眠（TASK_INTERRUPTABLE）     | S    | 进程处于挂起的状态，可以响应信号                             |
| 不可中断睡眠（TASK_UNINTERRUPTABLE） | D    | 进程处于阻塞等待的状态，不能响应信号。比如不能通过kill -9杀死一个处于D状态的进程。 |
| 暂停（TASK_STOPED）                  | T    | 进程处于暂停状态。发送SIGSTOP信号给进程可以使进程进入该状态。对该状态的进程发送SIGCONT信号可以使其继续运行。 |
| 僵尸（ZOMBIE）                       | Z    | 子进程退出后，父进程仍在运行且没有得知子进程已经退出从而未能回收相关资源。此时子进程无法完全结束，进入僵尸状态。 |

下面是针对Linux进程状态的一些总结点：

- ==传统意义上进程的运行态和就绪态对应Linux中的R状态==
- ==传统意义上进程的阻塞态对应Linux中的S和D状态。S和D的区别在于是否能相应外界给予的信号。S状态通常是由程序调用sleep等情况进入，属于阻塞中的睡眠/挂起状态；D状态通常是由系统调用访问硬件进入，是狭义上的阻塞状态==。
- D状态无法响应信号，目的是为了保护进程整体可以完整执行不被打断。从这方面来说，调用硬件比如读取硬盘中的内容等阻塞时，进程通常进入的是D状态。
- 系统中绝大多数进程都是S状态的。否则CPU撑不住。D状态的进程则很快就会结束状态，通常top很难捕捉到。
- 僵尸进程过多本身不会给CPU带来很大负担，但是僵尸进程的PCB，地址空间要维护，内存方面会有较大浪费（内存泄漏的原因之一）。

通过`ps aux`命令可以查看到更加细致一点的进程状态信息。这通过各种进程状态修饰符表现。修饰符主要有下面这些：

| 修饰符 | 含义                                                         |
| ------ | ------------------------------------------------------------ |
| <      | 高优先级                                                     |
| N      | 低优先级                                                     |
| s      | 是个Session Leader角色的进程，通常可以理解为，这个进程通过fork开启了一些子进程 |
| l      | 多线程进程                                                   |
| +      | 位于前台进程组                                               |

比如`ps aux`中某个进程的状态显示为`Ssl`，表明这个进程目前处于可中断睡眠状态，并且这个进程开启了几个子进程作为worker，再并且，这个进程是多线程的。

## fork函数

在Linux的C程序中，调用fork函数，记住其特点是==“调用一次，返回两次。一次返回子进程的pid给父进程，一次返回0给新建出来的子进程。”==。
因为子进程的内存是严格复制父进程的，因此父进程运行到fork为止的所有中间变量，子进程也直接继承，并接着运行。

比如下面这段程序：

```c
void main(){
    int i;
    for(i=0;i<3;i++){
        pid_t fpid = fork();
        if(fpid == 0){
            printf('son.');
        }
        else{
            printf('father.');
        }
    }
}
```

上述程序如何运行？第一层进程第一次运行到fork时，i显然是0，于是fork出一个i是0的子进程。此后两进程分别都从`if(fpid == 0)`开始继续运行。下面是这个进程树的图：

```text
           0
    0      1      2
  1   2    2
2
```

每个数字表示一个进程开始运行时其i的值是多少。这个值是`n`的话，就表明这个进程还剩下`3-n`轮循环，即会输出`3-n`行字符串。

所以，上述程序总共会生成`3 + (3+2+1) + (2+1+1) + 1 = 14`行。

## 停止进程

停止进程通常如下几种方式：键盘输入Ctrl + C，使用kill命令等。无论哪种方式，本质都是向进程发送信号，引导进程结束。但是不同方法发送的具体信号不同，进程响应方式也不同。

Ctrl+C其实是向进程发送了`SIGINT`信号；`kill`默认参数`-15`，发送`SIGTERM`信号；`kill -9`则发送`SIGKILL`信号。

`SIGINT`和`SIGTERM`相对而言是比较温和的结束方式。进程收到这两个信号时都可以将其捕获并进行相关处理如归还资源等。如果处理中没有明确写要终止进程，那么进程可能就不会终止。
**==两者不同指出在于，`SIGINT`信号不仅发送给进程也发送给进程的所有后辈进程，因此一杀就是一整个进程树。
而`SIGTERM`只发送给目标进程本身，因此如果进程终止，其子进程等会变成孤儿进程被init收养==**。

==`SIGKILL`则是比较粗暴的办法。因为`SIGKILL`无法被进程捕捉==，因此就谈不上什么处理，直接进程终止就完事了。

再次列出比较如下表

| 信号    | 发送方式   | 发送范围           | 可否被捕捉 |
| ------- | ---------- | ------------------ | ---------- |
| SIGINT  | Ctrl + C   | 包括子进程的进程树 | 可         |
| SIGTERM | kill (-15) | 单个进程           | 可         |
| SIGKILL | kill -9    | 单个进程           | 否         |

## 进程优先级

进程优先级的必要性显而易见。因为资源有限，就需要让重要的进程尽可能多地久地占据CPU进行计算。
Linux中进程优先级主要涉及两个概念，PR（Priority值）和NI（Nice值）。这两个也分别是top命令输出中的两个字段。

术语上来说，PR值和NI值分别称为动态优先级和静态优先级。
PR值是真正意义上的优先级值，而NI值是可通过人手指定的一个修正值。虽然NI值不是优先级本身，但是可以影响优先级。

### 实时进程与非实时进程

Linux内核中，为进程准备了0-139这140个具体的进程优先级。数字越小，优先级越高。
这140个优先级数字又被分成三个范围：0，1-99，100-139。
抛开0不管，其实1-99与100-139分别对应了Linux中两类进程，称为实时进程和非实时进程。

实时进程的优先度只能在1-99中选择，非实时则在100-139中选择。显然实时进程总是先于非实时进程进行运行。

那么Linux为什么要这么分类呢？
因为有些时候进程需要紧赶慢赶地赶快执行完。此时一来内核应该尽快运行该进程，二来调度进程时也应该尽量用简单快捷的办法，否则在调度上花时间得不偿失。
于是，Linux规定一些进程为实时进程，其优先级高，同时对多个实时进程的调度策略是最简单的FIFO或者时间片轮转。
另一些不那么要紧的进程，就是非实时进程，目前非实时进程通常用CFS（完全公平调度，注意区别进程调度算法中的FCFS）策略进行调度。

==CFS简单来说，就是根据优先级高低按比例分配CPU的时间片数量。通常优先级差一级，占用时间差10%左右。
这部分决策通过CFS的vruntime机制实现==。vruntime，即虚拟运行时间，举个简单的例子来说，比如优先级为139的进程实际占用CPU1秒，那么在vruntime中就记录其占用CPU1秒；而若优先级100的进程实际占用CPU10秒，vruntime中也记录其占用了1秒。
检查vruntime你会发现，两个进程分配得挺公平。但是实际上这是“依据优先级的公平”，虽然这种策略被称为完全公平…

### 进程优先级变化

通常，在不带任何修饰的情况下，创建一个进程后，进程的优先级是非实时进程优先级范围的中间值，即120。
此时进程是非实时进程，接受CFS策略调度。

当某时内核认为其有必要提升优先级到实时进程范围，就修改其优先级到0-99。
进程进入实时进程状态，从而接受FIFO或者轮转片策略的调度。

### 相关命令

上面说过NI值是人手设置的，可以影响优先级的值。
NI取值范围是-20到19。一个进程建立时默认优先级120，这其实也是值NI值为0的默认状态。

> 参考文章中对NI值的解释很直观。NI值衡量了进程的“性格”nice不nice。值越大，越nice的进程，就越不去抢CPU。相反值小的那些不够nice，很令人讨厌的进程，就去抢CPU :)

==通过比如`nice -n -10 xxx`启动进程，就可以为进程手动设置NI为-10。这么一来进程一开始的优先级就变成了110。
对于正在运行中的进程，可以通过如`renice -n 10 -p <pid>`的办法来改变NI值==。
不过，无论怎么改，NI值最多只会在100-139的非实时进程间移动。因为非实时进程变成实时进程的过程是由内核控制，而不能由你人手控制。

和`nice`启动进程类似的，还有一个命令叫`chrt`，这个命令则是可以直接指定实时进程优先级来启动进程，如
`chrt 10 bash`，此时启动的bash进程就直接是优先度10。
此外`chrt -f`还可以指定该进程用FIFO而不是默认的轮转片策略调度。

## 进线程数量上限

一个简单的问题：一个Linux系统中最多可以开多少进程？多少线程？

因为一个进程必须要有PID，而通常PID大概都是在0-3w多的样子，所以大概可以猜出来，Linux上开的进程最大数量应该是65535。这也确实是Linux默认情况下的最大进程数。这个值也可以通过`ulimit`来查看。
当然，实际服务器上不可能真的能开那么多进程。毕竟每个进程都需要有对应的内存空间等资源消耗。

线程方面，其实之前在哪里也说过。一个进程内可以并发最大数量线程，主要是考虑内存方面的限制。
通常一个线程需要有一片独立的栈空间，这个空间一般有一个系统默认值，比如Linux中可能是1M-8M不等。可用`ulimit -s`查看，单位是KB。
而线程的栈，都是要用进程用户空间中的匀出来的。所以像Linux32位系统有3G用户空间的话，若栈空间默认8M，则理论上最大也只能并发出384个线程。

# CPU

## 关于CPU负载

我们都知道，`top`或者`uptime`之类的命令可以返回CPU负载信息。CPU负载信息分成三个数字，分别是过去1分钟、5分钟、15分钟的平均负载。我们也知道，这些数字越小越好，而越大则机器越卡。

那么CPU负载到底是什么，详细来说一说。
首先应该明确，上面提到的三个数字，严格来说应该叫做CPU的平均负载。而CPU负载的定义，是在某一时刻，机器中正在被CPU执行以及（包括阻塞态的）等待被CPU执行的进程（实质上是线程，这里假设所有进程都是单线程的）个数，即，==某一时刻就绪队列的长度 + 阻塞队列的长度 + 1（+1是因为有一个进程正在被CPU运行）==。

由于知道一个瞬间的CPU负载意义并不大，所以我可以在1分钟内连续采样，比如每隔一秒采样一次，可得到60个数据，这60个数据的平均值，就是CPU最近一分钟的平均负载，即`top`等命令输出的三个值中的第一个。其余两个也类似。

于是就有了一个结论：单CPU系统中，CPU一段时间内平均负载为1.0时，说明这段时间内CPU一直处于忙碌状态且没有其他进程在等待被执行。相对的，若小于1.0，则说明CPU这段时间内有空闲状态；若大于1.0，则说明这段时间内有进程因为CPU忙不过来而被迫在就绪队列中等待了一段时间。

上述限定条件是单CPU系统，因为CPU平均负载计算只平均时间方向，不平均多核。换言之，如果你是四核系统，则这个“恰好满载”的基准值将是4.0。所以判断平均负载时，通常按核数来看。对于n核系统，只要平均负载没超过n，就还算正常。
至于`top`给出的三个值最好看哪个就见仁见智了。一般来说，短时间内负载高，但后续会平缓的话问题不大，从这个角度来看，可能更加适合看5或15分钟的指标。

### 平均负载与使用率

这两个都是CPU的重要指标。
首先两者的统计对象完全不同，平均负载如上面所说，统计的是单位时间内 运行态 + 就绪态 + 阻塞态所有进程的数量的平均值。
而使用率统计的是特定CPU在单位时间内处于运行状态的时间占比。

==对于CPU密集型任务，即大多进程都在就绪队列中，等待内核调度占用CPU进行计算时，此时显然CPU使用率会很高，因为其一直处于运行状态。
对于IO密集型比如磁盘IO密集任务，其实大多数进程都在阻塞队列中。此时平均负载仍然很高，但是CPU使用率却不怎么高==。

### 平均负载的问题排查

若负载和使用率都很高，则说明当前有较多CPU密集型任务在运行，且超出了CPU承受的极限，一般就需要优化代码或者加机器了。

若负载很高但是使用率比较低，则说明当前有较多IO密集型任务。此时应该取尝试定位哪些任务占用了大量IO资源。Linux中将这类等待IO的进程状态归类为“不可中断睡眠状态”，状态字是`D`，去ps或者top的结果中找D即可。

若负载很低但使用率很高，这则是说明系统中要执行的进程数目并不多，但是每个进程都在运行CPU密集的代码。这种情况比较少见，但是仍然可以适用第一种情况的解决办法，优化代码或者加强CPU性能。

## top中各种CPU使用率含义

我们知道CPU是按照时间片分给进程使用的。因此CPU使用率也可以说是其过去一段时间有多少时间片分给任务进行计算的占比。换句话说，就是过去一段时间CPU运行时间占比。

根据分配给的任务性质不同（这个任务是广义的，比如可以指用户态or系统态进程、也可以指等待IO、软中断硬中断等等）

- User Time & System Time

  ```
  顾名思义，就是CPU在用户态和内核态两种状态下各自时间比
  ```

- Nice Time

  ```
  指CPU用来给被通过nice手动调整过优先级的进程的时间比。上面的User Time其实不包括niced process，只包括unniced process
  ```

- Idle Time

  ```
  指CPU空闲时间比，通常Idle + User + System = 100%
  ```

- Waiting Time

  ```
  指等待磁盘IO读写的CPU时间比
  ```

- Soft/Hard IRQ Time

  ```
  指软/硬中断时间比。软硬中断的区别在于中断请求由软件还是硬件发出。
  这个时间表示CPU用于中断处理程序运行的时间比。
  ```

- Stolen Time

  ```
  只在虚拟机中有用。man top的原话是
  time stolen from this vm by the hypervisor
  ```
  
  ### CPU使用率超过100%
  
  CPU使用率的定义是一段时间范围内一个CPU处于各种状态的时间占比。从这个角度看，某个CPU的任何一个使用率都不可能超过100%。
  
  但是别忘了，更多时候，CPU使用率并不是从CPU视角来统计的，而是从进程的视角统计。即一个进程在一段时间内占据了多少CPU的时间片。由于进程可以分出多个线程，所以可能会出现某个进程的CPU使用率超过100%的情况。
  
  此时的实际含义是指，该进程分出的多个线程，占用的CPU总时间片大于统计的时间片段长度，因此超过100%。

# 命令 & Shell

> 更多实用命令可以查看面经资料目录下的Linux Cheet Sheet.pdf

## 命令行输入命令，系统会发生什么？

比较完整地考虑，
==首先应该要判断你输入的是不是一个路径。如果是一个路径，那么直接执行即可。==

如果不是路径，此时说明你输入的应该是一个命令，一般来说要去PATH里面找相应的二进制文件执行。
但是==Linux中其实自带一个保存了"命令 - 实际路径"的缓存。==

这个缓存可以通过`hash -l`来查看，也可以用其它参数来增删查改。如果某个命令存在于这个缓存中，那么就直接拿缓存中保存了的那个路径来用即可。
如果没有，才会去搜索PATH，找命令的二进制文件。注意找到了之后还要将这个对应关系保存到缓存中。

## 文本处理命令三剑客 grep / sed / awk
三剑客指文本流处理中的grep,sed,awk三个命令。==grep擅长查找内容，sed擅长取行以及替换，awk擅长取列以及格式化输出==。

### grep
grep的使用方法通常接在一个pipeline的后面。
另一方面，其实其官方的使用方法应该是`grep pattern file`。

常用的grep参数包括
```text
-i      忽略大小写
-v      不匹配
-o      只显示匹配到的部分而不显示整行
-E      使用扩展正则表达式
-A      (After) 输出匹配以及后X行，是这个option的参数值
-B      (Before) 同上，输出的是匹配行及其前X行
-C      (Context) 同上，输出的是匹配行及其前后各X行
以上参数都是修饰pattern的，即 grep [参数] pattern file

-r      递归搜索指定目录中所有文件内容，比如 grep 123 -r ./ 就会搜当前目录及其递归子目录下所有文件中所有带有123的行
以上参数是修饰file的，即 grep pattern [参数] file
```

### sed
sed后面跟的参数比较复杂，需要分成几个层面来看。
首先，sed本身可以带几个参数，因此形成了模式`sed [-nefr] '[编辑动作]'`。各个参数的含义是：

```text
-n      使用安静模式。默认非安静模式下所有内容都会被输出
-i      在文件中原地编辑 in-place
-i.bak  in-place编辑的同时备份源文件
-f      指定一个sed的"脚本文件"，里面每一行都是一个编辑动作。-f指定脚本后会按照顺序依次执行动作
-r      让后续动作中支持扩展正则表达式
```

接着，看编辑动作的格式。注意编辑动作要用单引号引起来。编辑动作大概可以分成两部分，`[addr][option]`。
其中addr是寻址表达式，意思是给出一些条件如行号或者正则式匹配，通过这些条件从而定位若干行。
option则是动作表达式。表示对寻址表达式匹配到的行进行相应操作。

注意两者并不总是连在一起，根据不同情况可能会有不同。总之记住编辑动作的两个要素，定位和操作。

寻址可以是单寻址（定位一行）或者多寻址（定位多行）。
单寻址的例子：
```text
42      第42行
$       最后一行
/pat/   能够匹配到pat这个正则式的**第一行**
```
多寻址的例子
```text
42,45   第42到第45行，总共是42,43,44,45四行
42,+4   第42行开始的四行，等效于上面的
x~y     步进，如1~2是所有奇数行，2~2是所有偶数行
```

接着是操作，主要有以下几种
```text
d       删除寻址找到的行（后面称这些行为指定行）
p       打印指定行，因为打印追加在stdout最后，所以通常和-n参数配合使用
aTEXT   在指定行下面append新的一行文本TEXT，TEXT中可以带有转义字符如\n以实现多行插入，下同
iTEXT   在指定行上面prepend新的一行文本TEXT
cTEXT   替换指定行为文本TEXT。注意这个操作如果针对连续行，则将连续行替换成一个而非多个
w/path  将指定行写入到新文件/path
=       在指定行上面prepend一行行号。配合-n参数可以打印指定行的行号。
!       取反指定行，需要接在其他操作指令的前面比如 !p 或者 !=。
s/a/b/g 替换操作
        关于这个替换操作，首先，s前可以加寻址式以进一步限定范围，比如1,5s/a/b/g
        其次，g是最常用的全局替换标识。除此之外还可以是p 只打印替换后的行，w/path 将替换后的行保存到新文件等。
        不写任何标识符则是替换每行的第一个匹配项。
```

>更多sed的使用例：https://blog.csdn.net/vanvan_/article/details/91397655


### awk
awk的基本工作格式是`awk '条件类型1{动作1} 条件类型2{动作2} ...' FILE`。

##### 动作格式字符串
先来看动作。动作是一串格式化字符串，其中带有一些动态含义的变量或者关键字。
因为awk是主要用于每一行的列字段处理，所以最常见的动作比如`print $1 "\t" $3`这种。

除了`$0`表示整行以及`$n`表示第n个字段的值以外，动作格式字符串中还可以有如下变量：
```text
NF      每一行($0)拥有的字段总数（Number of Fields）
NR      目前awk处理的是第几行数据，即行号（Number of Row）
FS      分隔符，默认是空白        
```

注意动作格式字符串中，那些写死的字符串用双引号引用出来，并且字符串之间不需要额外的符号，默认是连接在一起的。如：
```text
awk '{print $1 "\t lines:" NR "\t columns:" NF}'
```

注意上述变量除了读之外，其实还可以写。比如某行不使用默认空白作为分隔符时，需要手动指定分隔符，就可以操作如下：
```text
awk '{FS=":"} {print $1}'
```
注意以上做法还有点小问题，第一行数据无法正确输出字段而是输出整行。
这是因为awk命令的机理，是先读取一行数据，然后进行awk后面定义的操作的。在读取第一行的时候，FS还未被定义成冒号而是用了默认的空白，因此无法正确输出。

解决办法是使用BEGIN关键字如下：
```text
awk 'BEGIN {FS=":"} {print $1}'
```
跟在BEGIN关键字后面的动作将会在读取第一行开始前就执行，因此第一行也可以用我们定义的冒号进行分割了。

#### 条件类型
awk的条件，指的并不是像sed那样的寻址条件。
因为awk关注的是每一列的字段，因此其条件也是基于字段的值进行判断的条件。

具体来说，对于字段是数字的情况，其实条件是一些自然的逻辑运算，包括`< > <= >= == !=`。

结合上面的知识，可以写下面这样一个awk：
```text
awk 'BEGIN {FS=":"} $3<1000 {print $1}' /etc/passwd
```
这个命令的作用就是扫描/etc/passwd文件，用冒号作为每行的分割符，将每行第三个字段拿出来（其实是UID）看其是否小于1000，如果是就输出第一个字段的值（其实是用户名）


awk命令还有很多很多细节可以学习。先写到这里


## find

find命令的功能是在指定目录下寻找符合要求的文件，并输出其路径。
众所周知，find命令是实际扫描目录结构（==扫描内存中的目录项，若不存在目录项 ，才读取磁盘==）的，因此扫描很大很深的目录时速度会比较慢。尤其是扫描整个根目录之类的操作，应该避免。不过从实验来看，`find`命令也自带缓存功能，同样的搜索命令第一次运行可能花时间长一点，但是马上运行第二次很快就能出来。

find命令的使用格式是`find path [options]`。对，==记住path是紧跟着find命令，后面才是参数==。

至于options，最常见的，就是各种对文件进行过滤的条件。常用的有下面这些

- -name 指定文件名

  支持简单匹配、通配符匹配以及一些简单的正则匹配。下面是一些例子：

  ```shell
  find . -name "20201001\.log"
  find ~ -name "*\.log"
  find ../ -name "[a-z]*[0-9]\.log"
  ```

- -perm 指定文件权限

  通常可以用数字形式的权限查找。例子：

  ```shell
  find . -perm 755
  ```

- -user/-group与nouser,nogroup

  `-user`和`-group`很明显就是指定所属用户和用户组的过滤条件。
  这里具体写的参数值可以是用户/组名，也可以是uid和gid，例子：

  ```shell
  find . -user 501
  find . -group staff
  ```

  `-nouser`和`-nogroup`是针对这样一种情况：某个文件的owner或owner group被从系统中删除了。此时如果你`ls`看一下会发现这个文件的所属用户会变成uid，然而这个uid已经不对应系统中用户了。`-nouser`和`-nogroup`就是过滤出这类没有实际所属用户/用户组的文件。

- -mtime, -newer等跟时间有关的参数

  `-mtime`顾名思义就是根据文件的mtime搜索文件的参数。然而具体给定什么参数呢？考虑到很少会有给出某个时间点让你找恰好此时间点上发生改变的文件，`-mtime`通常是以一个正数或者负数为参数值，如：

  ```shell
  # 假如今天是7月1日
  find . -mtime -5    # 查找6月26日到今天的五天范围内被修改的文件
  find . -mtime +10    # 查找十天前的6月21日之前被修改的文件
  ```

  另外，如果时间的基准点不想以输入命令时刻为基准，则可以用`-newer`。
  这个参数的使用例是这样的：`-newer FILE_A`表示比FILE_A更新的文件。那么有没有older，答案是没有，但是可以用`! -newer FILE`这种形式，因为是“非newer”，所以输出中会保留FILE本身。另外这两个命令还可以放一起，形成一个范围。
  使用例：

  ```shell
  find . -newer 2012.log ! -newer 2017.log    # 如果一年一个log的话，那么输出结果会是2013/2014/2015/2016/2017这些
  ```

- -size

  默认不带任何单位的数字，其单位是数据块数。然后不带符号表示恰好大小等于指定值。若想要大于或者小于，可以再前面加正负号

  ```shell
  find . -size 100c    # 寻找大小恰好100字节的文件
  find . -size +10000    # 寻找大小大于10000个数据块的文件
  ```

- -depth

  默认使用DFS对目录结构进行扫描。输出时，目录将优先于目录中内容输出（相当于输出时机是在进入下层dfs之前）。
  加上这个参数后可以让上述时机变成dfs完成扫描之后，即输出结果中目录中的内容将优先于目录本身输出。

- -prune 排除一些范围

  这个场景的需求是，扫描当前目录下的所有文件，但唯独不包括当前目录下名为test的子目录中的文件。先来看看是怎么写的：

  ```shell
  find . -path "test" -prune -o -print
  ```

  分析一下这个命令。其实关键在于`-o`，与之相似的还有一个`-a`，这俩分别表示`OR`和`AND`两种逻辑判断。
  既然是这俩，那么很容易就可以得知，前后两个应该是两个不同的判断式了。实际上，看上面这个命令，`-path "test" -prune`就是指如果某个文件的相对路径以test开头，那么就将其prune掉。另一方面，若开头不是test，则前面这个条件不成立。由于前面条件不成立，两个条件又是OR关系，所以取计算后面的条件。后面条件的`-print`其实就是默认的答应文件路径操作，之前都是隐式的，这里因为在OR后面，必须显式写出来。

## sar

sar命令用于对Linux的一些基础性能指标进行监控。常见的一些需要监控的指标与显示该指标的命令对应如下：

> 各个命令返回结果的字段的解释见：https://blog.csdn.net/liyongbing1122/article/details/89517282

```shell
sar -u 1 3    # 监控CPU各种时间占比，每隔1秒输出一次，共输出三次。下面的所有命令的1 3也都是相同意义
sar -q 1 3    # 监控系统负载
sar -r 1 3    # 监控内存各项指标
sar -W 1 3    # 监控Swap分区的情况（主要是每秒换进换出的页数）
sar -b 1 3    # 查看IO和传递速率
sar -d        # 查看磁盘使用
```

除了以上这些硬件之外，还可以通过`sar -n`查看网络情况。这个下面的参数太多了就不写了，看上面的参考网址。

## uniq与sort

有一个场景题，ip.txt中每一行保存了一个IP的访问记录。
用Linux命令找出其中重复次数最多的三个。这俩命令的组合就可以很好完成这个任务。
命令是这样的：

```shell script
sort ip.txt | uniq -c | sort -rn | head -n 3
```
第一个sort排序所有IP，将相同的IP都连续摆放在一起。
第二个uniq将连续相同IP进行计数，同时输出计数值（-c参数）
第三个sort针对uniq的输出再次排序，-r表示逆序排序，-n表示以数字排序
最后head就不说了。

## lsof

大体上知道lsof是用来查看进程打开了哪些文件的。而因为Linux中一切皆文件，所以lsof能查看的不仅是普通文件，还包括目录、socket、设备、管道等等。

lsof的参数十分丰富，列举如下：

| 命令                | 功能                                                         |
| ------------------- | :----------------------------------------------------------- |
| lsof                | 列出所有进程打开的所有文件对象                               |
| lsof FILE           | 从文件视角出发，列出所有打开本文件的进程                     |
| lsof +D DIR         | 单纯输入lsof DIR只是查看是否有进程用这个目录，而不会查目录下面的内容。如果要递归寻找目录下的某个文件是否被打开，则需要这条。注意参数是+D不是-D |
| lsof -p PID         | 从进程视角出发，列出该进程打开的所有文件                     |
| lsof -u UID或用户名 | 从用户视角出发，列出该用户所有进程打开的文件                 |
| lsof -i             | 列出所有网络连接相关的文件（TCP/UDP）                        |
| lsof -i 限制条件    | 条件的选项包括`4 / 6 / tcp或udp / :端口 / @主机名 `。按照格式可以将多个条件结合在一起。 |

### lsof输出字段解释（一部分）

- COMMAND即启动的进程的命令

- PID，PPID，USER，PGID这些就不解释了

- FD即文件描述符(==就是多路复用IO里的那个！这些描述符通常都以硬链接的形式保存在`/proc/<pid>/fd`中。==)，常见的有

  ```
  cwd: 当前工作目录
  txt: 进程的代码/二进制文件
  mem: memory mapped file，通常是一些链接库
  0,1,2: stdin, stdout, stderr
  更大的数字：其他IO设备。这些包括上面三个标准设备，数字后面会加上文件的读取模式，r是只读，w是只写，u是既可读也可写
  ```

- TYPE即文件类型，常见的有

  ```
  DIR：目录
  REG：普通文件
  BLK：块设备
  unix: 域套接字
  ```

### 关于deleted标识与恢复误删文件

有时用lsof会看到文件的末尾有一个`(deleted)`。这是说明本进程好好地在用这个文件时，文件突然被别的进程删除了。
==在进程操作文件时，Linux通常会创建进程专属的一个硬链接连到对应文件上。而这个硬链接存放在`/proc/PID/fd`中。所以，当本进程打开某文件后，即使文件在原path被别的进程删除，本进程依然可以访问文件，因为有硬链接在==。

==另一方面反过来说，如果某个文件不小心被误删，而其恰好又还在被某个进程使用。那么进到进程的`fd`目录下面就可以使用硬链接找回原文件内容，于是可以恢复误删文件==。

## tcpdump

`tcpdump`正如我们所知，是个命令行的网络抓包工具。有GUI的抓包工具可以使用wireshark等。
网络包就是指TCP/IP五层模型中三层的数据传输单位。只要在tcpdump的过滤范围中，任何一个经过相关网卡的（不论是发送到主机还是从主机发出）包都会被记录下来。

这个命令常用的选项有下面这些：

```
-i    指定网卡接口
-nn    保留通信双方的IP/端口，而不是以域名显示
-c    指定抓包个数
-w    将抓包结果保存在文件中，通常文件名后缀是file.pcap
```

除了选项外，因为网络包很多很多，所以这个命令还提供了很多筛选条件以减少不必要的信息。常用的筛选条件包括

| 过滤类型    | 选项                              | 示例                                     | 说明                                           |
| ----------- | --------------------------------- | ---------------------------------------- | ---------------------------------------------- |
| 主机过滤    | host / src host / dst host HOST   | tcpdump host 192.168.1.100               | 对发送主机和（或）接收主机做固定值筛选         |
| 端口过滤    | port / src port / dst port PORT   | tcpdump port 80                          | 对发送主机端口和（或）接收主机端口做固定值筛选 |
| 协议过滤    | tcp / udp / icmp / ip / ip6 / arp | tcpdump tcp                              | 对通信协议做固定值筛选                         |
| TCP状态过滤 | 一些TCP状态的表达式               | tcpdump "tcp[tcpflags] & tcp-syn == 0"   | 顾名思义…这里更详细的语法不说了，可以百度      |
| 逻辑条件    | and / or / not                    | tcpdump dst host 192.168.1.1 and port 80 | 可以将上面多个不同的筛选条件通过关键字逻辑连接 |

比如，查看ping包的接收和响应情况就可以使用

```shell
tcpdump -i eth1 icmp and host x.x.x.x -nn
```

==值得注意的是，tcpdump的输出是一个阻断了stdin的数据流。也就是说不按`Ctrl + C`的话，包信息会不断刷新在屏幕上。==

tcpdump的输出，每一行代表一个包，用字符串的形式将需要的包部分信息展示出来。然而这样信息既不直观也不完整。可以用-w参数将信息写入到抓包文件中（注意抓包文件非普通文本，一定需要软件解析），然后将其导入wireshark中解析。wireshark则可以给出一个比较好看的界面，用于分析网络问题。

wireshark可以分层展示包信息。比如上面抓ping包的文件，解析后一个包的信息展示如下：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/image-20210720183227785.png" alt="image-20210720183227785" style="zoom:67%;" />

## ifstat, vmstat, iostat, netstat

*stat系列命令。

### ifstat

运行`ifstat`命令的结果大概长这样：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/image-20210803151854369.png" alt="image-20210803151854369" style="zoom:50%;" />

这个命令的原理是这样的，默认情况下，第一次执行一次ifstat之后，隔一段时间再执行一次ifstat。每次执行后，这次执行的结果会被写到`/tmp/.ifstat.$UID`文件里。

输出中每个网卡会有四列、两行信息。
第一行列标题中带有RX代表收到数据，第一列的单位是包个数，第三列的单位是字节数。带有TX的则是发送的数据。
第二行主要展示该网卡解包错误、丢包等方面的信息。
关于这个命令的输出，网上资料也不完全，目前还不能整明白。

### vmstat

vmstat综合展示了很多维度的机器的状态。输出大概长这样：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/image-20210803154009956.png" alt="image-20210803154009956" style="zoom:50%;" />

命令的两个数字，第一个是采样间隔秒数，第二个是总共采样次数。
输出结果总共有六大块。

第一块procs是进程相关。r表示就绪队列中正在等待运行的进程数，即瞬时CPU负载，b表示阻塞着的进程数
第二块是内存相关。和free的字段类似。swpd表示使用的虚拟内存的大小，单位是KB（注意区分虚拟内存和swap分区）
第三块swap分区相关，指的是当前每秒从swap分区换入/换出的页面总大小，单位为KB/S
第四块是IO相关，每秒读取/写入的磁盘块数
第五块是内核态CPU运行相关，in指每秒中断次数，cs指每秒上下文切换次数。
第六块则是熟悉的CPU使用率相关的一些指标，和top中意义是一致的。

### iostat

iostat的输出长这样：（iostat也可以后接两个数字，逻辑和vmstat一样）

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/image-20210803172340737.png" alt="image-20210803172340737" style="zoom:50%;" />

上面的CPU时间比部分输出就不说了，一个意思。

下面则是各个IO设备的信息。

tps指系统每秒请求IO设备的次数。
kB_read/s 与 kB_wrtn/s 自然是每秒读写的数据量，以KB为单位。
kB_read 和 kB_wrtn 是迄今为止读写过的总数据量，以KB为单位。

### netstat

这个是老熟人了。最简单常用的用法是加上参数`netstat -ntlp`查看端口开放、端口与进程对应等的情况。解释一下各个参数
`n`表示numeric，所有本机地址都用IP表示而非主机名
`t`表示TCP，与之对应的还有`u`表示UDP。
`l`表示listening，只展示处于listening状态的连接。(==默认展示的TCP连接都是处于ESTABLISHED或者挥手过程中的状态，如果`l`的基础上再加上`a`表示all，即所有状态的socket，那么就可以展示所有状态的socket连接了==)
`p`表示program，即展示端口对应的进程程序名称以及pid等。

一些可以记忆的命令：
`netstat -tnp`查看所有状态的TCP连接（再加上`l`则是只查看LISTEN的）
`netstat -unpa`查看所有UDP连接（？UDP哪来的连接…），注意一定要加`a`，否则不会出信息，因为默认情况下只会展示处于CONNECTED状态的socket。对TCP来说就是指ESTABLISHED或者挥手过程中的那些，但是UDP没有对应，因此会无信息。

### tar

tar命令用来打包多个文件，常常加上某些压缩算法来做压缩包。用法不是问题，这里想多讨论一些细节。

同样的压缩，还有`zip/unzip`，7z等方法可以实现，为什么`.tar.gz`会成为最通用的格式呢？这主要是两个原因。

第一，`tar`命令虽然用作打包，但打包得到的内容最为完整，包括了所有文件meta信息。换言之，只有`.tar`包才能保存下诸如文件的owner，权限等信息。其他打包/压缩软件针对这部分信息都会丢失。
第二，`gzip`压缩格式相对其他格式而言，在linux上被支持得最为广泛，因此采用`gzip`对`tar`包进行进一步的压缩。

基于上述两点，Linux上最通用的压缩包就变成了`.tar.gz`格式了。

## xargs

这个命令给我的印象是经常在pipeline中使用。其实其全称是extended argument，作用仅仅是在文本层面对于传递过来的参数进行形式上的整理。
比如多行边单行、给定分隔符进行分割等。大体上类似于Python中的zip函数、split函数等一些的作用。