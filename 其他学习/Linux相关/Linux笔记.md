## 在Linux上输入一个命令，系统会发生什么？

比较完整地考虑，
首先应该要判断你输入的是不是一个路径。如果是一个路径，那么直接执行即可。

如果不是路径，此时说明你输入的应该是一个命令，一般来说要去PATH里面找相应的二进制文件执行。
但是Linux中其实自带一个保存了"命令 - 实际路径"的缓存。

这个缓存可以通过`hash -l`来查看，也可以用其它参数来增删查改。如果某个命令存在于这个缓存中，那么就直接拿缓存中保存了的那个路径来用即可。
如果没有，才会去搜索PATH，找命令的二进制文件。注意找到了之后还要将这个对应关系保存到缓存中。

## Buffer和Cache的区别

在Linux上运行`free -mh`可以看到各种内存分区的占用情况。其中有一个Buffer/Cache，乍一看都叫缓存，但是具体是什么样的呢？

Cache全称Page Cache。他可以说就是一般意义上认为的内存中存在的磁盘缓存。即读写文件时为了避免频繁的磁盘IO，先将要读写的内容加载到Cache中，然后再进行统一的读写，尽量一次IO就搞定。
当下Linux的Cache通常动不动就几个G。Linux的内核设计逻辑就是，尽量使用内存，所以Cache会被用的比较多，只要文件被请求过，那么其内容就会暂时性永久保存在Cache中，即使请求了这个文件的进程本身都已经退出了。
当然，Cache并不是系统运行必须的东西，因此当内存空间吃紧的时候，系统会自动将Cache中的一些内容换回磁盘上去，从而腾出空间来分配给其他进程。

如果说Cache是文件内容的缓存区，那么Buffer就是那些cache中文件的meta信息的缓存区，比如存放路径、权限等。因为其存放的信息不太多，所以Buffer的空间一般都是几十M左右。
在2.4版本的Linux内核以后，Buffer和Cache就被统一起来管理了。

## 软硬链接的区别

Linux中所有文件都由inode和block组成。
inode保存一些meta信息而block保存实际的文件信息。

创建硬链接，是指新建一个inode指向对应文件的block。因此删除原文件（本质上是删除原文件的inode）并不会影响硬链接对文件的访问。
因为相关block的引用计数也未归零所以系统不会删除block。
硬链接不能跨越文件系统（因为你想不同文件系统的inode和block不一定兼容

另一方面，==软链接本身就是一个独立的文件，只不过其文件内容是一个指向对应文件的绝对路径==。
所以，不要说删除原文件，就算是原文件改个名或者改个路径，软链接就找不到文件了。
因为这是表层的路径映射，软链接可以跨文件系统建立。
Windows中的快捷方式等同于软链接。

## fork函数

在Linux的C程序中，调用fork函数，记住其特点是==“调用一次，返回两次。一次返回给父进程，一次返回给新建出来的子进程”==。
因为子进程的内存是严格复制父进程的，因此父进程运行到fork为止的所有中间变量，子进程也直接继承，并接着运行。

比如下面这段程序：

```c
void main(){
    int i;
    for(i=0;i<3;i++){
        pid_t fpid = fork();
        if(fpid == 0){
            printf('son.');
        }
        else{
            printf('father.');
        }
    }
}
```

上述程序如何运行？第一层进程第一次运行到fork时，i显然是0，于是fork出一个i是0的子进程。此后两进程分别都从`if(fpid == 0)`开始继续运行。下面是这个进程树的图：

```text
           0
    0      1      2
  1   2    2
2
```

每个数字表示一个进程开始运行时其i的值是多少。这个值是`n`的话，就表明这个进程还剩下`3-n`轮循环，即会输出`3-n`行字符串。

所以，上述程序总共会生成`3 + (3+2+1) + (2+1+1) + 1 = 14`行。


## 命令合集

### 文本处理命令三剑客 grep / sed / awk
三剑客指文本流处理中的grep,sed,awk三个命令。==grep擅长查找内容，sed擅长取行以及替换，awk擅长取列以及格式化输出==。

#### grep
grep的使用方法通常接在一个pipeline的后面。
另一方面，其实其官方的使用方法应该是`grep pattern file`。

常用的grep参数包括
```text
-i      忽略大小写
-v      不匹配
-o      只显示匹配到的部分而不显示整行
-E      使用扩展正则表达式
-A      (After) 输出匹配以及后X行，是这个option的参数值
-B      (Before) 同上，输出的是匹配行及其前X行
-C      (Context) 同上，输出的是匹配行及其前后各X行
以上参数都是修饰pattern的，即 grep [参数] pattern file

-r      递归搜索指定目录中所有文件内容，比如 grep 123 -r ./ 就会搜当前目录及其递归子目录下所有文件中所有带有123的行
以上参数是修饰file的，即 grep pattern [参数] file
```

#### sed
sed后面跟的参数比较复杂，需要分成几个层面来看。
首先，sed本身可以带几个参数，因此形成了模式`sed [-nefr] '[编辑动作]'`。各个参数的含义是：

```text
-n      使用安静模式。默认非安静模式下所有内容都会被输出
-i      在文件中原地编辑 in-place
-i.bak  in-place编辑的同时备份源文件
-f      指定一个sed的"脚本文件"，里面每一行都是一个编辑动作。-f指定脚本后会按照顺序依次执行动作
-r      让后续动作中支持扩展正则表达式
```

接着，看编辑动作的格式。注意编辑动作要用单引号引起来。编辑动作大概可以分成两部分，`[addr][option]`。
其中addr是寻址表达式，意思是给出一些条件如行号或者正则式匹配，通过这些条件从而定位若干行。
option则是动作表达式。表示对寻址表达式匹配到的行进行相应操作。

注意两者并不总是连在一起，根据不同情况可能会有不同。总之记住编辑动作的两个要素，定位和操作。

寻址可以是单寻址（定位一行）或者多寻址（定位多行）。
单寻址的例子：
```text
42      第42行
$       最后一行
/pat/   能够匹配到pat这个正则式的**第一行**
```
多寻址的例子
```text
42,45   第42到第45行，总共是42,43,44,45四行
42,+4   第42行开始的四行，等效于上面的
x~y     步进，如1~2是所有奇数行，2~2是所有偶数行
```

接着是操作，主要有以下几种
```text
d       删除寻址找到的行（后面称这些行为指定行）
p       打印指定行，因为打印追加在stdout最后，所以通常和-n参数配合使用
aTEXT   在指定行下面append新的一行文本TEXT，TEXT中可以带有转义字符如\n以实现多行插入，下同
iTEXT   在指定行上面prepend新的一行文本TEXT
cTEXT   替换指定行为文本TEXT。注意这个操作如果针对连续行，则将连续行替换成一个而非多个
w/path  将指定行写入到新文件/path
=       在指定行上面prepend一行行号。配合-n参数可以打印指定行的行号。
!       取反指定行，需要接在其他操作指令的前面比如 !p 或者 !=。
s/a/b/g 替换操作
        关于这个替换操作，首先，s前可以加寻址式以进一步限定范围，比如1,5s/a/b/g
        其次，g是最常用的全局替换标识。除此之外还可以是p 只打印替换后的行，w/path 将替换后的行保存到新文件等。
```

>更多sed的使用例：https://blog.csdn.net/vanvan_/article/details/91397655


#### awk
awk的基本工作格式是`awk '条件类型1{动作1} 条件类型2{动作2} ...' FILE`。

##### 动作格式字符串
先来看动作。动作是一串格式化字符串，其中带有一些动态含义的变量或者关键字。
因为awk是主要用于每一行的列字段处理，所以最常见的动作比如`print $1 "\t" $3`这种。

除了`$0`表示整行以及`$n`表示第n个字段的值以外，动作格式字符串中还可以有如下变量：
```text
NF      每一行($0)拥有的字段总数（Number of Fields）
NR      目前awk处理的是第几行数据，即行号（Number of Row）
FS      分隔符，默认是空白        
```

注意动作格式字符串中，那些写死的字符串用双引号引用出来，并且字符串之间不需要额外的符号，默认是连接在一起的。如：
```text
awk '{print $1 "\t lines:" NR "\t columns:" NF}'
```

注意上述变量除了读之外，其实还可以写。比如某行不使用默认空白作为分隔符时，需要手动指定分隔符，就可以操作如下：
```text
awk '{FS=":"} {print $1}'
```
注意以上做法还有点小问题，第一行数据无法正确输出字段而是输出整行。
这是因为awk命令的机理，是先读取一行数据，然后进行awk后面定义的操作的。在读取第一行的时候，FS还未被定义成冒号而是用了默认的空白，因此无法正确输出。

解决办法是使用BEGIN关键字如下：
```text
awk 'BEGIN {FS=":"} {print $1}'
```
跟在BEGIN关键字后面的动作将会在读取第一行开始前就执行，因此第一行也可以用我们定义的冒号进行分割了。

##### 条件类型
awk的条件，指的并不是像sed那样的寻址条件。
因为awk关注的是每一列的字段，因此其条件也是基于字段的值进行判断的条件。

具体来说，对于字段是数字的情况，其实条件是一些自然的逻辑运算，包括`< > <= >= == !=`。

结合上面的知识，可以写下面这样一个awk：
```text
awk 'BEGIN {FS=":"} $3<1000 {print $1}' /etc/passwd
```
这个命令的作用就是扫描/etc/passwd文件，用冒号作为每行的分割符，将每行第三个字段拿出来（其实是UID）看其是否小于1000，如果是就输出第一个字段的值（其实是用户名）


awk命令还有很多很多细节可以学习。先写到这里


### find

find命令的功能是在指定目录下寻找符合要求的文件，并输出其路径。
众所周知，find命令是实际扫描目录结构的，因此扫描很大很深的目录时速度会比较慢。尤其是扫描整个根目录之类的操作，应该避免（解决办法是用locate）。

find命令的使用格式是`find path [options]`。对，==记住path是紧跟着find命令，后面才是参数==。

至于options，最常见的，就是各种对文件进行过滤的条件。常用的有下面这些

- -name 指定文件名

  支持简单匹配、通配符匹配以及一些简单的正则匹配。下面是一些例子：

  ```shell
  find . -name "20201001\.log"
  find ~ -name "*\.log"
  find ../ -name "[a-z]*[0-9]\.log"
  ```

- -perm 指定文件权限

  通常可以用数字形式的权限查找。例子：

  ```shell
  find . -perm 755
  ```

- -user/-group与nouser,nogroup

  `-user`和`-group`很明显就是指定所属用户和用户组的过滤条件。
  这里具体写的参数值可以是用户/组名，也可以是uid和gid，例子：

  ```shell
  find . -user 501
  find . -group staff
  ```

  `-nouser`和`-nogroup`是针对这样一种情况：某个文件的owner或owner group被从系统中删除了。此时如果你`ls`看一下会发现这个文件的所属用户会变成uid，然而这个uid已经不对应系统中用户了。`-nouser`和`-nogroup`就是过滤出这类没有实际所属用户/用户组的文件。

- -mtime, -newer等跟时间有关的参数

  `-mtime`顾名思义就是根据文件的mtime搜索文件的参数。然而具体给定什么参数呢？考虑到很少会有给出某个时间点让你找恰好此时间点上发生改变的文件，`-mtime`通常是以一个正数或者负数为参数值，如：

  ```shell
  # 假如今天是7月1日
  find . -mtime -5    # 查找6月26日到今天的五天范围内被修改的文件
  find . -mtime +10    # 查找十天前的6月21日之前被修改的文件
  ```

  另外，如果时间的基准点不想以输入命令时刻为基准，则可以用`-newer`。
  这个参数的使用例是这样的：`-newer FILE_A`表示比FILE_A更新的文件。那么有没有older，答案是没有，但是可以用`! -newer FILE`这种形式，因为是“非newer”，所以输出中会保留FILE本身。另外这两个命令还可以放一起，形成一个范围。
  使用例：

  ```shell
  find . -newer 2012.log ! -newer 2017.log    # 如果一年一个log的话，那么输出结果会是2013/2014/2015/2016/2017这些
  ```

- -size

  默认不带任何单位的数字，其单位是数据块数。然后不带符号表示恰好大小等于指定值。若想要大于或者小于，可以再前面加正负号

  ```shell
  find . -size 100c    # 寻找大小恰好100字节的文件
  find . -size +10000    # 寻找大小大于10000个数据块的文件
  ```

- -depth

  默认使用DFS对目录结构进行扫描。输出时，目录将优先于目录中内容输出（相当于输出时机是在进入下层dfs之前）。
  加上这个参数后可以让上述时机变成dfs完成扫描之后，即输出结果中目录中的内容将优先于目录本身输出。

- -prune 排除一些范围

  这个场景的需求是，扫描当前目录下的所有文件，但唯独不包括当前目录下名为test的子目录中的文件。先来看看是怎么写的：

  ```shell
  find . -path "test" -prune -o -print
  ```

  分析一下这个命令。其实关键在于`-o`，与之相似的还有一个`-a`，这俩分别表示`OR`和`AND`两种逻辑判断。
  既然是这俩，那么很容易就可以得知，前后两个应该是两个不同的判断式了。实际上，看上面这个命令，`-path "test" -prune`就是指如果某个文件的相对路径以test开头，那么就将其prune掉。另一方面，若开头不是test，则前面这个条件不成立。由于前面条件不成立，两个条件又是OR关系，所以取计算后面的条件。后面条件的`-print`其实就是默认的答应文件路径操作，之前都是隐式的，这里因为在OR后面，必须显式写出来。

### sar

sar命令用于对Linux的一些基础性能指标进行监控。常见的一些需要监控的指标与显示该指标的命令对应如下：

> 各个命令返回结果的字段的解释见：https://blog.csdn.net/liyongbing1122/article/details/89517282

```shell
sar -u 1 3    # 监控CPU各种时间占比，每隔1秒输出一次，共输出三次。下面的所有命令的1 3也都是相同意义
sar -q 1 3    # 监控系统负载
sar -r 1 3    # 监控内存各项指标
sar -W 1 3    # 监控Swap分区的情况（主要是每秒换进换出的页数）
sar -b 1 3    # 查看IO和传递速率
sar -d        # 查看磁盘使用
```

除了以上这些硬件之外，还可以通过`sar -n`查看网络情况。这个下面的参数太多了就不写了，看上面的参考网址。

### uniq与sort

有一个场景题，ip.txt中每一行保存了一个IP的访问记录。
用Linux命令找出其中重复次数最多的三个。这俩命令的组合就可以很好完成这个任务。
命令是这样的：

```shell script
sort ip.txt | uniq -c | sort -rn | head -n 3
```
第一个sort排序所有IP，将相同的IP都连续摆放在一起。
第二个uniq将连续相同IP进行计数，同时输出计数值（-c参数）
第三个sort针对uniq的输出再次排序，-r表示逆序排序，-n表示以数字排序
最后head就不说了。

### top中各种cpu使用率含义

我们知道CPU是按照时间片分给进程使用的。因此CPU使用率也可以说是其过去一段时间有多少时间片分给任务进行计算的占比。换句话说，就是过去一段时间CPU运行时间占比。

根据分配给的任务性质不同（这个任务是广义的，比如可以指用户态or系统态进程、也可以指等待IO、软中断硬中断等等）

- User Time & System Time

  ```
  顾名思义，就是CPU在用户态和内核态两种状态下各自时间比
  ```

- Nice Time

  ```
  指CPU用来给进程重新计算优先级的用户态的时间比。Nice Time也包含在User Time中。
  ```

- Idle Time

  ```
  指CPU空闲时间比，通常Idle + User + System = 100%
  ```

- Waiting Time

  ```
  指等待磁盘读写的CPU时间比
  ```

- Soft/Hard IRQ Time

  ```
  指软/硬中断时间比。软硬中断的区别在于中断请求由软件还是硬件发出。而保存CPU信息，分析中断原因，开始调用中断处理函数，这部分的时间就是软硬中断时耗费的时间了。
  中断时间也包含在System Time中。
  ```



## 【TODO】lsof



## 【TODO】tcpdump

