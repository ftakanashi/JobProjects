# MySQL索引

>参考
>
>https://zhuanlan.zhihu.com/p/352181863
>
>https://www.cnblogs.com/tianhuilove/archive/2011/09/05/2167795.html

## 索引是什么，干什么的？
索引的本质是一种结构巧妙的数据结构。他的作用，是帮助快速检索。
更具体来说，当你在SQL中发出带有WHERE条件的SELECT语句时，没有任何索引辅助的情况下，最简单的思路就是一行一行搜索，
将符合条件的行全部返回。显然复杂度是O(n)的。

而有了索引之后，可以借助索引的辅助，依照给出的具体条件，有可能可以以更快的速度比如O(logn)甚至O(1)等获取到相关的行。

需要注意，索引虽然能够加快检索的速度，但是对写操作的性能是有损害的。因为写操作改变表中数据后就要额外更新索引。

## 其他索引类型以及前序知识
广义上的索引，根据其用来加速检索的数据结构的不同，而分成很多类型。
MySQL中最常用的索引类型是B+ Tree。
但是在说B+ Tree之前， 不妨先来讲讲其他类型。

### 哈希索引
根据上面对具体索引是干什么的描述，其实很容易想到哈希就是一个可能的索引。
比如针对一个学生信息表，我维护了一个学号到姓名的哈希。而后只要你SELECT 姓名 WHERE 学号=x的话，不用扫描表，直接通过这个哈希对应就可返回数据。

乍一看哈希索引似乎很好，但是其也有很明显的确定。
首先，==上述哈希的加速只能用于单条数据查询，比如我现在想要来个学号 LIKE xxx的查找，哈希就不行了==。
其次，==哈希不具备顺序性。比如我想知道学号是xxx后三个人的姓名，（假设学号并不连续）哈希也不行==。

事实上，常用的MySQL引擎InnoDB并不支持哈希索引。所以这里就看个乐吧。

### MySQL数据存储的底层实现
MySQL在存储方面，使用的最小存储单位叫数据页。一个数据页的默认大小是16K。
打个比方，一个数据页存放100行数据的话，那么显然为了存放第101个数据，需要开辟一个新的数据页。
数据页之间互相以双向链表的方式进行连接，因此通过一个数据页可以轻松地到达其后一个或者前一个数据页。

在数据页内部，行也是一个存储单位，内部具体结构根据不同的表定义而不同。但共通的一点是，数据页内的所有行，是根据主键的顺序从小到大排序的，并且
行之间通过单向链表的方式连接。
由于是单向链表，所以对行的遍历也是单向的。

除了数据页之外，我们还要引入一个概念叫主键目录。可以将其理解为一个特殊的数据页，内部每一行维护的，是指向一个数据页的指针、此数据页的编号、以及
此数据页的最小主键。
主键目录的意义在于，当我拿到一个主键后，想要搜索这条记录相关信息时，只要在住建目录上二分查找，就可以知道这个主键位于哪个数据页（根据数据页的最小主键确定范围），
进而快速地得到记录相关信息。
这个主键目录也被称为主键索引。泛泛来说这也算是索引的一种，且是最基础的一种索引。

上述结构如下图示：
![](https://pic3.zhimg.com/80/v2-774817ca13718769d799aaccc35463f2_720w.jpg)


## 索引页扩张以及B+树
从上面图中的状态，现在我们急剧扩大数据规模。假设主键从原来最大的6增大到30多。（当然这不是一个很大的量，这里只是比方说明）

这时引起一个问题，主键目录会变很长，从而导致即使二分查找也还是效率太差。
注意到主键目录本质上还是一个数据页，所以我们可以将其分页，然后创建一个新的特殊数据页用来指向这些被分开的主键目录。
这样的一个"主键目录的主键目录"称为索引页。这种索引页里，每一行维护的是指向每个"分主键目录"的指针以及该"分主键目录"的最小主键
而原先被分开的住建目录的各个页，也可以笼统地称为索引页。

但两种索引页不同的是，前者是主键目录的索引，后者是实际数据的索引。

上述方案可以以下面图示：
![](https://pic2.zhimg.com/80/v2-5f492391305b5a0971b28044b5f3fcc1_720w.jpg)

注意图中各个页都被标记成了索引页，但是索引页并不同。黑底的是索引页8是索引的索引（即二级索引），蓝底的索引页1和2是数据的索引。
按上图例子，比如现在我想找主键=20的数据在哪时，先在最上层的索引页找，发现20的索引被记录在索引页2，然后跳到索引页2，继续查找，发现20的数据在数据页5，
于是最后，到数据页5去找出想要的数据。

接着，如果数据进一步增多，导致二级索引页也过长了怎么办？分裂出一个三级索引呗。
以此类推，其实最终就会得到一个树形的结构。从根节点开始索引一级一级下降，到倒数第二层索引变成数据的索引，而叶子节点则是数据页。
整体图示如下：
![](https://pic1.zhimg.com/80/v2-e79c5057bed36c40ac34e265678eb38c_720w.jpg)

实际上，上面这棵树，是一个B+树。

### 什么是B+树
二叉树大家都知道怎么回事。多叉树也是类似的。
下面针对一个多叉树的节点，我们对其内容物进行一个拓展。

一般来说，树节点的内容物就是一个简单的val值，而这里，我们将其定义为若干个指针和数据。这些内容有顺序地排列在一起。
所有的叶子节点都是数据块。
对于一个节点如果其内部排序是`p1 d1 p2 d2`的话，那么所有`p1`指针指向的子节点及其所有后代节点的数据块的数据全部小于等于`d1`。
同理，`p2`指向的所有后代节点中的所有数据都大于等于`d1`但小于等于`d2`。
上面这样的一个树，叫做B树：
![](https://pic1.zhimg.com/80/v2-daf5fe2b640f9822a24b51210f8bed44_720w.jpg)

而把B树节点中的所有非叶子节点的数据块全部都去掉（或者说以合理的形式安排到其下属某个叶子节点中），得到的树就是B+树了。
显然，B+树每个非叶子节点只有指针，而指针之间又是互相有序的。前序指针的后代叶子节点中最大的数据，小于等于后续指针后代叶子节点中最小的数据。

具体到数据库的索引结构中，示意图大概长这样：

![](https://pic3.zhimg.com/80/v2-e409f0e42fed2eb95b2c83c246b03d2e_720w.jpg)

树上每个非叶子节点都是一个指针的有序集合。指针一层一层往下指，指导叶子节点位置。每个叶子节点都是一个数据页。此外正如上面说过的，这些数据页之间都用双向链表相连，即B+树的叶子节点之间还有序地前后相连着。

### ⭐️为什么用B+树

相比于B树，B+树的优势是：

- B+树的节点只有指针，因为一个节点是一个页，也是一次IO的单位。==因此B+树一次IO读取到的指针更多，潜在地可以访问更多数据。从而减少磁盘IO==。
- B+树的所有数据都在叶子节点上，因此查找时遍历的层数总是稳定的，即==查询速度稳定==
- B+树所有数据都在叶子节点上，并且以双向链表的方式互相连接，因此做==全表扫描时更方便高效==。这也是B+树最主要的优势，因为数据库查询中因要做范围查询而全表扫描非常常见。

### 一个B+树的容量

这里我们需要做一些假设。比如上面每一个“页”，我们认为其是4K大小好了。每个指针，64位系统中自然是8个字节，因此，根节点可以存放512个指针。这些指针又分别指向第二层的一个块，这个块也是4K大，内放512个指针。

这么一来，两层树就可以得到512^2^个指针，指向了26万多的数据页。假设这个表每行数据有10个字段，每个字段都是64位整数的话，一行数据80个字节，所以一个数据页可以存放50行数据左右。

乘一下，就知道，这棵树总共可以存放1300万行左右。换言之，==千万级别的表，可以只要用一个3层B+树就可以建立索引了==。

## ⭐️主键索引、聚簇索引、回表

以上示例中，默认用主键作为构建索引的关键项，即根据主键的大小关系进行索引的构建。很自然，这种建立在主键上的索引，称为主键索引。主键索引的叶子节点上，正如上面所说，保存完整的行的信息，是一个聚簇索引。

与主键索引相对的，当然就有非主键索引。非主键索引，则是指我们还可以把索引建立在非主键列上。并且根据多个列互相之间有优先度的比较大小，还可以建立在多个列上，称复合索引。
非主键索引通常叶子节点上不会保存完整的列信息，只会保存那些建立这个索引用了的列 加上 主键。要额外加一个主键是为了可以回表。显然，非主键索引也是非聚簇索引。

==一个表，有且只有一个聚簇索引，并且索引结构在建表时就直接建立。或者说，（使用InnoDB作为引擎的）表本身就是其自身的聚簇索引。看一下数据文件就知道，这样的表有两个文件，一个`.frm`文件保存一些表的meta信息，一个`.ibd`文件既是所有数据的文件，也是索引文件==。
当建表语句中指定了主键，自然是以上面的主键索引的形式建立聚簇索引。若表没有定义主键，则使用表定义中的第一个非空唯一字段列作为索引列构建聚簇索引。若还是没有这样的列，则存储引擎会创建隐藏row-id作为依据，建立聚簇索引。

我们知道，走不走索引根据where条件而定。这就会发生，走非聚簇索引找到数据后，发现要select的列不在索引列中。此时就要发生回表。即拿着找到的那行数据的主键，再次查询聚簇索引，聚簇索引含有所有列的信息，所以一定可以找出来。上述过程就叫回表。

## 索引覆盖、索引下推

### 索引覆盖

是指走非聚簇索引时，恰好要select的列全都在索引列中。自然，此时就犯不着回表，直接取出数据即可。

### 索引下推

是MySQL5.6版本带来的一个走联合索引时的优化。假设我们有一个表中有字段`name, age, gender`，并且在这三个字段上我建立了联合索引。

这里还有一个前情提要，就是MySQL的系统架构。一个请求发到MySQL，其实是发到了其最外层的服务层，然后服务层做的事是先查缓存看有没有缓存结果，然后进行SQL语法解析，进行预处理，进行SQL优化，制定执行计划。最后将计划交给引擎层去处理。而引擎层才是去和磁盘上的数据文件打交道的，整体图示如下：

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wNi10dC5ieXRlaW1nLmNvbS9vcmlnaW4vcGdjLWltYWdlLzA3NjZmYjE3YjNkZjQ0ZWZhZjIwMTYxNTJkZGNjNTIz?x-oss-process=image/format,png" style="zoom:50%;" />

总之，MySQL的架构从上至下大概是`客户端 → 服务层 → 引擎 → 数据`这么一个关系。

在没有索引下推优化前，比如运行一个`select * from table where name='a' and age=1 and gender='m';`这么一个SQL时，其原理是服务层只将第一个条件`name='a'`抽取出来交给引擎层。引擎会从数据中过滤出所有`name == 'a'`的记录返回给服务层。然后服务层在内部根据后两个where条件进行进一步过滤。最终返回。

==换言之，没有索引下推的话，联合索引和单列索引性能上没有什么差。这当然不是我们希望看到的。引入索引下推后，服务层可以直接将多个条件全部传递给引擎，从而在引擎层面直接完成筛选==。更具体的，引擎是走到索引，因此可以非常快地完成筛选并返回结果给服务层。
所以说，引入索引下推后，整体走索引时的效率提高了。

因为这个优化，将要走索引的字段全部下沉到了引擎层，所以称之为索引下推。


# 索引泛泛谈
## 两个引擎与索引间的联系

打开MySQL的数据文件存放位置，你可以看到表以数据文件的形式存在于此。

对于InnoDB引擎，会有大量的`表名.frm`和`表名.ibd`文件。其中前者保存的表的结构信息，后者保存的是InnoDB中一张表的主键索引，并且是一个聚簇索引，所以所有数据都被存放在了索引B+树的叶子中。
在这种概念下，表就是索引（聚簇主键索引），索引就是表。所以从非聚簇索引上取不到数据，而返回主键索引取的过程叫做回表。

对于MyISAM引擎而言，同样的位置你可以看到`表名.frm`、`表名.MYD`和`表名.MYI`文件。第一个仍然是结构，第二个保存表的数据，第三个保存表的索引。即MyISAM中，索引与数据分开文件存放。MyISAM虽然也用B+树实现索引，但是索引中的叶子节点里，装的不是实在数据，而是相关数据的地址。
换言之，MyISAM的索引是一个非聚簇索引。

## 索引优缺点

优点：
- 加快检索速度（废话）
- 将随机IO改为顺序IO（因为B+树的叶子节点彼此双向连接）
- 加速表与表的联结操作

缺点：
- 需要额外的空间存储索引
- 对写操作来说需要额外的时间更新索引

## 索引分类
从底层数据结构将，索引可以分成哈希索引，B+树索引，R树索引（比较适合地理数据存储，不常用）。
从对数据的作用范围来讲可以分成主键索引、组合索引、唯一索引、全文索引、普通索引等。

## 聚簇索引和非聚簇索引
两者区别在于，==聚簇索引将完整数据放在索引的叶子节点即数据页中存储，树的叶子节点保留了完整的数据行信息。
非聚簇索引不将或者只将部分数据列和主键存放在索引的叶子节点中==。树的叶子节点保留一部分数据行信息，因此如果想要知道更完整的数据行信息，需要回表。

在主键上建立的索引称为主索引。主索引默认是聚簇索引。
在非主键上建立的索引为辅助索引。辅助索引默认是非聚簇索引。
因此走辅助索引检索时，若想要的数据没有存在索引的数据页中，则需要先走一遍辅助索引找到主键，再走一遍主索引，依据主键找到数据行。而后半操作，就是回表了。

## 不适用索引的场景
- 表不太大时，有时候全表扫描比走索引更快
- 对于过大的表，维护索引也很费力，应该考虑分库分表
- 如果写操作多余检索，则索引是吃力不讨好

## 创建、删除索引的具体语句
有多种创建方法，比如
```sql
-- 使用CREATE INDEX
CREATE INDEX index_name ON table_name (column_list);
```

```sql
-- 在CREATE TABLE时就创建
CREATE TABLE user(
    id INT PRIMARY KEY,
    information TEXT,
    FULLTEXT KEY (information)
);
```

```sql
-- 使用ALTER TABLE在现有表上创建索引
ALTER TABLE table_name ADD INDEX index_name (column_list);
```

删除索引如下：
```sql
ALTER TABLE table_name DROP KEY index_name;
```

## ⭐️索引的最左匹配原则
> 参考在这个页面（https://www.nowcoder.com/discuss/637486）上搜索最左匹配原则

最左匹配原则，用一个例子来解释。假设我们创建了一个表，包含了`id, name, age, gender`和一些其他字段。随后我们在`name, age, gender`上按顺序建立了组合索引。接下来，下面的一些SQL，有些可以走索引，有些走不了索引：

下面这些SQL是走了索引的

```sql
SELECT * FROM t WHERE name='zhangsan';
SELECT * FROM t WHERE name='zhangsan' AND age=18;
SELECT * FROM t WHERE name='zhangsan' AND age=18 AND gender=0;
SELECT * FROM t WHERE age=18 AND name='zhangsan';
SELECT * FROM t WHERE name='zhangsan' AND age > 18;
SELECT * FROM t WHERE name like 'zhang%';
```

下面这些则是没能走索引的：

```sql
SELECT * FROM t WHERE age=18;
SELECT * FROM t WHERE age=18 AND gender=0;
SELECT * FROM t WHERE name='zhangsan' AND gender=0;
SELECT * FROM t WHERE name='zhangsan' AND age > 18 AND gender < 1;
SELECT * FROM t WHERE name like '%san';
SELECT * FROM t WHERE name='zhangsan' OR age=18;
```

总结一下，==索引的最左匹配规律是指，当一个表上有a,b,c等列组成的组合索引，使用SELECT语句对相关列进行查询时，WHERE条件经过优化后必须按照a,b,c的顺序从左到右连续的匹配，且最多只能在最后一个判别式中出现一次范围检索==。

能走索引的第1，2，3行都是标准的从左到右连续匹配。第4行虽然不是严格的从左到右，但是MySQL的优化器会对WHERE条件重新排序成从左到右的顺序，因此也是会走索引。第五行虽然有范围查询(`>, <`)，但是大于18相当于只要找到等于18的最后一个就行了，所以本质上和等于18没区别。最后一行like的匹配表达式中通配符不在开头位置，因此没问题。

再来看不能走索引的这些，前三行，即使经过优化器的优化，依然不满足从左到右连续的能匹配name, age, gender，因此不行。第四行有两个不等号，因此不行。第5行则是`%`在开头，所以不行。最后一行，不是全部条件以AND连接的情况，通通不行。

以上说明还存在一个坑，就是当表只有`id, name, age, gender`四个字段时，你会发现，不走索引部分的第一行、第二行等也都是走索引的。这是==因为在没有额外的列的情况下，基于主键建立的聚簇索引和基于`name, age, gender`建立的联合索引本质上是相同的（都保存了每列数据）。因为一些原因，不知道为啥就是可以走索引，暂且记住，当联合索引本质上和主键聚簇索引一样时，是特殊情况。这也是看似索引无效，实际索引有效的例子==。

## 索引在哪些情况下无效
- 原SQL不符合最左匹配原则
- 条件中带有or
- 对索引相关列进行计算或者任何函数处理
- 对索引相关列进行任何隐式数据类型转换
- 字符串匹配时以%开头的匹配模式
- 使用!=, <>, is null, is not null等符号判断

## 走查索引过程中的几个名词

回表：当前SQL给出的条件决定了走什么索引。而如果所选列中有部分没有被这个索引覆盖，那么就需要进行回表，回到聚簇索引以获取完整的数据。

索引覆盖：当前SQL走的索引恰好覆盖了所选列，因此直接走一遍索引即可，无需回表。这个就叫发生了索引覆盖。

索引的最左匹配原则：见上面说明

索引的选择性：指建立索引的时候，应该尽量选择值的区分度大的列。比如80%的值都是唯一值的。这是很好理解的。因为走索引本质上是一个二分查找的过程，如果有很多很多同值记录，那么二分查找要找到具体例子就只能在同值区间内挨个遍历了。区分度越大，我们就说索引选择性越大，索引也就越有效。


# 事务相关

## ⭐️⭐️事务的ACID四大特性
- 原子性 (Atomic)：事务中包含的操作要么全部执行，要么全部回滚
- 一致性 (Consistent)：事务执行前和执行后，无论成功与否，数据库内数据都是满足一致性的。
这点有点抽象，可以类比银行转账。A，B账户分别有800，200元。此时是初始化状态默认满足一致性。
A发起转账200到B，于是执行这个事务。这个事务包括A-200和B+200两个操作。
两个操作完成后，事务完成。此时A，B分别有600，400元。加起来仍然是1000，与原来一致。说明仍然满足一致性。
相反如果出账成功并且入账失败，总金额数与原来不一致，就不满足一致性了。
- 隔离性 (Isolated)：若多个事务并行运行，某个事务发起的改变在最终生效之前，其做的改动对其他事务是不可见的。
这样避免了多事务同时执行时起冲突。
事务隔离有各种不同的级别。设置级别不同，隔离性的强度自然也不同。
- 持久性 (Durable)：事务一旦提交，其做的改变将永久保存于数据库中，不应该因为任何原因比如突然宕机之后而看到的是修改前的数据。

### ⭐️四大特性的实现方式

- 原子性

  ```
  依靠MVCC机制下的undo log进行实现。undo log是指数据库中一部分引擎维护的内存空间。这片内存空间中，保存着事务开始以来所有被更改过数据的历史版本。每一行数据的回滚指针都指向其前一个版本。通过回滚整个历史，可以保证事务的原子性。
  ```

- 隔离性

  ```
  如上所述，依靠事务的隔离机制实现。隔离机制与相关隔离级别见下节。
  ```

- 持久性

  ```
  依靠MVCC机制下的redo log实现。关于redo log的说明写在了后面的章节中。
  ```

- 一致性

  ```
  从本质上来说，一致性描述是最抽象的，也是我们的终极目的：保证数据不出错。
  因此，可以认为在实现原子性、隔离性、持久性的基础上，我们才/就能实现一致性。这是从数据库实现机制的层面上来说的。
  但仅仅这样还不够，从应用层面上来说，我们需要在应用代码中也写足够的逻辑校验代码，从而实现数据的一致有效。
  ```


## ⭐️⭐️事务隔离级别
从低到高依次为：
- 未提交读（Read Uncomitted, RU）：即使事务A提交前，其修改对事务B可见。这也相当于没有任何隔离

- 提交读（Read Committed, RC）：只有事务A提交后，其修改才对事务B可见。

- 可重复读 (Repeatable Read, RR)：在事务B的生命周期内，一切读的结果都遵照第一次读到的结果，即A提交前的老版本。
因为解决了A提交前后读两次会数据不一致的问题，所以这个级别也叫"可重复读"。

- 串行化：最高级别，将所有事务串行化执行。能够杜绝所有因为并行发生的问题，但是效率低。

## ⭐️⭐️事务并发一致性问题与隔离级别的关系
事务并发时，由于一致性可能会产生如下问题：
- 脏读：A事务修改后B事务读到修改后的数据，而后A事务回滚了。导致B事务读到的是脏数据。
- 不可重复读：A事务修改数据时，修改前B事务读到一个值，修改后B事务又可以读到一个值。两个值不一致的问题成为不可重复读。
- 幻读：A事务试图插入一行新数据或者删除数据时，在RC隔离级别下操作前后B事务分别会可以读到两批不一致的数据，在RR级别下操作前后虽然能读到一致的数据（与ReadView生成时机相关，参考下方MVCC节），但是如果进行写操作，此时要进行当前读，读到最新的数据，此时就和读到的数据行数不匹配。总之不管在RC还是RR下，都存在幻读的问题。==而在RR下，只有当操作有快照读也有当前读的时候，才会发生幻读问题==。

上面提到的事务隔离级别从低到高，可以逐渐解决这几个问题。具体的对应关系是这样的：

| 隔离级别            | 可解决问题             |
| ------------------- | ---------------------- |
| 未提交读（RU）      | 无                     |
| 已提交读（RC）      | 脏读                   |
| 可重复读（RR)       | 脏读、不可重复读       |
| 串行化（SERIALIZE） | 脏读、不可重复读、幻读 |

默认情况下，InnoDB的隔离级别是可重复读。

四个级别中，已提交读和可重复读可以通过MVCC实现。串行化可以通过锁实现。

查看当前数据库的事务隔离级别命令是：
```sql
SELECT @@tx_isolation;
```
设置事务隔离级别的命令是：
```sql
SET TRANSACTION ISOLATION LEVEL xxx;
```

## ⭐️⭐️MVCC

> https://www.zhihu.com/question/263820564/answer/289269082

MVCC全称多版本并发控制。上面提到了，数据库总共有四种隔离级别，其中RU和串行化与MVCC不兼容。MVCC机制只在RC和RR下工作。并且，通过MVCC控制一些读写数据的细节，可以实现RC和RR两种隔离级别。
MVCC具体还牵扯到很多实体。下面来从头捋一下。

#### 数据行的隐藏字段、undo log

首先我们要知道，对于MySQL中的一行数据，除了我们定义的字段以外，还有不少不可见的内建字段。这些字段大概包括了`row_id`，`事务id`，`回滚指针`。

> 顺便一提，MySQL规定每一行数据必须有一个标识id。当有主键的时候，当然可以利用主键作为这个id，当没有主键时，MySQL寻找具有唯一值的列作为标识，如果连唯一值的列都没有，那么就自动生成一个6位的`row_id`，就是这里说的这个了。

`事务id`字段记录的，是最后一个对本行做出修改的事务的ID。（每个事务在开始时都会被分配一个ID，且全局递增，越早开始的事务ID越小）

`回滚指针`则是指向一个地址。每发生一次数据变动，在事务没提交之前，所有的历史数据不会丢失而是会保留下来，被保存在undolog中。而更新后的数据的回滚指针，就会指向其前一个版本的历史数据。直到事务提交后，所有历史版本数据会被清空。

以上提到的undo log，就是MVCC机制的核心内容。由于undo log对数据的多个版本进行了记录，可以借此层层回溯回滚，==因此还可以说，有了undo log就可以实现原子性==。

#### 当前读和快照读和ReadView

当某个事务尝试读取数据时，可以分成两种模式，当前读和快照读。==当前读是指事务先对相应记录加锁，然后读取数据的行为。而快照读指不加锁读取某个时刻生成的快照中的数据，可以理解为快照读读的是数据的某个历史版本，即undo log；当前读读的就是最新数据==。

既然快照读要读取数据的历史版本，那么问题来了，到底读取哪个历史版本呢？==简单的回答是，事务会在某个时间点生成一个叫做ReadView的东西作为快照读依据，读取正确的历史版本==。
ReadView是包含了事务层面一些信息的视图。包括了如下信息

- 创建该ReadView的事务自身ID `creator_trx_id`
- ReadView生成时所有还活跃着的，即开启但还未提交的所有事务ID `m_ids`。显然这是个列表。
- `m_ids`中最小的事务ID `up_limit_id`（记得别把这个up和下面的low记反了）
- 下一个尚未分配的事务ID `low_limit_id`
- ...

当事务A尝试读取某数据的历史版本时，MVCC会将数据的`事务id`字段拿出来，与ReadView中的信息做比较。比较规则如下：

```python
if trx_id == creator_trx_id: return True    # 当前事务自己修改出该历史版本，自己的嘛，肯定可见
elif trx_id < up_limit_id: return True    # ReadView生成时，修改出该历史版本的事务早已提交
elif trx_id >= low_limit_id: return False    # ReadView生成时，修改出该历史版本的事务尚未创建
elif trx_id in m_ids: return False    # ReadView生成时，修改出该历史版本的事务正在运行，尚未提交
elif trx_id not in m_ids: return True    # ReadView生成时，修改出该历史版本的事务已经提交
```

上述规则中，返回True的情况表示事务A可以读取到该历史版本数据，即可见的。
返回False的情况表示事务A无法读取到该历史版本数据，表示不可见。

那么MVCC凭借着ReadView到底如何实现了两种隔离级别？

#### 基于MVCC的隔离级别实现

==MVCC通过设定不同的ReadView生成时机，来区别RC和RR这两种隔离级别==。

在一个读取数据的事务中，如果设定其ReadView只在第一次快照读时就生成，并且之后在事务的整个生命周期中一直使用，那么就是可重复读（RR）级别的。
相当于第一次生成ReadView时就冻结了数据库，之后其他事务不论怎么修改，提交数据，对于本事务来说都不可见了。因此本事务可以“可重复”地读数据。

若每次快照读时，都重新生成一次ReadView，那么这个事务每次都能读到其可见的最新数据，所以是“读已提交”（RC）级别的。

#### MVCC与幻读

RR级别下，MVCC设置的ReadView生成时机如上所述，是第一次快照读的时候。
==当事务只有快照读没有当前读时，由于数据都被“冻结”了，新增/减少数据记录对发起快照读的事务也不可见，所以MVCC还顺带解决了幻读问题。==

当然上述情况只适用于 只有快照读 的情况。当事务需要当前读时，就不可避免地去读取最新数据，从而会发现数据新增/删除的矛盾了。

## MySQL三个主要日志

MySQL中其实存在六种日志，分别是：

```
binlog, redo log, undo log, errorlog, slow query log, relay log
```

其中前三种与MySQL的事务机制息息相关，慢日志则是性能分析时常用的，relay log主要和主从复制有关。这节主要讲讲前三种和事务相关的日志，也是面试中高频出现的。

### binlog

可以认为binlog记录的就是各种写操作SQL语句的反操作SQL，因为记录的是SQL文本而不是数据库物理页面的变化信息，所以认为binlog是一个逻辑日志而非物理日志。从维护主体的角度来说，其是整个数据库层面的一个“大综合”日志。

因为其记录了所有操作的反操作，自然沿着这些反向操作一步步回溯的话，就可以将数据库回溯到某个特定时间点的状态。
另一方面，也是因为其记录了所有操作，所以可以在主从复制方面发挥作用。当主服务器改写了数据后，从服务器只要读取binlog就可以完全复现这些操作。
这也是binlog两个主要的作用。

binlog在事务提交时进行更新。因此当事务比较大，涉及到的修改操作较多时，binlog的更新会导致提交的速度变慢。

### redo log

redo log经常和binlog搞混。因为redo log记录的内容也是各种写操作。但是redo log和binlog有两个很大的区别。

==第一，redo log记录的不是SQL文本而是物理页面的修改信息，因此redo log从分类上来说是物理日志。==
==第二，redo log的更新时间点是事务开始后。即当事务开始后每做一次写操作，redo log就会被更新一次。相对的binlog要等到事务提交才更新。==

由于第二点差别，redo log的作用主要是保证事务的持久性。当事务进行到一半，因为突发情况服务器重启之类的，为了保证事务的持久性，重启后可以读取redo log并恢复其中的内容来保证之前的写入仍然有效。

此外，因为redo log主要是为了保持持久性，当事务提交，写操作落地后，其就没有存在的必要了。因此可以说redo log是一个事务层面的日志。

#### redo log的刷盘时机

关于redo log一个很重要的知识点是什么时候进行redo log的写入。上面说过，redo log在事务开始之后就开始被更新。但是不可能真的操作一行数据就更新一次，那样太费IO了。通常，redo log的刷盘时机有下面三种

- 数据库本身会每隔一段时间主动发起一次刷盘
- 事务提交时也会进行一次刷盘
- log写入肯定有缓存，当redo log的写入缓存空余空间不足一半时，也会进行一次刷盘

### undo log

undo log中保存的是事务范围内行单位的历史数据。其格式也是SQL语句所以其是逻辑日志。
因为保存了历史数据，所以其主要作用是提供回滚的依据；同时也是MVCC中快照读的数据来源。

和redo log类似的，undo log也是事务层面的日志。并且其更新时机和redo log也差不多，都是事务内操作完成后更新，而不等到事务提交。另外undo log要生成完整的历史记录，所以在事务开始前，undo log就首先将现有的数据作为最初的历史记录写进日志了。

事务提交后，似乎就不用undo log来提供历史数据了。但是考虑到本事务提交后可能还有其他事务在进行数据的快照读，所以提交后并不直接删除undo log，而是将其放到保留区，并由purge线程检查是否其还在被其他事务使用。确认没人使用后再删除。

### 三种日志的对比

|            | binlog                               | redo log                       | undo log                               |
| ---------- | ------------------------------------ | ------------------------------ | -------------------------------------- |
| ==层面==   | 数据库层                             | 事务层                         | 事务层                                 |
| 内容与格式 | 写操作与其反操作记录，逻辑日志       | 写操作（后的物理页），物理日志 | 历史数据，逻辑日志                     |
| 作用       | 基于时间点的数据复原<br />主从复制   | 重写，保证事务持久性           | 回滚 & 快照读，保证事务的原子性        |
| 更新时机   | 事务提交时                           | 事务开始后（还需注意刷盘时机） | 事务开始前                             |
| 释放时机   | 参数`expire_logs_days`确定的过期时间 | 事务提交后数据落地             | 事务提交后确认无其他事务使用本undo log |
| 存放位置   | 参数`log_bin_basename`指定           | 数据库data目录下的ib_logfile   | MySQL的共享表空间中，即数据文件内部    |

> 关于binlog和redo log的区别
>
> 再来仔细看看这个问题。两者虽然都是记录“进行了什么写操作”这方面的内容。但是两者的区别主要在于：
> 日志格式，一个是逻辑日志，一个是物理日志。
> 更新时机，一个在事务提交时更新，一个在事务开始后就更新
> binlog是泛泛的数据库层日志，并不关心某个具体事务执行得怎么样；redo log关心某个具体的事务，并且要保证其持久性
> 两者虽然都有泛泛的“恢复数据”的功能，但是由于格式不同，基于物理日志的恢复效率比逻辑日志高得多。


# MySQL锁
当数据库有并发事务的时候，保证数据访问顺序的机制就是锁机制。

默认情况下，事务可以在其中某个地方对某个数据进行加锁操作（比如`for update`子句就是对UPDATE操作的加锁，具体可百度）
当事务COMMIT的时候自动将锁解锁。

## 锁的分类
### 按粒度分类
按照不同标准有不同的分类方法。比如以锁的粒度从精细到粗放，可以分为行锁、页面锁、表锁等。当然，粒度越精细，需要耗费的资源就更多，加锁速度也会越慢。
MyISAM默认使用表级锁，而InnoDB默认使用行级锁。

行级锁还可以细分为记录锁（即一般意义上的行锁）、间隙锁（对第一条记录前或者最后一条记录后的间隙加锁）、next-key锁（前两者组合，既锁一个记录，也锁一个记录之前的间隙）。

==需要注意，试图上行级锁时通常要根据索引对要上锁的行明确做出限制。
若没有限制条件，那么会将所有行都上锁，即行级锁会退化成表级锁。==

### 按性质分类
按照锁的性质分类，大致可以分成共享锁和排他锁。
这两种锁又分别称为读锁（S锁）和写锁（X锁）。

顾名思义，当事务要对数据对象进行读操作的时候，对其上S锁。
某个数据被上了S锁之后，仍然接受其他事务的S锁请求（即可以多事务同时读），但是会拒绝其他事务的X锁请求。
另一方面，当事务要对数据对象进行写操作的时候，对其上X锁。某个数据上了X锁后，会拒绝其他事务的任何锁请求。

即整体的兼容情况如下表：

| |请求读锁|请求写锁|
|---|---|---|
|当前读锁|可|不可|
|当前写锁|不可|不可|

## 意向锁
==行锁存在这么一个问题：如果事务A想要给某表加X锁，自然就需要检查有没有其他事务已经持有该表（任意一行）的S或X锁。
此时要针对每一行都扫描一遍，效率太差。这个问题通过加设意向锁解决。==
InnoDB内部还设置了两个意向锁，分别是意向读锁（IS）和意向写锁（IX）。
这两种锁都是表锁。InnoDB规定，任何事务想要给某行加S锁时必须先获取IS锁；想要给某行加X锁时必须先获取IX锁。

这样，在上述情况中，当A试图加X锁时，只需要查看该表有没有其他事务有IS或者IX锁就可以了。
扩张了两种意向锁后，当前锁和请求锁之间的兼容关系如下：

|当前锁↓  请求锁→|X|IX|S|IS|
|---|---|---|---|---|
|X|否|否|否|否|
|IX|否|是|否|是|
|S|否|否|是|是|
|IS|否|是|是|是|

## InnoDB的默认锁
InnoDB的默认锁有两个特点。==第一，是行锁。第二，其上锁对象不是数据，而是索引==。
若没有显式建立的索引，则通过隐藏的`row_id`字段的聚簇索引来进行加锁。

另外，==如果检索数据的SQL不走索引，MySQL就无法在索引中对相应的记录上锁。为了安全，MySQL还是会对表中所有行都上锁==。效果上来说就和上表锁一样了。

## 乐观锁和悲观锁
首先应当明确，乐观锁和悲观锁并不是狭义上的锁的分类。而是广义上的，防止数据冲突的两种不同的并发控制机制。所以更加合理的称呼应该是“乐观并发控制机制”与“悲观并发控制机制”。不过为了方便，下文中还是以锁称呼这两个概念。

悲观锁，顾名思义，考虑最坏的情况，即每次访问数据（包括读和写）时数据都是不稳定的。为了避免这种情况，悲观锁机制要求任何数据访问者在访问前必须获得锁。
上面提到的所有MySQL中的锁（狭义的锁）都属于悲观锁范畴。

乐观锁，反过来，考虑最好的情况。即每次访问数据时，默认数据是稳定的。如果访问数据是指修改数据的写操作，那么乐观锁会在提交的时候最后进行一次数据一致性检查。
乐观锁通常通过版本号与CAS算法等外部机制实现，与狭义上的MySQL的锁并无太大关系。

==悲观锁控制不出错的效果更好，但降低了运行效率。悲观锁还有可能引起死锁。悲观锁适用于写比较多的场景。
乐观锁则相反，如果所有事务都是读数据的话，那么乐观锁是可行的。乐观锁适用于读多写少的场景==。

### 乐观锁实现 CAS+版本号

乐观锁主要有CAS和版本号两种实现方式。这里主要讲CAS。
CAS全称Compare and Swap，是一种实现乐观锁的算法。

CAS的基本思想是这样的：==当多个线程对某个资源进行并发写操作时，针对一个特定线程，在其开始任何操作前先记录当前内存中的值`V`，当要对该值做出修改时检查当前值`E`。仅当`V == E`时，才将`E`修改为新的值`U`==。

CAS有一个问题。我们利用CAS机制是为了让一个线程写资源时保证该资源没有受到过篡改。“篡改”二字有深层次的意义。它既可以指单纯值是否有改动（此时CAS没问题），也可以只改动这个动作是否有发生。
换言之，如果线程一先读取到预存值`V`，然后线程二快速地将`V`改成其他值后又改回`V`，此时线程一再来读取，发现`V`没有变，其是否可以提交要做的修改呢？这就是CAS算法存在的ABA问题。

==ABA问题根源在于，对值的修改是自由任意的。因此可以通过给值加上一个版本号，每修改一次版本号自增。这个版本号的修改是单向的，因此线程一不用看值是否变更，只要看版本号是否变更即可。这就解决了ABA问题==。

### 悲观锁实现

悲观锁就是狭义上的锁。如果被问到悲观锁的实现，那么可以从下面这几个角度来说：

第一，从编写SQL的层面来说，可以使用`select ... for update`语句手动给某数据上锁。

第二，从锁的层级来说，悲观锁（或者说狭义上的锁）能上行锁则上行锁，如果无法明确则上表锁。至于能不能上表锁，主要看定位数据有没有走索引。
比如`update table set xxx where field=x`和`update table set xxx where id=x`。乍一看没什么区别，但是后者的where条件是与主键相关的，导致这条SQL会走索引，因此走完索引后直接给相关索引项上锁，是行锁；而前者不走索引，只能全表扫，因此只能上表锁。

第三，从数据范围来说，锁其实只是记录了索引中的索引项，或者说将索引项上锁了。



## 死锁
设想事务A和B分别对数据X和Y进行操作。
第一步，A和B分别对X和Y进行写操作，于是A获得X的写锁，B获得Y的写锁。
第二部，A和B分别对Y和X进行读操作，于是他们会尝试去获得相应数据的读锁。但是我们知道，这两个数据已经被上了写锁，
于是此时A为了获取对Y的读锁，而被阻塞。然而要想打破阻塞，B必须放开对Y的写锁，可这个操作的前提就是A要放开对X的写锁。而A此时被阻塞。

因此进入了死循环，形成了死锁。

防止死锁的策略大概有如下：
- 尽量让多个事务以同样的顺序存取数据
- 尽量使用索引访问数据，使用行锁，不使用表锁，通过精细粒度的访问控制防止死锁等。


# MySQL集群相关

在MySQL分布式集群中常常被问到以下几个领域的概念。主从复制、读写分离、分库分表等。

## ⭐️主从复制

主从复制是指分布式的情况下，为了保证主从服务器的数据一致性，当向主服务器插入数据后，从服务器将自动从主服务器上同步数据过来。

MySQL主从复制涉及主从服务器上共三个线程实体：==binlog线程、IO线程、SQL线程==。
整体流程是这样的：

1. 主服务器上数据发生改变，其binlog线程将相关改变写入binlog中
2. 从服务器的IO线程连接主服务器并且将binlog的变动读取出来，写入本地的中继日志（relay log）中
3. 从服务器的SQL线程读取中继日志，解析出主服务器上做的改动，并且将其Update到本服务器的分库中。
4. 第3步操作导致从服务器的binlog也发生相同变化，因此另一台从服务器此时不仅可以去同步主服务器，也可以来同步这台从服务器。

上述流程的著名图示如下：

![在这里插入图片描述](https://uploadfiles.nowcoder.com/files/20210411/115285789_1618134217150/20210121201012972.jpg)

主从复制的作用是

- 高可用和故障转移
- 负载均衡
- 数据备份
- 升级测试

### 主从复制延时问题

主从复制经常会发生延时问题。延时问题是指从服务器总是花费过长时间才能向主服务器同步到数据。
引起这个问题的原因可能是多方面的。比如最显而易见的，是主从服务器毕竟是两台服务器，需要通过网络连接，网络出问题了那么主从复制肯定出问题。除此之外，还可以考虑机器性能的问题。

比如主从服务器配置差距过大，那么从服务器肯定就跟不上主服务器的节奏导致延时；
比如从服务器通常是读服务器，如果有大量读请求需要处理，也会导致从服务器来不及进行数据同步；
比如大事务执行，在主服务器上事务本身就执行了较长时间，而binlog的写入必须等事务结束，所以从服务器上要干等待这段时间导致延迟；

除了上述原因外，还可以分析图中的流程。主服务器binlog thread写binlog，从服务器io thread读到binlog，从服务器io thread写relay log，从服务器sql thread读relay log，这四个流程，都是对日志的读写。而对日志的读写，从原理上来说就是顺序读写，因此并不太耗时。

==真正耗时的地方，在于从服务器的sql thread写入数据库的操作。==根据具体SQL语句不同，写的效率也有所差别，但是无论是怎么样的语句，对数据库的写肯定涉及到寻址操作，因此一定是随机写。这么一来，这也就成了整个流程唯一可能拖后腿的地方。在稍微老一点的MySQL中，sql thread只有一个，若主服务器更新数据TPS非常高，则可能会导致从服务器上单个线程反应不及时，导致延迟。

在MySQL5.7及以后版本中，允许sql thread的多线程。但是由于线程之间的执行顺序是随机的，有可能无法按照主库中的顺序挨个执行数据变更，导致数据不一致。所以在sql thread和relay log之间，MySQL额外设置了一个coordinator，由其维护一系列规则，基于规则进行数据的同步，保证数据一致性。

### 三种复制类型与主机Commit（返回数据）的时机

> https://www.cnblogs.com/bigox/p/11530540.html

上述主从复制过程中，还有一个小细节可以确认，即当客户端请求发到主服务器并执行后，主服务器会在什么时机进行响应或者说数据的返回。（有些人也将其称为Commit时机，但是binlog是commit之后才会更新，而主从复制又是基于binlog的变化的，所以说这里讨论的说他是commit时机，其实是不正确的。

对于单机情况，这个没什么可说的，写完提交完，直接返回就完事了。
然而在主从复制场景下，我们知道提交完后binlog会变化，而从库会来复制这些变化。这时就会分成下列三种复制类型。

#### 异步复制

异步复制也是默认情况。到达上述时间点时，主库不管从库的复制进度与情况，直接返回客户端数据。相当于响应客户端和从库同步这两个工作完全异步。

#### 全同步复制

异步复制的对立面就是全同步复制。当binlog改变后所有从库都来同步，期间所有主库阻塞住返回客户端数据，只有所有从库都明确返回同步成功的信号（IO线程完成了relay log的同步，然后返回主库消息），主库再返回客户端。

可以预见，全同步复制的效率比较低，作为客户端来说的感受就是等待请求返回数据要等很久。但是另一方面，这也是最保守稳妥的方案，确保了主从库的数据总是完全同步的。

#### 半同步复制

顾名思义，半同步复制介于上面说过的两者之间。
具体来说，半同步复制固定主库收到一个从库发来的，开始写relay log的信号即认为OK，返回客户端数据。
注意，和全同步相比，==这里有两点不同，第一，只要一个从库有反应即可；第二，从库的反应也不是“我写完了relay log”，而是“我开始写relay log”。==

## 读写分离是什么

读写分离依赖于主从复制的分布式机制。

主服务器负责写，从服务器负责读，从而降低了锁的竞争。
==从服务器因为不用写，所以引擎可以使用诸如无事务机制的MyISAM等。这类引擎的开销更小，帮助提升查询性能。==
另外主从复制架构本来就加强了系统整体可用性。


# MySQL零碎内容

>参考1：https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/MySQL.md
>
>参考2: https://mp.weixin.qq.com/s/IiJYHoAxqTnqW0LfRAh2BQ
>
>索引：https://zhuanlan.zhihu.com/p/352181863
>
>参考（2021/06/26追加）：https://www.nowcoder.com/discuss/637486

## MySQL的存储引擎有哪些，区别是什么
MySQL支持很多存储引擎。主要比较InnoDB和MyISAM。
可以在终端中键入`show engines;`查看。两者的区别主要包括了

|              | InnoDB                             | MyISAM                         |
| ------------ | ---------------------------------- | ------------------------------ |
| 事务         | 支持                               | 不支持                         |
| 外键         | 支持                               | 不支持                         |
| 锁级别       | 行级锁                             | 表级锁                         |
| 组织形式     | 聚簇索引（索引和数据放一个文件里） | 非聚簇索引（索引和数据分开放） |
| FULLTEXT索引 | 不支持                             | 支持                           |

## MySQL常用数据类型
- 整数：INT, BIGINT分别标识32、64位整数
- 浮点数：FLOAT，DOUBLE，DECIMAL。其中DECIMAL基于字符串处理，能存储更加精确的小数。
三者都可以指定位长如`DECIMAL(a,b)`表示总共用a位表示浮点数，其中b位保存小数部分。

- 字符串：CHAR, VARCHAR。VARCHAR可变长，更灵活但更耗费空间。==CHAR更适合内容变更频繁的，或者普遍很短的字段，这样可以减少内存碎片。==
- 日期：DATE，DATETIME等

## MySQL收到请求后的处理流程
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9wNi10dC5ieXRlaW1nLmNvbS9vcmlnaW4vcGdjLWltYWdlLzA3NjZmYjE3YjNkZjQ0ZWZhZjIwMTYxNTJkZGNjNTIz?x-oss-process=image/format,png)

## SQL语句基础知识与优化
### SQL语句主要分类
- DDL(Data Definition Language)语句: CREATE, DROP, ALTER等
- DQL(Data Query Language)语句: 主要是SELECT
- DML(Data Manipulation Language)语句：主要指INSERT, DELETE, UPDATE
- DCL(Data Control Language)语句：指权限功能相关比如GRANT, REVOKE, COMMIT, ROLLBACK等。

### SQL约束有哪些
主键约束、外键约束：略
唯一约束：要求保证每列数据没有相同的值
默认约束：插入新数据时对没有指定数据的列设置为默认值或者默认的默认值NULL
check约束：check通过逻辑表达式判断数据有效性并以此为约束

### 子查询
子查询可以分成下面几种：

标量子查询：指子查询返回的结果是一个值，可以通过各类运算符与之运算如：
```sql
SELECT * FROM user WHERE age = (SELECT Max(age) FROM all_users);
```

列子查询：指子查询返回的是一个列，通常可以用IN, ALL, ANY等操作符与之进行计算如：
```sql
SELECT * FROM user WHERE name IN (SELECT name FROM all_users);
```

行子查询：指子查询返回的是一个行，此时通常用元组等式来判断如
```sql
SELECT * FROM user WHERE (name, age) = (SELECT name, age FROM all_users WHERE id=1);
```

表子查询：子查询返回一个多行多列的子表（临时表），这里也可以用元组IN来做判断如：
```sql
SELECT * FROM user WHERE (name, age) IN (SELECT name,age FROM all_users WHERE age>=10);
```

### 联结的种类
联结包括内联结，左右外联结，全外联结和交叉联结。
根据是否表与自身联结还可以分化出一个自联结的概念。当然自联结和上面这些联结分类并不处于同一个概念维度。
其中MySQL不支持全外联结。

假如我们有这两张表：
表L:
```text
A   B
a1  b1
a2  b2
a3  b3
```
表R:
```text
B   C
b1  c1
b2  c2
b4  c4
```

则内联结：`SELECT L.*, R.* FROM L JOIN R ON L.B=R.B;` 得到：
```text
A   B   B   C
a1  b1  b1  c1
a2  b2  b2  c2
```

左外联结：`SELECT L.*, R.* FROM L LEFT JOIN R ON L.B=R.B;`。得到(N表示NULL)
```text
A   B   B   C
a1  b1  b1  c1
a2  b2  b2  c2
a3  b3  N   N
```
右外联结就是R表在前的左连接，相当于只有b4 c4没有a3 b3的情况，就不重复写了。

交叉联结：`SELECT L.*, R.* FROM L, R;`不带任何限定条件，因此相当于把A的每一行和B的每一行配对，做一个笛卡尔积。得到
```text
A   B   B   C
a1  b1  b1  c1
a1  b1  b2  c2
...
a3  b3  b4  c3
```
在这个后面加上限定条件，这其实就变成了简单的内联结。
由于使用交叉联结 + 限定条件的方式，还是会生成一个很大的临时表，所以能用JOIN解决的时候尽量应该用JOIN解决。

### IN和EXISTS的区别
这两个关键字都用于子查询匹配的场景。我们将原表称为外表，而子查询查询的表称为内表。
于是范式大概是`外表字段 IN/EXISTS (内表范围)`。这个语句的原理其实是：

两者区别在于，使用EXISTS时会先进行外表查询，然后将每行代入内表查看是否满足条件。
IN则反过来，先进行子查询确定内表范围，然后再代入外表过滤结果集。

==通常，先确定一个小范围比较有效率，因此外表比内表大的时候，IN更好；反之，外表比内表小的时候EXISTS更好==。

而对于NOT EXISTS，总是比NOT IN要更好。因为NOT EXISTS会用索引而NOT IN只会进行全表扫描。

### varchar和char
varchar可变长，因此体现出两者的优劣性。
因为可变长，varchar更加灵活，且更加节省空间（不会因为字符长度小于指定值而用空格padding）。
但是由于可变长，offset就不管用，因此存储速度上varchar略慢一点。

>补充一点，int(10)和varchar(10)/char(10)有什么区别
>
>这两种定义的根本就不是同一类型的数据。int(10)中的10只是表示显示数据的长度，比如对于1这个数，int(10)显示
>0000000001，而int(3)可能就显示001。两者都是占用4个字节。
>
>而varchar和char则是真的指出了用几位去存储一个数据。

### DROP, DELETE, TRUNCATE
DROP用于删除整个表数据和表结构。
TRUNCATE用于删除整个表数据，但是保留表结构。
==注意这两者都是DDL，所以不能回滚。==

DELETE通常用于行的删除，不加限定条件是也可删除整个表数据，但是一行行删除，比较费时。
==另外DELETE是DML，可以回滚。==

### UNION和UNION ALL
UNION合并结果时去重并排序。
UNION ALL合并结果时直接合并，不去重也不排序。
UNION ALL更快。（废话

### 慢查询，慢查询日志，如何优化
可通过对`slow_query_log`等开启对慢查询日志的记录。
优化思路有
- 查看执行计划，看SQL是否走了索引
- 垂直、水平分库，从根本上解决慢查询
- 优化limit分页

### 主键用自增ID和UUID的优劣
一般使用自增ID即可。
自增ID的好处有
- 字段长度小，比较大小很快
- 可轻松按序存放，方便主键索引的建立

相对的自增ID也有一些缺点，比如
- 通过自增ID可以推测业务量等
- 数据迁移、表合并比较麻烦

总体来说，自增ID还是完胜UUID的

### 为什么某列无值时尽量应该用空值而非NULL
即，为什么列尽量应该设置NOT NULL
- Count等聚合函数不统计NULL值
- 参与字段数值比较时，NULL比较难处理

### 如何优化WHERE子句条件
- 尽量不使用不等于号
- 尽量用UNION ALL代替OR
- 对WHERE或者ORDER BY涉及的列建立索引
- 尽量避免IN或者NOT IN从而引发全表扫描

## 大表的优化策略

### 大表数据查询的优化思路有哪些
- 使用索引
- SQL语句逻辑优化
- 水平/垂直分表
- 使用缓存
- 读写分离
等等

### 什么是垂直/水平分库分表
垂直分表：将原来一个表的字段分成多个表，每个表存储一部分字段。通常将常用字段整到一个表，不常用整另一个。
垂直分表的好处是可以提升热门数据的查询效率，减少IO竞争。因为表内数据都是存在数据页上的。如果一行的字段过多，导致一个数据页能存放的行数就变少，
检索表时要频繁切换数据页等。

垂直分库：类似的，将原来一个库中的各个表部署到不同的数据库，不同的数据库也可以放到不同的服务器上。
垂直分库的好处也是类似的，提升IO效率，降低单机的资源限制

垂直分库分表的劣势：
整体数据上会多出冗余的主键列。
事务处理会变复杂。
仍然会有单表数据过大的问题。


水平分表分库：不解释
水平分库分表的好处是同样，可以减少IO竞争，解决单个表数据量过大问题。
缺点是分片事务的一致性很难保证。跨节点的SQL性能会受到影响。数据扩展难度大，不易维护。

### 分库分表后如何保持主键的全局唯一性
有多种可能的解决方案。
- UUID，用UUID的话基本可以保证全局唯一性。但是UUID的坏处上面也说过。

- 利用额外表自增ID。在分库分表后，在数据库中设立一个全局的用于生成自增ID的表。每当要新生成一个ID时，无论其要插入在哪个分库分表中，
先在这个额外的表中插入一条空数据另其生成一个新ID，然后取这个新ID作为主键再插入分库分表实际数据。

- Redis生成法：用Redis的自增机制生成ID。

## 大数据量分页查询优化case

>https://www.cnblogs.com/gxyandwmm/p/13363100.html

首先明确什么是分页查询。分页查询，就是指用户明确指出我想看第几页的数据。通常会用到LIMIT子句，即`LIMIT page_no * page_len, page_len`。

当数据的量很大时，如下面这个查询：

```sql
SELECT * FROM xxx WHERE num=8 LIMIT 100000, 100;
```

即使在num上建有索引，上述语句还是会比较慢。究其原因，在于LIMIT子句的运行原理。==引擎解析并执行LIMIT子句的逻辑是，从头开始扫描表中符合要求的记录，一共找`100000 + 100`行，然后舍弃掉前面的`100000`行并返回最后的100行作为结果。
再加上取的列又是全列，要进行大量的回表操作，因此很慢==。

现优化如下：

```sql
SELECT * FROM xxx WHERE num=8 AND id >= (
  SELECT id FROM xxx WHERE num=8 LIMIT 100000, 1
) LIMIT 100;
```

上述SQL里面的子查询，注意到查的是主键`id`。==由于`num`上的索引虽然是个非聚簇索引，但是其保有id信息，所以子查询虽然也要构建一个长度为`100000 + 1`的结果集，但是这个结果集无需回表，节省了大量回表操作的时间==。而子查询返回的，是第100000个符合要求(`num == 8`)的结果的id。我要求的数据的id必然都大于这个值，所以外边再接上`id >=`条件，就可以查到想要的结果。

显然，优化后的外查询，只需要构建长度为100的结果集，即使回表，也无所谓了。

## SQL语句执行很慢的原因可能有什么

最简单的原因，当然是当前服务器很忙，难以分出资源执行SQL。或者是网络方面的原因。
考虑深一点，可能是执行遇到了锁，而不得不等待。
再深一点，还有可能恰好碰到了redo log刷盘，因此也要等待。

上述都是偶尔很慢的情况，如果某条SQL一直执行很满的话，那么就需要考虑优化SQL了。比如用索引、减少全表扫描、分库分表操作等。