>https://blog.csdn.net/hzp666/article/details/70236656
>
>https://blog.csdn.net/v_july_v/article/details/7382693
>
>https://blog.csdn.net/sinat_42483341/article/details/108277388

# 海量数据问题

面试中常见的问题类型之一。通常场景是给出一片海量的数据，和与之相比非常小的内存空间。由于内存空间小，不可能一口气读入所有数据。让你求这片数据中一些符合要求的数值。比如值最大(TopK大)的，出现频率最高(TopK高)的，按频率排序，不重复的，交集等等。

处理这类问题，思路大体包括了

- 哈希分治，各个击破
- 多层桶划分
- Bloom Filter和Bitmap
- Trie树
- 外排序
- 分布式处理（Hadoop / MapReduce）

其中前三种是比较常用的。下面从几个具体的题目入手来看。

## 哈希分治

### 求频率最高的项

```
Q.有一个很大的日志文件，每一行是一个IP。让你求出这个文件中IP出现次数最多的是哪个？
```

这类题的思路是 ==**<font color="red">哈希分治 + counter统计 + 排序 。核心思想是哈希一致性</font>**。这个思路几乎是一半以上海量数据题的基本思路，一定要记住！！==

1. 哈希分治，是指将每一行数据都通过`hash`函数转换成一个哈希值，然后取哈希值对某个不大不小的数，比如1024，的余数作为这行数据的标识。这样，所有数据都会被分成至多1024份。
   只要数据没有特别明显的偏向性，这1024份数据的大小不会差太多。

   ==之所以要用哈希值取余来区分数据，是因为哈希一致性==。即同样的两行数据经过哈希处理后肯定会被分到同一个部分中。如果无法保证这一点，那么后续操作将失去正确性。

2. counter统计很好理解，接下来我们依次分析这1024份数据中频率最高的IP值是什么，这可以通过设置一个counter来分析。

3. 分析完1024份数据后，我们得到了1024个出现次数很多的IP以及他们各自的次数。由于哈希一致性，可以确认整体次数最多的那个IP一定在这1024个之中。接下来只要针对1024个数据做一个简单排序即可。

### 求最大的数

```
Q. 有一个很大的文件，每一行是一个数。求这些数中的最大值。
```

相比于上题，这题还更方便了，因为不用counter统计出现次数。
只需要按照上述思路，先用哈希分治，此时甚至可以不用哈希函数，因为输入本身就是值（另一个角度来说，比如Python中的`hash`函数，对于实数而言其`hash(int)`的结果就是`int`本身）。所以直接对1024取余即可。

接下来需要确定的，就是每个小文件内的最大值。这可以通过一次线性扫描获得。

最后，获得1024个很大的值之后，全局最大值肯定在这其中，最后再扫描一次，就获得了最终答案。

总结一下，==当比较的基准不是频率是值时，其实本质上没有区别。统计频率的时候的counter操作，实际上也就是把一个记录与一个实数值关联起来，然后根据实数值进行筛选==。

### 求Top K频率最高的项

这也可以从最高类比出去。最高就是Top 1嘛。而`1`体现在，对于每个小文件，只取最高频率项。

换言之，如果你想求全局的Top K，那么我可以针对每个小文件，求出小文件中最高频率Top K的项。这样，就算运气很不好，分文件的时候把最终答案的K个IP全分到一个文件中去，也不影响最终能找全答案。这样可以得到`K * N`个IP，然后将这些IP排个序求前`K`个即可。

不过需要补充一句的是，==如果K不是太小，那么最终可能面临需要排序的数据的量，会是`K * N`，也不是一个小值。此时简单排序取前K就会显得有些费时间。下面是几种优化的思路==（假定对于每个分片文件的Top K，都已经排序完成）

- 用堆进行Top K抽取
  求大值用小顶堆，求小值用大顶堆。扫描`N*K`个数据并维护一个长度为`K`的堆。以求大值，小顶堆为例，新扫描到数据若小于等于堆顶，则没必要入堆，否则将其入堆并弹出当前堆顶。总体复杂度在`O(NKlogK)`。
- 用归并排序思想
  由于每个分片文件的K个结果已经排好序，这其实就是一个归并排序的场景。此时我们可以给每个文件设置一个指针，然后通过`O(N)`时间查找所有分片文件中的最大值，收割结果并将相应指针下移。这样，全程只需要`O(NK)`就可以找出全局Top K了。

另外如果给的内存小得离谱或者K大得离谱，这还可以是个套娃问题。也就是说面对`N`份数据中找出来的`N * K`个数据，再进行一次分治。==需要注意，套娃分治的时候显然`N`不能取原来的值了，因为这组数据的哈希值对`N`取余都是同样的，这也是他们在第一次分治中被分到同一组的原因。同样的，选取`N`的因数结果也还是一样。通常选择与`N`互质的一个数会比较好。另外，选取`m * N`作为因子的话，可以指定地将这组细分成`m`组==。

### 更多例题

#### 求全排序

```
Q.有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。
```

运用哈希分治思想，依次扫描各个文件并将query按照哈希值进行拆分。比如也分成十个文件。若原数据分布均匀，则每个文件也差不多1G大。

接着依次读取每个分片后的文件，统计文件内各query的频数。并将`query: 频数`键值对存放到另外10个文件中去。

若数据中query整体的重复率比较高，那么这10个频数文件其实会是比较小的。这样，==每个文件都可以排好序。之后只要把10个文件中的内容读取出来做排序即可。由于每个文件都已经拍好了序，这就是一个归并排序问题。可以给每个文件设置一个指针，进行排序。这样每时每刻内存中就只会有10个数字，比较这10个数字中最大值，收割结果然后将对应文件指针继续下移即可==。

> 考虑得更全面一些，其实如果前提是query整体重复率很高的话，那么其实不用那么复杂，直接一个counter计数然后排序就完了。
>
> 但如果query整体重复率很低（最极端的情况，每行都不一样），那么无论怎么分，都没法做到在小内存内解决这个问题。

#### 求交集

```
Q.给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？
```

显然，直接加载进内存是不可能的。但是可以这么考虑：
通过哈希分治的思路，将A文件分成`a0, a1, a2, ... a999`这样1000个子文件。同理B文件可以分成`b0, b1, b2, ..., b999`这样1000个子文件。若URL重复率较高，则每个子文件其实就不大。

==由于哈希的一致性，相同的URL一定会被分到下标相同的分片文件中。因此我们只需要从0到999，依次比对ai和bi中重复的URL即可。==
至于比对ai和bi的具体做法，就看具体文件的大小了。
如果文件还是比较大，则可以继续套娃细分文件。注意第二次分治的分治数量选取，上面说过应该尽量选择与第一次分治数量互质的一个数。
如果文件比较小，那么就很简单了。比如对ai求一个set，然后遍历bi中的URL看是否存在于ai中。

## 多层桶划分

多层桶划分仍然是分治的思想，只不过不再通过哈希进行分治，而是基于原有数据自身的排序性质分治。比如下面这题

### 求第K大数

```
Q.给出5亿个32位int数，找出其中的中位数是多少？
```

显然，直接排序并不现实，肯定要分治。因为要求中位数这种跟原数据本身的大小排序紧密相关的东西，所以不能使用哈希分治，因为哈希并取余之后，原有数据大小的排序就被破坏了。

我们这么来考虑，32位int数总共有2^32^个，范围是 -2^31^ ~ 2^31^-1。我们将这个范围手动分割成 2^16^ 个部分。
显然，每个部分可以容纳 2^16^ = 65536个数字。可以将这些范围称为桶。

运用桶思想，我们将5亿个数字分配到上面这些桶中去。因为内存放不下那么多桶，所以可以将桶具象化成文件。

接下来，求5亿个数的中位数，即求从小到大排序的第250,000,000与第250,000,001两个数的算术平均，所以我们可以从小到大遍历各个桶并将计数往上加。直到碰到一个桶，不加其桶中数字个数时总计数不足250000000，加上之后又大于250000001，我们就确定，中位数位于这个桶中。

至于如何从桶里确定中位数的值，这个和前面类似，看桶大不大。
如果不是太大，那么直接排个序，然后遍历计数找就完了。
如果还比较大，那么就套娃，再分数字范围，即二级桶。这也是多层桶划分的思想精髓所在。

==桶划分思想适用于求第K大数（求中位数是一个特殊的求第K大问题）问题==。

## Bloom Filter 与 Bitmap

bitmap我们都知道，是用一个或若干个二进制位来表示某些状态，从而一来节省了表状态的内存空间，二来可以在很快的时间内（因为是位运算）找到状态值。典型的应用例子就有Leetcode判断数独有效性那道题。

> Bloom过滤器是什么
>
> Bloom过滤器则是bitmap的一个改进版。构建bloom过滤器时，除了需要一定数量的二进制位之外，还需要指定若干个哈希函数。假设bloom过滤器分配得`N`个二进制位，那么所有这些哈希函数都可以做到将一个值映射成`0 ~ N-1`中的一个值，即二进制位的某个下标。
> 当bloom过滤器想要加入一个值时，通过多个哈希函数算得值对应的多个下标，然后把这些下标全部置1（当然根据已经进入bloom过滤器的值，这些位置的部分或者全部可能已经是1，这个不管）。
> 之后，在判断某个值是否在bloom过滤器中时，使用多个哈希函数计算出多个下标并依次检查这些下标。
> 若这些下标中至少有一个为0，那么说明该值必然不在bloom过滤器中；
> 若这些下标全部为1，考虑到哈希函数的散列性质，说明该值很可能在bloom过滤器中。
>
> 显然，bloom过滤器不是一个很严格的数据结构。对于某元素是否存在于其中，False答案可以完全相信，但是True答案存在一定错误率。但是考虑到其对存储空间的节省，很多不要求错误率为零的场景下，bloom过滤器是一个很好的选择。

### 求不重复数

```
Q. 从2.5亿个32位整数中找出不重复的整数。
```

这道题可以用哈希分治的思路来做，将所有数字分到不同的文件中，然后统计各个文件中没有重复的数字，然后合并各个文件的结果就是总的结果了。

下面给出一个基于bitmap的思路。32位整数最多只有2^32^个，最简单的思路，就是设置2^32^个二进制位表示每个整数。当然，这题要求判断的，是整数不重复，即出现次数恰好为一次。这么说来，某个整数的状态可以分为出现零次、出现一次、出现两次及以上。==因为有三种可能，所以至少需要两个bit位来表示了==。
比如`00`表示出现零次，`01`表示出现一次，`10`表示出现两次以及以上，`11`无意义。
这样，我们需要`2 ** 32 * 2 / 8`字节来完整地表示这些整数出现的次数。然而这个式子，结果是1G，也并不是太大，可以接受。
因此，这题的思路就是，给所有32位整数安排两个bit位，共需要1G内存，然后按照上述规则扫描2.5亿个数字，对每个数字的出现次数进行维护。

### 判是否含有

```
Q. 给出40亿个不重复的32位整数，未经排序。再给一个数num，求判断num是否在这40亿个数中
```

用哈希表显然是不现实的。另一方面，可以直接申请512M空间，对所有32位整数是否出现在数集中用位图法表示。
之后再给一个num，就可以利用位图在`O(1)`时间内判断其是否存在于数集中了。