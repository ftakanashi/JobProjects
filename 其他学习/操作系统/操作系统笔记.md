# ※从硬件讲起

> 这部分不是教科书，参考的是小林Coding的图解系统

## 硬件位数与软件位数

==硬件位数指CPU的位宽。即CPU一次性可以读写多少位数据==（这个的本质其实是CPU连出的总线线宽：32根总线必然同时只能读写32位0或1）这里的数据是广义的，既可以指数据，也可以指内存地址，还可以指指令本身大小。同时，指令的大小其实又对应了软件位数。==当一个软件内部指令都是32位大小时，软件称为32位软件（如32位操作系统，操作系统也是软件）==。

于是，就有了如下现象：

- 32位CPU无法直接一次计算大于32位整数的运算、无法执行任何64位软件、也无法找大于32位的地址（因此32位系统下进程的寻址空间最大4G）
- 64位CPU可以进行32位系统等的运算。但是需要加兼容机制。

## CPU的频率

CPU的参数中通常会带有GHz参数。比如1GHz的CPU，指的是1秒内可以进行1G次高低电平的转换。一次转换称为1个时钟周期。

另外特别指出，一条指令并不总是1个时钟周期内完成。只有那些最简单的比如一个加法，可以在一个时钟周期内完成，略微复杂一些的比如乘法就不行了。

## 存储器的层级

我们知道，存储器的层级从高到低，价格从高到低、数量（容量）从低到高的顺序是：

```
寄存器
CPU缓存（L1/L2/L3）
主存
磁盘
```

其中寄存器最为昂贵，通常一个CPU只有几十到几百个寄存器。每个寄存器可以存储与CPU位数一样多的位。==寄存器又可以分为普通寄存器（存普通数据）、指令寄存器（存指令）、程序计数器（存放下一个指令的地址）等==。

CPU缓存则是因为内存和CPU访问速度差太多，现代通常内存访问时间是几百个时钟周期，相当于这期间都够CPU做好几百次运算。如果不加一点中间缓存，那么CPU明显会被内存读写太慢而拖累。L1、L2、L3逐级层次降低。在Linux中分别在`/sys/devices/system/cpu/cpu0/cache/index?/size`中看到各个缓存的容量。注意?换成1、2、3。默认情况三者大小可能是32K, 256K, 3M。

内存和磁盘就不说了。

为了有个印象，特别说明下，L1缓存和磁盘相比，访问速度前者是后者的10^7^倍左右，而单位造价也是后者的466倍。

==每种存储器读写数据时，都只会与相邻的存储器级别打交道，无法越级读写。==

### 感受CPU缓存的力量

现在让我们遍历一个二维数组。有两种代码：

```python
# 第一种
for i in range(n):
    for j in range(n):
        print(matrix[i][j])
    
# 第二种
for i in range(n):
    for j in range(n):
        print(matrix[j][i])
```

两者看似没什么差，但是如果n很大的时候，你会发现后者比前者慢好多。其原因是这样的。
首先我们应该意识到，二维数组在内存中，仍然是连续存放的，涉及到一个二维坐标转一维的过程。如`n==2`的时候，内存中的顺序应该是`00, 01, 10, 11`。

无论哪种方法，第一个遍历到的都是`00`，由于`00`只存在于内存，不存在于CPU缓存中，因此CPU会将其加载到CPU缓存中来。另外考虑到程序数据的局部性，还会顺带将内存中连续的后面一部分也加载进来，这里比方说额外加载了一个数据。

此时，第一种方法的下一个数据恰好是01，所以可以直接命中CPU缓存，因此直接完事。
而第二种方法，因为下一个数据是10，其仍然在内存中不在缓存中，因此还是要去访问内存，拖慢了速度。

和寄存器一样，CPU缓存也可以分为数据用缓存和指令用缓存。而做程序优化，就要尽量提高这两种缓存的命中率。

## 【旧】~~关于硬软中断~~

硬/软中断顾名思义就是由硬件和软件引起的中断。
中断，指CPU正在执行某个任务时，因为硬件的请求，不得不将当前程序暂停执行，转而做其他工作。所谓其他工作，是由中断发生后，系统调用内核中的中断处理程序决定的。

可以预见，中断处理程序必须得快。这是为了一来尽量不影响原先正在执行的那个进程，二来中断处理期间无法处理新来的中断（也可以套娃中断，取决于具体系统逻辑）。
为了能尽量快进行中断处理，==系统将中断处理分成了两部分，分别称为上半部和下半部==。

上半部，中断发生后，系统处理硬件的请求，做一些最低限度不得不做的事，比如网卡接收包后发生中断，系统只将包存入内存，但不解析。这部分也成为硬中断，对应原本中断的意义。

下半部，系统在内核中发起一个软中断线程。这个线程会向内核发出一个中断信号，从而进行中断处理未完成的工作，比如上面的那个包，将它解析。软中断严格意义上不是中断，而是硬中断处理完成后，由内核发起的一个独立任务。其可以和其他进程一起竞争CPU。当软中断进程处理完成后，整个中断处理就完成了。而在软中断处理期间，一来其他进程又可以继续运行，二来新的中断也可以进来了。

由于软中断处理实际上是一个内核线程在跑，那么此内核线程占用的CPU时间就可以统计为，软中断占用的时间。相对的，硬中断处理要做的事情也会有硬中断占用的CPU时间。

这两个占用率在Linux的top输出中分别以hi和si表示。

更多中断相关信息，记录在I/O系统一章。

> 注意区分硬/软中断和硬件/软件中断。
> 虽然一字之差，但是概念上还是有些区别的。==硬/软中断特指一次中断过程的上下两半部分的处理方式。通常这里的“中断”特指由硬件发起的一次中断，即硬件中断==。
>
> 与硬件中断相对的自然是软件中断。软件中断顾名思义由软件发起，具体是其向内核发送INT信号（这里INT是interrupt而不是整数）。软件中断发生后也要进行一整套中断处理操作。
> ==软件中断发生的常见的场合，第一个就是进程进行系统调用，从而从用户态进入系统态的“陷入(trap)”过程。进程系统调用时，向内核发送INT信号，进入中断处理；第二个就是进程的时间片用完，内核进行新进程调度时，也会发起软件中断==。
> 此外，程序中发生“异常”时，也会触发软件中断，所以可以认为异常也是一种软件中断。
>
> 为了不混淆两组概念，通常也把这节主要说的，中断处理的两部分称为中断的上半部和下半部。

## 关于软硬中断

这块概念一直不清不楚的，今天尝试再思考一次试试。

首先，广义上的中断指这么一种机制：当中断发生，让CPU暂停当前运行的进程，保存现场，加载执行中断处理程序，处理完成后加载回当时被中断的进程继续运行。
中断机制的意义在于，有些任务十分紧急不能将其作为普通的进程放到就绪队列中等待执行。比如网卡接收网络包这个事情，网卡的缓冲区很小，因此在其接收到网络包后OS应当立即将网络包保存到内存中，从而使得网卡可以继续接收新的包。

软/硬中断，顾名思义定义上来说就是指软件/硬件发起的中断。
硬件发起，更具体来说应该是硬件设备的控制器发起，本质上是传导一个电信号给CPU。==常见的可以发起硬中断的硬件包括磁盘、网卡（这些是需要IO的情况）、时钟（时间片计量，用完时间片后中断进程进行进程切换）等==。
软件发起，具体是指软件代码中发出了INT中断指令。==常见的软中断的场景包括发起IO请求、系统调用（进程需要被中断进入内核态）、异常（需要中断进行异常处理，此时中断处理程序就是异常处理程序）等==。

### 软硬中断的联系与区别

由于定义上的区别，导致两种中断在各种方面都有不同之处。

首先，从流程上来说，==硬中断的启动流程是`硬件 -> CPU -> 中断处理`；而软中断直接在CPU执行代码时发起，所以是`CPU -> 中断处理`，比硬中断少一个步骤==。
另外，因为软中断是CPU执行代码时发起，所以遵循时钟周期；相对的，硬中断随时可能发生。

两者的联系：硬中断发生后要进行中断处理，通常我们期望这个处理是十分迅速的，因为硬中断处理不够迅速将导致硬件压力过大。这就需要讲到一次典型的硬中断处理的上半部和下半部了。
==硬中断发生后，通常上半部是硬中断机制进行处理==，即硬件发起中断请求，CPU接收请求并调用内核中的终端处理程序。而这个处理程序通常只会做一些简单的工作，比如收网络包的时候把网络包给复制到内存中。此时硬中断虽然发生，但中断处理却未完全完成，剩余工作交给下半部进行。
下半部以软中断机制进行，即程序会在合适的时候发起中断请求，进行中断处理。

多重中断的场景中，硬中断可屏蔽（不接受新来的硬中断）可嵌套（套娃处理）、软中断不可屏蔽不可嵌套。

## 二进制表示小数

### 二进制表示整数

正整数没什么可说的，就二进制表示就完了。==准确的说，正整数的原码、反码、补码全部相同。==
关键在于负数怎么办。现代计算机都采用符号位+补码的形式表示负数。

符号位，指所有负整数的最高位都是1，相对的所有正整数符号位都是0。最高位是1了之后，剩余部分是其绝对值（一个正数）的原码取反+1。光取反，叫反码，反码+1，叫补码。
==比如`-2`在8位整数下的表示是，首先最高符号位写成1，其次，剩余7位按照2的原码 (00000010) 取反 (11111101)  +1 (11111110)。最终得到`-2`的二进制表达是`11111110`==。

根据二进制表达求原数则是将上述流程倒过来。比如我拿到`11111001`这么一个8位表达的整数。首先看到符号位是1，说明其是一个负数，然后将剩余7位拿出来，-1 (1111000)  取反 (0000111)。发现等于`7`。所以原数等于`-7`。

使用拐弯抹角的补码表达负整数的好处是，保证二进制加法的协调性。比如计算`-2 + 1`，在其他形式的表示中，程序需要额外判断正负性才能获得结果，而若采用补码形式，则直接`11111110 + 00000001`得到`11111111`。根据上面二进制转十进制的规则，看符号位后减一取反，得到`-1`，即正确结果，补码形式直接加就完事了。

### 二进制表示小数部分

任意一个小数，都可以分为整数部分和小数部分。整数部分如何解决上面已经说了，接下来就在于如何表示二进制的小数部分。直接将小数部分作为整数处理是不行的，比如你无法区分`.01`和`.0001`的区别。
前人采用的办法是，用2的负数次幂逼近。比如`.625`的二进制表示是`101`，因为`0.625 = 1*2^(-1) + 0*2^(-2) + 1*2^(-3)`。

但是问题是，并非所有小数部分都可以恰好用2的负次幂和精确加和得到。比如无限循环小数，甚至连简单的`0.1`都不行。因此，很多时候小数部分的表示只是一个近似值。这也是浮点数的近似性的根本原因。

结合上述策略，可以用二进制表达某个完整的小数。比如`8.625`，可以表示成`1000.101`。

### 计算机中的浮点数

上述`1000.101`的表示方式确实是广义上的二进制表达小数的做法。这种表达也被称为“定点数”因为小数点确定在某个位置不能改变，一旦改变，数值也就变动了。
另一方面，计算机中使用的是浮点数，表示小数点可以变化。小数点变化而保持数值不变，其实可以想到用科学计数法来表示。十进制下的科学计数法表示为`a * 10^(b)`，其中要求`a`是一个小数且`1 <= a < 10`，`b`则可以是任意整数。
类比到二进制，任意一个二进制小数都可以表示为`1.a * 2^(b)`。注意前半部分`1.a`是二进制表达，小数点前面只能是1。

比如上面提到的`8.625`即`1000.101`表示为浮点数，就是`1.000101 * 2^3`。2的3次方，是因为相比于原数，小数点左移了3位。至此可以看出，决定一个浮点数值的有两个因素，分别是这里的`000101`和`3`，这两个也分别被称为尾数和指数。

根据IEEE标准，==一个浮点数在内存中从高位到低位分别是，符号位、指数位（表达一个整数，有偏移量机制）、尾数位（表达一个位数，按照上述2的负次幂方式逼近）。32位的float型，这三种位的长度分别是1, 8, 23，而64位double型这三种位的长度分别是1, 11, 52==。

接下来我们来实际看看如何用一个32位float表示`10.625`。按上述规则，`10.625`表达为浮点数应该是`1.010101 * 2^(3)`（注意`1.010101`是二进制小数）。
因为其是正数，符号位为0没毛病。尾数部分为`010101000...`(补齐直到23位)，也没毛病。而指数部分，看似应该是`00000011`，但是因为考虑到指数可能是负数不方便，保存时将真实的指数加上一个偏移量，偏移量是指数位能表达的最大正数。这里是8位，表达最大是`01111111`即127。换言之，32位float的指数可以表达的范围是`-126 ~ 127`，因为指数位被当成一个无符号整数解释。
回到例子中，指数是3，所以其在指数位的表示是`3+127=130=10000010`。

至此，`10.625`的完整float型表示就有了：`0 10000010 01010100000000000000000`。

反过来，我们再来看这样一个二进制表达的float其值是多少：`0 01111110 11000000000000000000000`。
首先这还是一个正数。其次指数部分明面值是126，减去偏移量127得到是-1，所以浮点数表达为`1.11 * 2^(-1)`。继续将.11解释为`2^(-1) + 2^(-2)`，所以上述式子写成十进制形式应该是`(1 + 0.75) * 2^(-1) = 0.875`。 

# 进程的描述与控制

## 进程的描述

### 进程的定义

进程由程序段、相关数据段、PCB三部分组成一个进程实体。将这个实体简称为进程。

### ⭐️进程的基本状态及互相转换

进程具有就绪态(Ready)，运行态(Running)，阻塞态(Block)三种状态。

- 就绪态：指进程已经得到了除了CPU外所有必要的资源，等待获得CPU后开始运行。系统中若有多个处于就绪态的进程，则还需要将他们按照一定规律排成一个队列。队列是就绪队列。
- 运行态：从就绪态分得CPU后进入运行态，进程处于执行状态。当分配到的CPU时间片完成后，重新回到就绪态。
- 阻塞态：在执行态时进程发生IO请求或者申请缓冲区失败等情况时，进入阻塞态。当请求完成或者错误处理后，回到就绪态。

考虑得更加周全一点，还可以加入创建态和终止态。

- 创建态：指进程创建指令发出后，建立PCB，申请相关资源的过程。当创建态的进程被操作系统调度器许可执行了，那么就可以进入就绪态了。
- 终止态：同样的，进程在运行态运行完成后，还需要一些额外的时间用来回收资源，清空PCB等。这个过程是终止态。

#### 挂起操作和进程转换

有时进程的外部，比如用户或者父进程等，会想让进程暂时停止不要继续运行。此时可以发起挂起操作。此时进程若处于运行态，则会暂停运行；若处于就绪态，则其不会进入就绪队列接受调度。挂起的逆向操作是激活。
==常见的引起挂起的原因有比如程序调用了`sleep`函数、用户按了Ctrl+Z手动挂起、内存不足等==。

引入挂起操作之后，在三态互相转换的关系中，可以新加入额外的两个状态：

- 静止就绪态：将就绪态 或者 运行态的进程挂起后，进程进入静止就绪态。激活静止就绪态的进程会进入（活动）就绪态。
- 静止阻塞态：（活动）阻塞态通过挂起得到静止阻塞态，反过来激活静止阻塞态得到（活动）阻塞态。

总体的进程状态转换图如下：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210715224346410.png" alt="image-20210715224346410" style="zoom:75%;" />

#### 阻塞/挂起/睡眠的区别

术语上的辨析：阻塞=block，挂起=suspend，睡眠=sleep

以前总是会混用这几个概念。其实这几个概念确实也很像。进程无论是被阻塞还是挂起还是睡眠，其都要进行进程暂停执行，并且进行CPU上下文切换从而让出CPU给其他进程执行。

不同之处在于：

- 发起/恢复方式不同

  挂起和其恢复可以是进程主动发起的，比如调试代码过程，代码运行到断点后进程就被挂起，点击继续执行就恢复；再比如父进程可以要求挂起某个子进程，在之后合适时恢复。==睡眠可以认为是一个特殊的挂起情况，在代码中调用了`sleep`就进入睡眠状态，在固定时间后进程自动恢复==。

  阻塞通常是由内核控制，不随进程意志变化。比如进程拿不到执行时必要的锁；或者是在等待数据写入文件、socket等时，就是阻塞。而在不定的时间，其拿到了资源从而满足了执行条件，此时阻塞恢复。

- 保存位置不同

  挂起/睡眠后的进程，会被内核从内存中交换到磁盘上，从而腾出内存空间。直到恢复时再将相关进程换回内存。也正是基于这个特点，OS有时候也会主动将一些优先级低的进程挂起，以腾出空间来。

  阻塞后的进程仍然保存在内存中，等待阻塞完成后继续运行。

### 进程管理的数据结构

操作系统中为了统一管理各种资源，会有一个类似于管理中心的地方。这个地方又被分成了好几块用于管理不同的资源。通常包括了内存表、设备表、文件表和进程表。进程表中维护了各个进程的信息，而这个信息，具体来说就是进程控制块（PCB）。操作系统通过PCB感知进程并指挥进程、与进程联系。

一个进程的PCB主要包含了下列内容：

- 进程标识符(PID)、用户标识符（进程归属的用户UID）
-  处理器状态，也称为处理器上下文。基本上保存的是各种寄存器在进程当前进度的中间值。这些寄存器包括了通用寄存器、指令计数器、程序状态字、用户栈指针等。正因为有了这些信息，才能保证进程可以在下一次运行时从断点续上。
- 进程调度信息，比如进程状态，进程优先级，事件（进程阻塞原因）等
- 进程控制信息，比如程序和数据段的地址，进程同步机制，资源清单等

#### PCB在进程表中的组织方式

- 顺序表：最简单的办法，将所有PCB表按顺序放在一个列表中。这样的话每次搜索PCB都可能扫描全表。
- 链表：进程状态中提到，进程可能有很多种状态，某个状态可能还有个队列。要把这方面信息也维护在进程表中，就需要更复杂一点的数据结构了。一种方案是链接，具体来说，进程表中维护各个队列的队首指针，指向某个PCB。而某个PCB会指向队列中的下一个PCB。PCB们本身可以还是存在一个线性表中，但是从进程表的不同队列指针出发，就可以区分处于不同状态的进程。
- 索引：进程表中还可以根据不同队列，直接维护队列中各个PCB的指针。这样就不需要PCB之间的互相连接了。

==不论采用哪种组织形式，通常都会将相同状态的进程的PCB给放在同一个结构中。所以在内存中会形成进程的“就绪队列”、“阻塞队列”等==。

### ⭐️孤儿进程、僵尸进程

- 孤儿进程：当父进程结束后因为一些原因（==比如父进程退出时子进程处于挂起状态，未能接收到父进程通知等情况；再比如发信号SIGTERM给父进程==）其子进程没有正常结束，此时子进程会被init进程收养，因为所有进程必须要有父进程。于是这个子进程就变成了孤儿进程。
- 僵尸进程：子进程调用exit进行进程结束流程。其会归还内存等资源，然后需父进程调用`wait`或者`waitpid`获取将子进程从进程表中删除，到这子进程才算是彻底结束。若父进程未调用`wait`等做相关处理，则子进程的PCB等信息一直存在，其变成僵尸进程。

两者之间的联系：当一个父进程产生了大量子进程且未做回收处理时，此时大量僵尸进程会占用过多的系统资源（僵尸进程虽然归还了内存，但是仍然占据PCB）。

==僵尸进程的处理方法也很简单，注意因为其本身已经结束运行，所以通过类似`kill -9`发送信号也不会响应。==
==但只需要将父进程杀死，这样僵尸进程们就变成了孤儿进程，从而被init进程收养。被收养后，由init进程负责将其资源回收==。

## 进程内存分布

首先，32位系统无法直接运算32位整数以上的数，因此32位系统中最大的寻址只可能寻址到`0xFFFFFFFF`。又因为内存的物理最小单位是字节，因此一个进程最多可拥有的内存空间是`2^32`字节即4GB空间。64位系统则是`2^64`字节，当然这个空间比目前实际进程需要的空间大的多的多，所以基本不可能用满，通常是从中选取低位48位使用，所以是`2^48B = 256TB`，这也够大了。

得益于分页式的内存管理系统，新建一个进程时，即使其理论内存空间是256TB，我们不必真的整理出一块连续的256TB的空间给它。而是通过分页，当你需要更大空间时，我再将空的页分配给你的策略。

以32位系统的4GB空间为例，我们知道进程的内存需要分成内核态内存与用户态内存两部分，从而可以区分进程的内核态运行与用户态运行。而在Windows和Linux中，对于这两种类型的分配策略不同。Windows采取2GB/2GB，而Linux采取1GB/3GB的分配模式。

继续，以Linux系统为例，来看看3GB用户态空间和1GB内核态空间都是如何规划的：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/v2-449604d2b17cfeb9f15354ebb5ca3158_720w.jpg" alt="img" style="zoom:80%;" />

==在整个地址空间的最高位1GB，即从`0xc0000000`到`0xffffffff`是内核空间，剩余部分是用户空间==。
用户空间又被细分成为如下几个部分：

- text（代码段）：存放程序的指令，通常只读
- rodata（只读数据段）：存放常量，只读
- data（数据段）：存放已初始化的全局变量、静态变量等，可读可写
- BSS：存放未初始化的全局变量、静态变量等，可读可写。BSS与data构成了上述图中的全局数据区
- heap（堆）：进程运行中可以通过`malloc`，`free`等函数进行内存扩张、收缩的区域。必须通过堆指针对堆进行访问。
- mmap（内存映射段）：将一些磁盘中的文件映射到内存里，避免频繁的磁盘IO。通常用于加载动态链接库等库内容。进程间共享内存，也是将同一块内存给映射到各自mmap中的一部分去。
- stack（栈）：由编译器自动分配释放的一块内存区域，主要用于存放非静态的局部变量等。栈也必须通过栈指针进行访问。

## 进程控制

### OS内核

为了防止重要信息被破坏以及提升运行效率，OS会将一些与硬件紧密相关的模块或者常用的模块安排在靠近硬件的层次。这些程序及其数据常驻内存中，称为OS内核。

内核主要有下列功能：

- 中断处理、时钟管理、原语操作等支撑功能
- 进程管理、存储器管理、设备管理、等资源管理功能

光区分了内核还不够，为了让其他进程不要破坏内核的程序以及数据，CPU运行时被分为内核态和用户态。处于内核态运行的程序有最高权限，可以访问硬件、内核所属的内存等。而用户态的程序只允许访问部分内存，不允许直接访问硬件。

一般用户态的进程如果想要访问硬件等，就需要通过系统调用进入内核态。为了明确系统调用前后两种态的界限，用户态进程会先触发中断。CPU调用中断处理程序，即被进程调用的内核程序。内核程序结束后再次触发中断，将CPU还给用户态进程。

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210711112241221.png" alt="image-20210711112241221" style="zoom:50%;" />

### 进程上下文切换

说进程上下文切换前，应该先说说CPU上下文切换，后者包括前者。CPU上下文切换指的是不同任务在时分复用CPU时，抢占到CPU资源后必然要将断点续入CPU。这个过程就是CPU上下文切换。
==CPU上下文切换具体切换的东西，是CPU寄存器（包括指令和数据寄存器）和程序计数器两个部件中的内容，即CPU上下文==。
根据时分复用CPU的任务的形式不同，CPU上下文切换又可以分为进程上下文切换、线程上下文切换、中断上下文切换三种。

这里重点说进程上下文切换。进程上下文切换过程，肯定包括CPU上下文切换。除此之外，还包括了进程的虚拟内存、栈、全局变量等用户空间的资源，以及，内核空间的内核堆栈等。
进行进程上下文切换时，首先老进程的将上述这些信息给保存到该进程的PCB中，然后读取新进程PCB中上述信息到内存里，接着运行新进程。

### 系统调用（模式切换）与上下文切换

> (1) https://stackoverflow.com/questions/9238326/system-call-and-context-switch

这两个概念之间有联系，具体来说，==进行系统调用时进程的状态必然会发生用户态向内核态的转变，而这个转变也多多少少涉及到上下文的切换。只不过这个切换的量的多少，与具体做了什么系统调用有关==。

按参考(1)的说法，若系统调用只是一些简单的比如请求当前的时间等。此时只需要将寄存器、程序计数器等信息保存，然后加载内核代码所需的内容去获取时间，将时间存入寄存器或用户态内存等位置，再恢复之前保存的信息。这整个过程其实更像是同一个进程下线程的上下文切换，只涉及到很少一部分内容的切换。
但若系统调用比较复杂，比如是一个会阻塞主进程的读取文件的过程，此时从CPU调度的角度来说，就要进行一次进程上下文的切换，将别的进程调入CPU执行，而阻塞的原进程放到一边等待（在用DMA的情况下，数据由磁盘控制器直接放入内核态内存）。从这个意义上来说，这次系统调用引发的上下文切换，swap了相当多的东西。

总的来说，系统调用肯定会触发上下文切换，至于切换的内容多少就和具体的系统调用有关了。

## 进程同步

### 进程同步的基本概念

注意区分进程同步和进程通信这两个概念的区别。
进程同步是指一种机制，其对多个进程在执行次序上进行协调，从而使其可以以一定规律有序地共享系统资源。

#### 制约关系

两个进程之间若存在制约关系，则说明他们不能自由地同时运行。这种制约关系分成间接制约和直接制约。间接制约是指A和B两进程需要互斥地访问同一个资源，这就导致两者不能同时运行。直接制约指B的运行需要A的输入，则两者不能同时运行。

#### 临界资源与临界区

多个进程对某个硬件资源（打印机、磁带机）或者软件资源（某个变量等）需要互斥地进行访问，且访问时不允许别的进程进行抢占。这些资源称之为临界资源。一个进程的代码中，需要访问临界资源的部分称之为临界区。

所谓的同步，就是指限制所有进程中，只有一个进程能进入临界区。

### 信号量机制

实现同步的方式有硬件也有软件的。信号量就是一个通过软件实现同步的典型代表。

最早==信号量是一个整型值（也称整型信号量），用于抽象系统中某些特定的可供分配的资源总数==。进程需要用到资源时，通过对信号量`-1`来实现对资源的获取。显然当资源耗尽时信号量小于等于0，此时若再有进程想要申请资源，只能被阻塞或者等待。进程执行完成后，让信号量`+1`返还相关资源。

上面提到的让信号量`-1`和`+1`的操作，都是原子操作。因此保证了多进程对信号量操作的互斥性。
若信号量的初始化值是1，即全局只有一个资源的情况，这也被称为互斥信号量。

#### AND型信号量

很多时候，进程可能需要多个资源都到位之后才能运行。此时如果给每个资源都分配一个信号量的话，很可能导致死锁。一个解决办法是，规定所有资源必须全部满足可获取状态，才获取资源开始运行，并且修改信号量。运行完成后又全部一起返还资源。这样，多个资源就可以视为一个资源，一起获取一起返还。（这也是预防死锁的一个方案）这种信号量称为AND信号量。

信号量还有其他一些变种比如信号量集。此外还有将信号量以及其他一些必要的数据给包装成一个数据结构的管程等。这里就不多说了

### 哲学家进餐问题

进程同步方面有一个很有名的哲学家进餐问题。问题描述为，五个哲学家围坐一桌，每人面前有一道菜，且每两人之间都有一个叉。现在哲学家们不定时地切换思考和吃饭模式。思考模式下就独自思考，切换到吃饭模式时，一定要拿到左边和右边两个叉子才能开始吃饭，如果有一边叉子正在隔壁的人手里使用，则必须等隔壁的人用完后自己再用。

这个场景下，会出现这样一个问题，每个哲学家都拿到了左手边的叉子，而要拿右手边叉子时发现，叉子已经被隔壁拿走，所以就等待。每个人都等待，陷入死锁。

==一个很简单的解决办法是，为拿叉子这个动作加上一个互斥信号量==。这样一个哲学家试图去拿叉子的时候，其他人就不能动，保证这个哲学家拿到叉子并完成进餐，放下叉子。
但是这么做的问题在于，每一个时刻只有一个哲学家进餐，导致系统效率较低。

==一种更好的解决办法是，将哲学家编号，并规定所有奇数编号的哲学家必须先拿右边再拿左边、所有偶数编号的哲学家必须先拿左边再拿右边的叉子==。于是，桌上只有一部分叉子会被两位哲学家竞争，而没被竞争的那部分叉子则可以作为避免死锁的突破口，防止桌上形成死锁局面。

## 进程通信

在保证进程的同步和互斥中，理论上进程已经可以通过诸如信号量等中介进行通信了。但是这种通信的效率比较低。而高效率的进程间通信主要有以下几种：

### ⭐️进程间通信类型

#### 管道

管道本质上是个文件，连接了一个读进程和一个写进程进行通信。两个进程之间互斥地读写管道内容，即在任意一个时刻两个进程只能一个读一个写。并且，这个读写过程是同步的，即写进程写完之后，在内容还没有被读取完之前，不能返回做其他事。

==管道还可细分为无名管道（内存中的文件，仅供父子进程间通信）和有名管道（FIFO文件，供任意进程间通信）==。
无名管道本质上是一个不存在于磁盘，只存在于内核内存中的一个文件（或者叫它是一个缓冲区也行）。
有名管道则是读写两进程通过 提前在系统中创建好的管道设备文件 进行信息读写。该文件存在于文件系统中。

因为管道某一时刻只能一端读一端写，为了不引起混乱，实现双向通信通常需要建立两个管道。

#### 消息队列

管道通信有很多缺点，比如其同步特性。消息队列则是另一种实现方法。

消息队列本质是内核内存中维护这的一个链表。这个链表的每一项都是通信双方约定好格式的“消息体”。==消息队列是异步的==，发信方只要发出信息即可返回做其他事，无需同步等待接收方接收。
与管道的流信息相比，消息队列的传输基于块信息。

消息队列的缺点是，可传递信息的大小收到了消息体大小的限制，并且无法实时收发消息。另外因为消息队列存在于内核空间中，所以收发消息时，进程需要进行内核与用户态的切换。

#### 共享内存

在内存中划一块专用于共享内存通信的地盘。各进程都可以申请到其中一部分，将其附加到进程自身内存中，然后对其进行读写。读写完成后归还其到共享内存。共享内存是最快的进程间通信方法。在Linux上共享内存映射在`/dev/shm`文件上。

由于被共享的内存都存在于进程的用户空间中，所以使用共享内存进行通信时进程不需要切换到内核态。
当然，对于被共享的内存需要有好的管理方法，要不然会引起进程的数据混乱。

#### 套接字

Socket主要用于网络间的进程通信，而主机内部进程间的 通信也可以基于Socket进行。
根据Socket类型不同，可以实现

- TCP网络字节流通信
- UDP网络数据报通信
- 本地字节流/数据报通信

具体的参数什么的涉及到Linux系统调用中创建socket的函数。这里就不多说了。

#### 信号量

上面《进程同步》中已经说过了，就不重复讲了。
多说一句，信号量初始化为1时可以让多进程互斥访问资源；信号量初始化为0时可以让多进程同步（生产者-消费者模型）。

#### 信号

信号和信号量虽然就差了一个字，但是是完全不同的两个概念。
信号主要是指其他进程通过软件和硬件向本进程发送某个信号，促使本进程做出某些动作回应的机制。
Linux中的信号选择可以通过`kill -l`来查看。

通过硬件发送信号比如键盘上按Ctrl + C，此时其实就是通过键盘这个IO设备，给当前正在运行的进程发送了一个`SIGINT信号`。
而常用的 `kill -9 xxx`就是给PID是xxx的进程发送一个`SIGKILL`信号。
不带参数的`kill xxx`其实是默认参数15，即发送`SIGTERM`信号。（关于这几个信号，稍微详细一点的写在Linux篇里）

另外，某个进程接收信号后通常可做的动作回应包括了 1.默认动作，由系统实现预设好的 2.自定义信号处理函数 3.忽略信号，但`SIGKILL`和`SIGSTP`这两个信号不能忽略。

### 进程通信相关命令：ipcs

`ipcs`命令可以查看到共享内存、信号量、消息队列这三个通信渠道的一些信息。
`ipcs -l`列出了这些渠道能承载的消息上限。
`ipcs -a`查看当前正在这些渠道一些定性的属性比如什么进程在使用，具有什么权限等。
`ipcs -u`则列出了这些渠道一些定量的属性，比如已经使用资源占多少，还剩下空余资源多少等。

### 一些补充

- 共享内存是最快的IPC方法，因为其他一切方法，数据从进程A发到进程B，必然A先进入内核态发数据，B再进入内核态取数据。
  ==共享内存通过直接把内存映射到内核空间的同一地址，避免了用户/内核态的切换从而加快了通信。==
- 关于生命周期：共享内存与消息队列等，都是内核起来之后就常驻内存的东西，随内核。只有当内核重启这部分内容才会被清空刷新。而（无名）管道则是随着进程间通信需要在内存中建立，进程间通信完成后也会自动被清空回收，随进程。

## 线程

在OS中引入进程，以进程为资源分配和调度运行的基本单位，解决了多个程序并发运行的问题。而引入线程，是为了进一步减少多程序并发时的时空开销的问题。可以说这两个引入，一个是从0到1，一个是从1到更好。

一个进程，从创建，到运行时进行CPU的上下文切换，到销毁时回收资源，都会发生时空损耗。从纯功利主义的角度来所，这些都属于不必要的额外的损耗。为了降低这种损耗，引入了线程这种更加轻量级的概念。

### ⭐️线程与进程比较（附赠协程

| 比较点           | 进程                                                         | 线程                                                         | 协程                                                         |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 定义             | 资源分配的基本单位                                           | 程序执行的基本单位                                           | 轻量级线程，线程内部的调度基本单位                           |
| 拥有资源         | CPU资源、内存空间、文件句柄等                                | 程序计数器、寄存器、栈等                                     | 多协程共享线程寄存器但是每个协程独享寄存器上下文、有独立的栈（也有不带栈的协程 |
| 切换时           | 整个CPU环境都要切换（CPU寄存器（包括页表寄存器）、栈、进程内存空间、文件句柄等） | （同进程内线程切换）==只需要切换程序计数器、寄存器上下文、栈指针等少量线程独有内容==即可 | 切换内容和线程切换一样，只是不需要进入内核态                 |
| 切换过程         | 用户态 -> 内核态 -> 用户态                                   | 用户态 -> 内核态 -> 用户态                                   | 用户态（不陷入内核态）                                       |
| 并发性与系统开销 | 可多CPU并行运行，占用系统空间大、切换开销大                  | 多线程可并发运行、占用系统空间较小、切换较快                 | 同一线程内任意一时刻只能有一个协程运行，其他休眠、切换内容最少因此最快 |

如果我们把一个程序抽象成函数，那么不同进程就是不同函数。同一个进程内的不同线程就是同样函数的几个副本同时跑，只不过副本间彼此进度不同。
而协程，是指一个函数内部并不按照从上至下的线性执行规律。比如Python的生成器就是一个协程的好例子。比如这个例子：

```python
def generator():
  # 协程A：生成器不断生成新数据的过程
  for res in range(10):
    yield res
  
def main():
  # 协程B，或者说是主协程，不断消费generator生成的数据
  for i in generator():
    # do something
```

`main`里调用了一个生成器：`for i in generator()`。此时从生成器中遍历出一个`i`之后，生成器本身的协程就休眠，转而进入这个`main`里的for循环执行。执行完一步后for循环协程休眠，转而进入生成器协程，继续生产下一个`i`。

### 线程状态和TCB

和进程很类似，线程也有三种主要状态：就绪、运行、阻塞。其互相转换关系和进程也一样。

和进程有PCB类似，线程有TCB，其中内容也很相似，主要包括了：线程标识符、寄存器、运行状态、优先级、线程专有存储区、堆栈指针等。==主要就记住，一个进程内的多个线程共享进程的代码、数据、文件、进程虚拟内存等资源；相对的，独自拥有栈、寄存器这些和独自执行程序时实时动态紧密相关的资源==。

### 线程上下文的切换

上面进程上下文切换中提到了，线程上下文切换也是CPU上下文切换的一种。
==具体来说，如果旧新两个线程分属不同的进程，那么这里的线程切换实质上就是进程切换。
若两个线程属于同一个进程，此时由于线程间共享进程内存、全局变量等，这些东西都不用变。要变的只有线程独自拥有的如栈指针、寄存器内容等。因此线程切换比进程切换快很多，省开销==。

线程切换时和进程切换时一样，相关信息中继保存在TCB中。

 #### 为什么线程切换比进程开销小

最笼统地说，进程切换时要切换的东西比（同进程内）线程切换时多，因此自然开销更大一些。
==其中可以着重讲一讲的是页表==。页表虽然不用整个加载到寄存器中。加载到CPU寄存器中并且直接被CPU使用的，是页表的始址以及长度这些减短的信息。然而，别忘了快表。进程切换后显然，包括快表在内的很多缓存机制都直接失效。

因为切换进程后缺页时快表命中率会降低不少，因此切换后一段时间内存访问减慢，综合来说开销更大。

#### 为什么协程切换比线程开销小

对于协程切换，首先不需要寄存器信息的切换，即 切换内容更少。这方面和线程与进程对比是类似的。

而这里可以着重讲一讲的是协程切换直接在用户态完成，不需要像线程一样进入内核态，由内核代码进行切换，因此省去了用户态内核态互相之间的切换，自然开销更小。

### 多线程OS中的进程属性

在引入了线程之后，就要对进程的部分概念进行一些修正了（毕竟现在所有计算机都是多线程的了）。

在多线程系统中，进程仍然是可拥有资源的基本单位，特指那些比较大的比如文件、设备等资源。而线程的并发更为广泛应用，传统的进程运行方式已经被称为单线程运行。一个进程至少有一个主线程。

而进程已经不再是可执行的实体。线程才是可独立运行的基本单位。通常说某个进程在执行，是指其某个线程正在被执行。另一方面，对进程的操作会反映到其所有线程上。比如对进程挂起，其所有线程也都挂起。

### 多进程与多线程的优缺点比较

多进程和多线程的优缺点互相对立。以多进程的视角来说：
多进程的优点：（反过来就是多线程的缺点）

- 进程间互相独立，一个挂了不会影响其他进程继续提供服务。
- 由于相对较独立，所以避免了复杂的锁机制。还能支持自恢复（worker挂掉后master可以重启一个worker）

多进程缺点：（反过来就是多线程的优点）

- 开销较大。不论是占用的死内存，还是进行切换，整体开销都大于多线程。
- 逻辑控制较为复杂。
- 进程间通信的难度高，效率低于线程间通信。

应用场景方面：
多进程常用于web服务进程、浏览器程序等需要工作单位间互相独立性较强的场景。
多线程常用于爬虫、桌面软件、泛泛的并行计算等工作单位间共性较大，并且可能需要频繁创建销毁工作单位的场景。

# CPU调度与死锁

CPU调度其实可以分成好多层级。最高层的有作业调度（Job），中层有内存调度，低层的是进程调度。这里主要聚焦于进程调度的内容。

## 进程调度

进程调度的主要任务有三个：

- 保存CPU的现场信息
- 按照某种算法选取下一个进程
- 将CPU分配给该进程

### 进程调度的基本方式（Mode）

- 非抢占方式：一旦将CPU分配给某个进程后，直到进程完成或者被阻塞等情况时，才将CPU收回分配给其他进程
- 抢占式：将某个正在执行的程序按照特定原则暂停，然后将其CPU收回，分配给其他进程。

### ⭐️各类进程调度算法

- 先来先服务算法（FCFS）、短作业优先算法（SJF）

  ```
  这俩算法其实最开始是作业调度层面的算法，但是也可以用于进程调度。需要注意这两种算法都是非抢占式的算法。当一个进程开始处理之后就会运行到其结束为止。
  简单来说，FCFS就是从进程的就绪队列中按序挨个拿出进程，进行执行。执行到其结束后继续处理下一个。是最简单的处理逻辑。
  SJF算法是按照进程预计需要用时进行排序，优先处理预计用时较短的进程。这样可以使总等待时间较小。
  以上两种算法，前者只考虑进程的等待时间，后者只考虑进程的运行时间，都比较极端化。
  ```

- 轮转调度算法：

  ```
  分时系统中最简单的调度算法。采用最公平的分配方式，让就绪队列中每个进程运行一个时间片，然后暂停其运行将CPU分给队列中下一个进程。
  这个算法的关键在于时间片设置成多大。可以想象，如果时间片过小，就会耗费大量时间在切换进程上，而如果时间片过大，所有进程都在一个时间片内完成运行，则算法退化成FCFS算法。
  ```

- 优先级调度算法

  ```
  轮转调度中，假设所有进程的优先级都相同，但是实际上并不是这样。所以我们会考虑将优先级也纳入调度算法的考虑中来。
  此时还可分成非抢占式和抢占式两种方式。非抢占式的算法，一旦将CPU分配给当前最高优先级进程后，即使过程中出现更高优先级的，也不变化。
  相对，抢占式算法在这种情况下会暂停当前进程，转而分配CPU给更高优先级的进程。
  ```

- 多队列调度算法

  ```
  以上所有算法默认都只有一个就绪队列。而多队列算法可以设置有多个就绪队列，每个队列又可以设置不同的算法以及优先度。
  灵活安排，从而可以实现更加高效的调度。
  ```

  多队列调度算法是一个比较泛泛的概念，下面说其中一个最佳实践：

  - 多级反馈队列

    ==队列间采用优先级调度，队列内采用时间片轮转调度。任务在多个队列间逐级下滑。==
    
    ```
    多级反馈队列算法设置有多个就绪队列。每个队列被分配一个优先级，第一个队列优先级最高，第二次之，以此类推。每个队列内采取轮转调度算法，并且优先级越高的队列，设置的时间片越小。
    当新进程进入内存后，默认将其放入第一个队列中等待执行。轮到他时拿去执行，如果在一个时间片内这个进程没能执行完成，则暂停执行并将此进程放入第二个队列的队尾，等待执行。以此类推，直到设置的最后一个队列。最后一个队列以普通的轮转调度算法执行。
对于不同队列间的调度，采取优先级调度算法。即，只有第一队列中目前是空的，才去第二队列队首取进程执行，以此类推。
    ```
    
    

## 死锁

死锁总是发生在对临界资源的使用时。临界资源，定义是需要互斥访问，并且不可以被抢占的资源，比如打印机、队列、信号量等。

最经典的死锁的模式，是A和B分别对X和Y两个临界资源发起请求。不同的是A以XY的顺序发起，B以YX的顺序发起，导致互相等对方释放前一个资源，从而死锁。上述模式也可以总结称为 ==“竞争不可抢占性资源引起死锁”==。

另一种死锁的模式是，加入A和B两个进程分别要求某种相同的资源各三个。然而这种资源系统里总共就只有4个。如果AB同时发出资源申请，很可能会出现，A获得两个，B获得两个的情况。此时两者都还没有满足获得三个资源的条件，因此不会运行，然而系统资源也没了，互相之间就死锁了。这种情况下，本应想定资源即使不够，也应该至少满足一个进程的运行，这样等进程运行结束后让出了资源可供另一个进程使用。这种模式成为==“竞争消耗性资源引起死锁”==。

死锁的定义: 一组进程中，每个进程都在等待由该组进程中其他进程才能引发的事件重回就绪态，那么这组进程是死锁的。

### 产生死锁的必要条件

1. 互斥条件

   ```
   进程对所分配的资源进行排他性的使用。
   ```

2. 请求和保持条件

   ```
   进程在使用到某个排他性资源后，要继续请求另一个资源，且这个过程中，对已有的排他性资源进行保持不放。
   ```

3. 不可抢占条件

   ```
   上述已经使用的排他性资源，不能被其他进程抢占。
   ```

4. 循环等待条件

   ```
   发生死锁时，若将资源、进程之间的互相关系以有向图的形式画出来，必然存在一个循环链。
   ```

### ⭐️预防死锁

预防死锁，是指一切程序开始运行前，通过追加一些限制条件，破坏死锁四个必要条件中的一个或几个，从而预防运行过程中产生死锁的情况。针对四个条件不同，有不同的预防策略如：

- 破坏“请求和保持条件”

  ```
  破坏请求和保持条件，实际上就是不允许进程在请求新资源的同时持有不可抢占的资源。解决这个问题有两种思路，
  第一，要求进程在开始运行前申请好全部需要的资源，否则不允许运行。这样就不会有持有一些资源，申请另一些资源的情况了；
  第二，进程在申请新资源之前，将已经使用完成的旧资源全部回收处理。
  第二种思路比第一种更高效因为第一种在一开始就要占据全部资源，可能会造成浪费。
  ```

- 破坏不可抢占条件

  ```
  一句话就是允许资源被抢占。准确来说，只有当某个进程尝试申请新资源没有立即成功时，就将其目前持有的资源设置为可抢占。自然，这个资源很快就会被别的进程抢占去。
  ```

- 破坏循环等待条件

  ```
  本质上就是破坏资源-进程图中的环。具体是这么做的：
  对于所有资源，我们将其从小到大编号。每个资源有了编号之后，我们规定，任何进程，都必须先申请较低编号的资源，再申请较高编号的资源。
  若某进程持有较高编号（如12）的资源时，想要申请较低编号（如5）的资源时，其必须先把12号资源给释放，然后再从头申请5号和12号资源。
  有了这个限制，资源-进程图就不会成环。
  ```

==总结一下，对于竞争互斥性资源引起的死锁，预防的思路大概有 设置资源为可抢占性、规定程序只有凑齐资源才能开始运行（AND型信号量）、规定请求资源的顺序。==

### 避免死锁

避免死锁看起来字面意思和预防死锁差不多，两者指两种不同的防止死锁出现的方案。预防死锁更多的是在程序运行前追加限制条件。而避免死锁更多的，是指在程序运行过程中动态地判断某些资源能不能分配，分配了之后会不会引起不安全状态，从而防止死锁出现。

避免死锁更多的是用在 竞争消耗性资源引起的死锁 的解决上。这里首先定义一个概念叫做系统的安全状态：

- 安全状态：指当前进程和系统资源的情况下，可以找到一个进程的排列，使得现有的系统资源可以通过这个排列依次分配资源进行进程运行。期间不会出现死锁直到所有进程结束。相对的，不安全状态就是指一个这样的排列都找不到。

避免死锁的算法称为银行家算法。

#### ⭐️银行家算法

简单来说，银行家算法要求每个新进程进入系统时，声明运行过程中需要的各种资源的最大数目。当进程对某资源发起请求时，系统会结合该进程目前持有的资源判断，系统是否有足够的资源满足该进程。只有是的情况，才允许分配资源给进程。

如此就避免了因 竞争消耗性资源而引起的死锁。

银行家算法的具体内容这里就不写了，可以参看书本。

### 死锁的检测

正如前面提到的，验证循环等待条件的方法，就是将当前的进程-资源有向图画出来。然后探索这个图看有没有环就可以知道是否存在死锁了。

> 顺便一提，检测有向图 中是否有环，是一个拓扑排序问题。可以用基于DFS的拓扑排序方法来解决。

### 死锁的解除

解除死锁的方法也很简单。从两个方面考虑，第一，解放出新的足够的资源，从而使得死锁解除。第二，终止进程，打破循环链解除。

对于后者，还可选择一次性终止整个死锁组的进程，或者一个个终止。一次性终止所有进程，是个很暴力的解决办法。。一个个终止稍微温和一点，但是仍然可能会带来比较大的损失。

# 存储器管理

## 存储器的层次结构

存储器泛指计算机上所有具有数据存储功能的部件。存储器的访问速度与其最大容量、价格之间有一个trade-off，因此不同速容比的访问器也有不同的用途。常见的从访问速度从高到低，最大容量从小到大的顺序有：

```
寄存器（CPU寄存器）
主存（高速缓存、主存储器、磁盘缓存）
辅存（磁盘、可移动存储介质）
```

寄存器和主存在掉电后回丢失其中保存的信息，而辅存的信息是持久化的。另外，CPU寄存器和主存储器也被称为可执行存储器。与辅存等非可执行存储相比，对可执行存储的访问不必通过IO设备，因此比要通过IO设备的辅存访问快3个数量级。

本章主要介绍寄存器、主存这些掉电后丢失信息的存储器。至于磁盘等的管理在后面。

### 各类存储器简介

- 主存储器

  ```
  即内存，CPU从内存中读取指令，并把计算结果输出给内存。
  因为CPU的执行指令的速度比访问内存的速度要快很多，为了调和这个矛盾，又引入了寄存器和高速缓存
  内存嘛，通常大小在几百M到几个G之间。
  ```

- 寄存器

  ```
  寄存器具有和CPU处理同样快的速度，因此访问很快，可以和CPU协调工作。
  寄存器是很小很小的，通常是32、64位。相对的可能会设置很多个寄存器。
  ```

- 高速缓存

  ```
  高速缓存介于寄存器和主存之间。主要用于备份主存中常用的数据，从而提升主存与CPU之间通信的效率。
  高速缓存的大小通常在几十K到几个M间，比寄存器要大很多，但比主存小很多。
  为了进一步提升效率，现在通常都会设有多级的高速缓存，越高级的高速缓存速度快容量小。套娃。
  ```

- 磁盘缓存

  ```
  和高速缓存调和了CPU计算速度与主存访问速度的矛盾一样，磁盘缓存用来调和主存访问速度与磁盘访问速度之间的矛盾。
  需要注意的是，磁盘缓存不是真实的存储器而是一个概念。磁盘缓存通常是在主存中特别划出一部分空间，用来做磁盘缓存，保存一些磁盘过来的信息。
  ```

## 连续分配 存储管理方式

连续分配方式是存储管理方式的一种。其特点是将一片连续的内存空间分配给某个进程的代码和数据。具体的还可分为如下四种算法的分配方式

- 单一连续分配：将整个可以分配的内存分配给一个进程。显然只适用于单用户单任务的操作系统中
- 固定分区分配：将整个可以分配的内存提前按照一定规则划分成数个区域，每个区域针对某用户的某任务进行单一连续分配。虽然支持了多用户多任务系统，但是十分死板。
- 动态分区分配：根据进程的实际需要，可以动态地进行内存分配工作。这个下面会重点介绍。
- 动态可重定位分区分配：当分配碎片过多时，将已经分配空间进行归纳整理，比如将其全部都整理到低址区，从而可以空出大片连续的高址区。然而这么做的问题是已经分配的部分因为绝对地址的改变，导致无法正常读取程序和数据。此时就需要进行一次动态的重定位，修正其绝对地址到新地址上。

### ⭐️动态分区分配具体算法

动态分区分配的前提是要知道当前内存还有哪些空间是可以被分配的，于是这就要求我们实时维护一个空闲分区表。这个表记录了所有空闲分区的 1.大小 2.起始地址。

而其具体算法可以分为两类。基于顺序搜索的分配算法和基于索引搜索的分配算法。先来说说基于顺序搜索的：

- 首次适应（FF）算法

  ```
  在空闲分区表从低址到高址依次扫描，碰到的第一个足够容下进程的空闲分区时将其分配给进程。
  需要注意如果空闲分区比进程要求的空间大，那么剩余空间会遗留下来。
  FF算法的特点是每次尝试分配都会从低址开始扫描，因此其倾向于使用低址区域的空闲分区。
  这也导致可能的问题：低址区域的内存会越来越碎片化，且后期找空闲分区会花费较长时间因为低址处无地可用。
  ```

- 循环首次适应（NF）算法

  ```
  为了避免FF中出现的碎片化空间的问题，NF中规定本次扫描是从上次扫描到的空闲分区的下一个分区开始。
  由于不是每次都从头扫描，可以避免碎片化空间过于集中的问题。
  ```

- 最佳适应（BF）算法

  ```
  我们总是选取当前空闲分区中能够满足进程要求且最小的分区分配给进程。
  这么做乍一看好像挺合理的，但是实际上每次都选择最佳适应空闲分区的话，也会有最大的风险不断产生很小的无法利用的碎片空间。
  并且为了实时知晓维护分区的大小比较情况，此算法比较耗费时间。
  ```

- 最坏适应（WF）算法

  ```
  和BF相反，总是选用空闲分区中最大的来分配给进程。
  这种算法可以避免过多的碎片空间，并且每次分配只要看最大的空闲分区即可，所以算法耗时上比较好一些。
  ```

上述四种是基本的，基于顺序搜索的动态分区分配算法。从实践上来说，一般还是最简单直白的首次适应算法具有最佳性能。

基于顺序搜索的动态分区分配算法通常适用于较小系统。当内存较大时，空闲分区表本来就很大，会导致顺序搜索的效率下降。此时用索引搜索是一个更好的办法。下面继续介绍几个基于索引搜索的分配算法。

- 快速适应（Quick Fit）算法

  ```
  事先将所有空闲分区按照大小规格分类，对每类分区单独安排一个空闲分区表。于是就有了一个 规格：分区 的索引表。
  借助这个索引表，对于新来的进程可以快速地为其找到合适的分区并分配。
  ```

- 伙伴系统

  ```
  略
  ```

- 哈希算法

  ```
  哈希和QF也差不多，只不过这里不规定死的大小规格，视内存当前具体情况，把所有空闲分区大小的可能，都用 空闲分区大小：起始地址 类似的形式用一个哈希表整合起来。
  ```

### 外碎片和内碎片

以上提到的内存碎片基本都属于外碎片，即虽然空闲在内存中，但是由于过小而无法分配给其他程序使用的碎片。

相对的还有内碎片的概念。这种概念通常用于描述如固定分区分配等情况中，那些分配给了某个程序但是程序基本不使用，从而导致浪费了的碎片。

## 对换（Swapping）

将内存中暂时不能、不用运行的程序以及其数据换出到外存上，腾出内存空间，从而将已经具备运行条件的程序和数据从外存交换到内存中。

按照对换操作的基本单位，可以将对换分成 整体对换（指一次对换针对一整个进程）或者 部分对换（一次对换只针对一个页面等部分单位）。这章主要介绍的是整体对换。当然部分对换可能才是现在的主流操作，部分对换写在了虚拟存储器一章。

### 对换空间的管理

在要进行对换的系统中，磁盘上都会划出一块对换区。这片对换区就是用来进行对换的外存空间。由于进入这个区域的内容都不会长久驻留且访问频率很高，因此这个区域应该要实现高效的访问而不是空间利用率的提升。

因此，对换区通常采用 “连续分配方式”（注意，虽然上面介绍过的连续分配方式是针对内存的，但是要知道内存和磁盘都是存储器，本质是一样的，所以可以沿用在这里。

对换，不论换哪个方向，其本质都是从一片存储区域中找到一个合适的区域来存放进程内容。因此之前介绍到的所有动态分区匹配的算法也都适用于此。

### 对换进程的选择

通常优先换出阻塞的进程、优先级低的进程。注意虽然进程本身的虚拟空间被换出，但是PCB还是常驻内存中的（存在于进程表中）。

## ⭐️离散分配 —— 分页存储管理方式

上面提到的存储管理方式主要是连续分配存储管理方式。可以感觉到，这种方式的一个很大的缺点，就是可能会引起很多碎片空间，碎片空间是无法使用的，因此会影响有效空间使用率。

相对的，离散分配的存储管理方式看起来似乎更加灵活。根据离散分配的单位大小不同，将离散分配管理方式大概分为 分页、分段、页段三种。这节主要讲讲分页的管理方式。

### 分页存储管理的基本方法

分页，指一方面将进程的地址空间分成若干个固定页面大小的部分，通常这个大小是1K~8K。另一方面，将内存也分成同样大小的页框，或者叫块。进程的任意一页都可以放到内存的任意一块中去。

在分页体系下，可以通过页号P和偏移量W来确定一个地址。假设页长是L，则有`A = P * L + W`。

另一方面，如果知道了逻辑地址A，也可以快速找到其页号和页内地址：`P = A // L`, `W = A % L`。

分页管理，是一种离散型的管理方式。这也就意味着针对一个进程的每个页，我们都得知道其处于内存的哪个物理块中。为了维护这方面信息，系统给每个进程又开辟了一个页表。==页表，就是 一个进程页的页号 对应到 内存中块的块地址 的映射关系==。

### 地址变换机构

进程程序中， 所有地址都是逻辑地址。在分页管理方式的语境下，逻辑地址通常是指一个逻辑页号（指要访问本进程内存的第几页）和页内偏移量的组合。而CPU要访问的是实际物理内存中的具体地址，于是我们需要一个地址变换机构，把逻辑地址转变为物理地址。

因为页和物理块是一一完全对应的，所以有了页内偏移量之后，确定具体的物理地址，只要将页号和块号的起始地址对上即可。换言之，地址变换机构具体要做的，是将一个逻辑页号，转化成对应的物理块号。

上面的这个对应，其实就是页表维护的内容。==而页表本身就是内存中一段连续的空间。因此，只需要找到页表的始址，再加上逻辑页号乘以页表项长度，就可以定位指定页号在页表中的项了==。那么页表的始址又去哪里找呢？系统会将页表的始址以及页表长度（总共有多少页表项）从PCB中读取出来后，加载到CPU的页表寄存器中。这样，CPU每拿到一个逻辑页号，先行检验其是否越界（是否大于页表长度），如果否，则`页表始址+页号*页表项长度`得到页表项的地址。然后访问该地址，得到对应的物理块号。

由于每个进程的页表位置不同，互相独立，因此进程切换的时候，页表寄存器中内容也要相应地切换。

以上就是地址变换机构最基本的工作原理。

#### ⭐️使用快表寻址

==上述地址变换机构的工作过程中，CPU需要访问两次内存。第一次，访问页表，用逻辑页号检索得到物理块号。第二次才去访问物理块。而所谓的快表，就是在这个过程中加入一个名为快表的LRU缓存。CPU拿到逻辑页号后，先去缓存里找是否有相关记录记录了其对应的块号。如果有，直接使用即可。没有才再去访问页表查找相应的物理块号==。

快表通常是一个寄存器（如果读取速度和内存一样慢，那就没有意义了），因为是寄存器所以很小，通常只能存放512条页号→块号的记录。然而这还挺够用的，因为计算机数据访问的局部性（或者叫二八定律，80%的访问总是落到20%的热门数据上），因此可以加速。因为快表是一个LRU缓存，所以当表满的时候会把最老的没人用过的记录给清除掉。

加入快表之后，寻址会有一个命中率的概念。命中率指，在泛泛的寻址过程中，一个逻辑页号可以再快表中找到对应物理块号的大致概率。代码数据复用率越高，热门数据越热门，命中率也就越高，从而整体CPU访问内存速度会加快很多。

### 多级页表

现在操作系统大多都是32或者64位，说明其中一个进程理论上最大可以支持`2^32 ~ 2^64`字节的地址空间。即使一个内存页的大小设置为4K（即`2^12`），除法做一下，一个32位进程的页表项长度仍可能达到一百万，更不用说64位的了。

根据上面说的寻址机制，页表需要一块连续内存存放。显然过长的页表对内存的空间和规整提出了要求。
为了使得页表机制能更方便地被使用，提出了多级页表。以二级的结构为例。这种结构中，有一个一级页表和若干个二级页表。
一级页表是“页表的页表”，维护二级页表号和二级页表始址的关系；二级页表才是经典意义的页表，维护页号和物理块号的关系。
比如上述32位4K页的例子中，一百多万个页表项被分成1024个部分，每个部分1024个项分开保存。每个部分就是一个二级页表，而二级页表序号和地址的对应由一级页表维护。

==分级之后，一个显而易见的好处是不再需要大量连续的空间了==。只需要连续空间存放一级页表，而每个二级页表之间不必再紧紧相连。
但空间问题似乎还在，即便分开存储，不是还得要一百万多的页表项的空间吗。
其实这里，==对每个二级页表而言，并不需要每时每刻存放在内存里。在特定时刻，结合后面要说的内存页调入调出机制（一个二级页表本身也是一个内存页），将要使用的二级页表调入内存，不用的调出，即可让页表系统不用占据那么大空间==。
考虑到程序的局部性性质，这么做也是合理的。

注意，升级到多级页表后还有一些其他地方也要变化。比如显然一个页号已经不能定位某个页对应的页表项了。==此时一个页的逻辑地址，从原先的`逻辑页号 + 页内偏移`应该变成`一级逻辑页号 + 二级逻辑页号 + 页内偏移`==。
相应的，CPU的页表寄存器也应该变成两级。
另外为了适应调入调出，我们还得时刻知道某个二级页表（别忘了其本身也是一个内存页）是否在内存中。这通过在一级页表中添加一个状态位来实现。这方面在后面的请求分页式存储管理方式中也会讲。

## 分段式存储管理方式

> ==一段小小的总结：==
>
> ==最早的操作系统，支持的内存管理方式是单一连续分配：将所有内存分配给一个用户的一个任务。
> 随着多道系统的发展，分配方式又变成了固定连续分配：将空间分割成固定的几个区域分给不同任务。
> 为了适应不同任务对内存大小的需要，又有了动态分区连续分配：空间被动态地分成大小不同的区域给不同任务。
> 为了进一步提升内存空间的利用率，减少碎片，又发展出了不同于连续分配的离散分配方案，如分页式。
> 以上分配方案的发展都主要是在不断提升内存使用的效率和方便性，而分段式则是主要为了程序员在编程上多方面的要求。==

一个程序，在加载进内存时可以被分为好多逻辑段。如主程序段MAIN，子程序段X，数据段D，栈段S等。分段存储管理方式，就是指在内存中，这些段可以离散地分开存储。

既然是离散的，就免不了又要维护一个逻辑地址转物理地址的完整机制了。在分段式方式中，首先要有一个段表。
段表的字段有 段号、段长、物理始址。和页表非常相似的。但是因为每个段不一定等长，因此这里加入了段长这个字段。

### 地址变换机构

类似的，要找一个具体物理地址时，需要给出 `段号 + 段内偏移`的组合。随后，类似的地址变换机构先比较段号和段表长度，看是否越界。若无越界，则 `段表始址 + 段号`找到段表中对应的段表项，并依此查找段的物理始址再加上偏移量，找到实际的物理地址。
也是类似的（页表寄存器），段表始址和段表长度存放在“段表寄存器”中。
还是类似的（快表），为了防止两次访问内存，使用一个叫做“联想寄存器”的东西作为缓存，发挥类似快表的作用。

### 分段和分页

上面的描述可以看出来，分段和分页两种方式，因为围绕着共同的“离散分配”这一个特点，有许多共通之处。而两者的不同之处如下：

- 页的大小是系统直接决定，程序员无从更改；段的大小根本上是程序员写的程序决定，而直接的是由编译器在编译程序是决定。
- 页是物理单位，分页过程其实对用户不可见，完全是系统行为；而段是逻辑单位，分段过程可以由程序员控制，利用分段程序员还可以做很多方便的事。

### 分段的好处之一：数据共享

上面说了很多，分段之后程序员会很方便。现在就从数据共享的角度来看看到底怎么方便了。

现在假设有一个多用户程序，这个程序的代码占160K，数据区占40K。每个用户拥有一个进程，共40个用户。对于每个用户进程而言，他们的代码区是一模一样的，而数据是互相不同的。
显然，如果不做任何进程间的数据共享，那么总共需要内存空间是`(160K + 40K) * 40 = 8M`。

原理上来说，只要是离散分配的，都可以做到共享。比如在分页的情形下，每个进程的访问代码时，可以让各自的页表相关页表项指向同一个内存地址，这样就做到了共享代码。
然而问题出在页表本身上。我们知道页通常很小，若一页是4K的话，那么这个例子中一个进程指向代码区的页表项需要`160 / 4 = 40`个。有点多了。
如果改为分段，那么每个进程各自段表的相关段表项指向同一个内存地址这点还是不变，然而因为是分段，整个代码区是一个整体所以每个进程只需要一个段表项就可以了。从段/页表的大小对比上来说，分段更适合做数据共享。

## 段页式存储管理方式

一句话就是，段页式结合了分页可以最大限度减少内外碎片 和 分段可以让程序员方便地管理程序 两个优点。

段页式中，程序被先分成若干个逻辑段，而每个段又被分成若干个页。这些页被离散存储在物理内存中。
自然，为了找到某个物理地址需要给出的地址结构是`段号 + 段内页号 + 页内偏移`。

### 地址变换机构

段页式的地址变换机构，首先有一个段表寄存器存放段表始址以及段表长度。来了一个地址后先分析其段表项。
为了节省一个页表寄存器，段表中存放的不是页号或者什么而是该段对应页表的始址（这点和二级页表很像）以及页表长度。
此时你有了页表始址、页表长度，进一步解析请求地址中的段内页号，接下来工作就和普通分页机制中找地址一样了，先判页号是否越界，然后找到页表项，进而找到页对应的块地址。最后结合偏移量算出物理地址。

可以看出，==段页式方式中，找出一个物理地址需要三次访问内存。第一次访问段表，根据段号找页表始址和大小。第二次访问页表，根据段内页号和页表找块物理地址。第三次才是去块中取数据。==

# 虚拟存储器

## 概述

以上提到的所有内存管理方式，有一个大前提，就是要求将一个进程的整个地址空间全部都放入内存，然后才开始运行进程。

但是如果物理内存不足而进程地址空间又很大的话，会导致进程无法运行。

当然，物理上增大内存可行，而更灵活的方法就是用虚拟化方法，虚拟地扩大当前现有的内存。

简言之，用时间换空间。进程运行不一定需要整个地址空间中的所有信息，于是我们可以只将当前进程要用的内容加载到内存，运行进程；而其要求新内容时，将用完的内容换出内存，加载新的内容进来，就可以保证进程在小内存空间中无问题地运行。

### 虚拟存储器的运行原理

首先，虚拟存储器必然建立在分页存储管理方式的基础上。如果是连续分配管理方式，考虑到进程所有内容都有可能被用到，终究还是要分配足够容纳整个进程的空间，就无法做到虚拟化。

具体的，程序运行之前，可能仅将进程的一部分内存页加载到物理内存中，先行开始运行。运行过程中，如果进程发现需要访问的页不在内存中，此时称为发生缺页，于是进程将向OS发起 “缺页中断请求”。OS接到请求后，利用页置换计数，将相关页加载入内存。如果内存此时已经充满，那么还需要将内存中一些页面给调到磁盘上，腾出内存空间以调入新内存页。

以上过程不仅可以让一个大进程在小内存中运行，也可以使同样内存中运行更多的进程。

### 虚拟存储器的定义与特征

> 这个“虚拟存储器”，很容易叫成虚拟内存，但是Windows系统中的虚拟内存更像是Linux中的Swapping机制，所以为了不混淆，这里继续使用虚拟存储器这个叫法。

虚拟存储器，并不是一个实际客观存在的存储器，而是集合了主存、辅存、具有请求调入和置换功能，借此可以从逻辑上对内存容量进行扩充的存储器系统。

按照基于的存储系统是分页还是分段的，又可以分成两类。这里以分页式的作为例子进行说明。

## 请求分页存储管理方式

分页式的虚拟存储器学名 请求分页系统，在基本的分页存储管理方式上发展而来。注意这里以及下文中的的“请求”二字是一个定语而不是动词，用来形容这个分页不是一般的分页而是带有调入、置换功能的分页体系。

### ⭐️硬件要求

请求分页系统的硬件要求有：内存、外存、请求页表、缺页中断机构、地址变换机构。

#### 请求页表

我们知道，普通的页表是进程的内存页与物理内存块之间地址的映射。因此一行只有页号+物理块号两个字段。而请求页表，因为要考虑与外存换页的功能，这里还有额外的四个字段，分别是

- 状态位P

  仅一位，指示该页是否在内存中

- 访问位A

  用于记录该页多久没有被访问。可以作为置换算法的参考。

- 修改位M

  记录该页这次在进入内存后是否被修改了。==通常外存会保存该页的一个副本，如果一个页进入内存后始终没修改，那么就没必要将其原封不动地写回去，直接保留副本即可。这样可以减少和磁盘交互的时间==。

- 外存地址

  保存该页在外存的副本的地址。供调入内存时参考。

#### 缺页中断机构

当进程需要访问的页面不在内存中时，就会触发缺页中断，请求OS将相关页调入内存。

和一般的中断相比，缺页中断当然也需要保存CPU信息，分析原因，调入中断处理程序。不同的是，缺页中断可以在指令执行过程中产生（这一般是硬中断的特点），而一般中断通常是在指令完成后才检查有没有中断请求。此外，即便是一条指令内部，也有可能发生多次中断请求。

#### 地址变换机构

请求分页模式下的地址变换更加复杂，因为要根据页是否在内存中以及是否在快表中等多个条件，制定不同的变换策略。大致过程是这样的：

拿到页号后，先检索快表看是否命中，

- 若命中，则直接访问相关物理块，修改页内的访问位字段。
  - 若这个指令是写指令，则在写完成后还需要修改 修改位 字段的信息。

- 若没有命中，说明需要到内存中去检索页表，但该页有可能不在内存中，因此先检查该页 状态位。
  - 若该页已经在内存中，则更新快表，继续访问即可。
  - 若不在内存中，则触发缺页中断。此时OS去外存中找相关页，找到后还要看内存是否满了
    - 如果满了则根据置换算法选择一页换出，换出后记得后续更新一些内容比如该页的状态位以及页表等。
    - 如果没满，则直接启动IO，将外存的页加载到内存，加载结束后更新页表，更新快表。

总的来说，页表中记录的页必然是已经在内存中的，而快表中的页必然是在页表中的。

### 请求分页存储管理方式中的内存分配

在一般的分页存储管理方式中，系统默认分配给一个进程足够的内存空间。所以也不存在什么分配策略的问题。然而在请求分页体系中，就有很多细节需要明确。

首先，要明确保证一个进程能够运行的最小的物理块数。通常最简单的直接寻址方式工作的系统，进程只需要两个物理块，一个存指令，一个存数据，就可以运行下去（虽然要真这么干，换页会非常频繁地发生）。

其次，要确定内存该如何分配。
总体来说，针对一个进程，分配给他固定的内存还是可变的内存、当缺页发生时置换的页是局部的还是全局的，根据这两个维度可以衍生出几种不同的策略。

- 固定分配局部置换

  ```
  固定分配，即将定值个内存块分配给一个进程，之后进程运行过程中，属于此进程的内存块个数不再变化。
  局部置换，即缺页时，OS只考虑将属于当前进程范围内的某个页置换出去，调入新的页。因为只考虑本进程范围内，所以称为局部置换。
  显然，固定分配的坏处是很难把握到底分配块给这个进程才合适。如果太少，则频繁发生缺页中断；若太多，则又降低了内存中进程的个数。
  ```

- 可变分配全局置换

  ```
  可变分配，即进程运行过程中，会根据其需要，动态地增减分配给其的块数。
  全局置换，即缺页时，OS考虑从全局所有页中找到合适的块来接收新页。这个块可能本身就是空闲的，那么相当于是给本进程增容了；或者是别的进程使用中的页，那么相当于给本进程增容但给其他进程减容。
  ```

- 可变分配局部置换

  ```
  可变分配和局部置换的概念上面都说了。
  具体的，这种策略下，缺页时优先考虑进行进程内的局部置换。当缺页频率上升局部置换频繁发生时，系统将额外的块追加分配给该进程改善其内存紧缺的情况。
  ```

最后，不同进程间如何分配有限的物理块也存在一个策略问题。
常见的策略是 1. 平均分配  2. 按比例分配  3. 按优先级分配

### 请求分页存储管理方式中的页面调入

在何时调入页面：分为预调页和请求调页两种策略。预调页默认某个页面被用到后其后面的一些页很有可能在接下来的执行中用到，所以一次性将多个连续页面调入，减少磁盘IO。

调入页过程：

```
当进程要访问某页，发现其状态位是0（不在内存中），于是向CPU发出缺页中断。
中断前先保存CPU环境，分析中断原因，调用中断处理程序。中断处理程序查找页表中相关页信息，得知其外存地址，然后尝试将其调入内存。
调入内存分为内存充足（直接调入）和内存不足（使用置换算法将一个老页出去，置换成新页）两种情况。
调入页面后，还需要更新页表，更新快表。
```

### 缺页率

设程序运行过程中，每次访问页面时，若成功访问到的次数是S，发生缺页的次数是F，那么缺页率就是`F / (F+S)`。影响缺页率的因素有如下几点：
页面大小，进程分配所得的物理块数目，页面置换算法，程序本身（较好地体现程序局部性，即存在明显的热门数据，热门代码的程序缺页率低）

## ⭐️页面置换算法

缺页发生，且内存中并无空闲块，此时就要发生页面置换，即将已经存在于内存中的某个页面置换到外存，将要用的页面置换进来。而如何选择那个已经存在内存中的页面，就要靠页面置换算法来决定了。

一个不合适的页面置换算法会引发这种现象：刚开始内外存分别有A、B两个页面，下一个时刻，AB互换变成了BA，再下一个时刻，发现又要用A了，于是再将A置换回来，再次变成AB。如此，频繁地置换页面，浪费大量计算资源。这种现象也被称为页面置换的“抖动”。

下面介绍一下各个算法

- 最佳置换算法

  ```
  需要指出，最佳置换算法是一种理论算法，目前还无法实现，是页面置换算法性能的天花板，同时也是用于评价其他实际算法的标杆。
  最佳置换算法假设在某一时刻我们可以识别出内存中已经存在的所有页中，在未来最长时间内不会再次被使用的页面，将其作为被置换页面置换出去。
  
  显然，目前的技术水平尚无法确定到底哪个页面在未来最长时间不会被使用，因此是个理论算法。
  ```

- 先进先出（FIFO）算法

  ```
  顾名思义，这是将内存看做是一个页的队伍，当要挑一个祭天的时候，就挑最早进来的那个。
  ```

- 最近最久（LRU）未使用算法

  ```
  LRU算法是什么样的就不说了，从思考上来说，这是一种将 “最近的过去” 用来近似 “未来”，从而逼近最佳置换算法的手段。
  另外，为了实现LRU，还需要硬件支持。硬件可以是寄存器或者栈。
  ```

- 最近最少使用（LFU）置换算法

  ```
  顾名思义，该算法将过去一段时间内访问次数最少的页作为祭品。
  具体的，该算法和LRU一样需要硬件支持。他要对每个页安排一个寄存器。该寄存器用来统计一个极短时间间隔内页面是否被访问。
  所有寄存器的值每隔一段时间t后右移，最后经过n个t后寄存器中值最小的那个页面，就是过去n*t时间内，使用最少的页。
  
  能够实现LRU的一套硬件，也可以拿来实现LFU，两者很相似。
  ```

- 简单Clock置换算法（也称NRU算法）

  ```
  要求额外的硬件使得LRU并没有那么容易实现。而Clock置换算法是一种不需额外硬件的LRU近似算法。
  该算法中，利用请求页面体系中，页表中某个页的 访问位 。
  具体原理是，安排一个指针从头到尾再从头，循环地扫描所有页。我们知道，当某个页被进程访问后，这个页的访问位置1。
  而Clock指针扫描到一个页，若其访问位是1，则说明最近有进程使用过他，因此给予其留在内存的机会，不过将访问位置0，并继续向下扫描。
  相反，若某个页访问位是0，则说明在上次置换之后，这个页最近一段时间没人用过，因此可以将其祭天。
  
  这种算法也是找了最近未使用页，所以称为NRU算法。
  究其本质，其实是对页表的一个循环扫描，循环扫描相当于把页表看成一个环状结构了。于是指针就像钟表上的分针一样，一圈一圈地扫描页表，因此称为clock算法。
  ```

- 改进型Clock置换算法

  ```
  我们知道，对于某个被置换出去的页来说，如果 修改位 是1的话，说明其滞留内存期间被修改，因此置换出去之后需要重写外存中这个页的副本；否则不用。
  那么显然，优先考虑置换那些未被修改过的页出去是比较合理的。于是有这么一个策略：根据 访问位A和修改位M两者的值不同将页分类：
  1. A=0, M=0
  2. A=0, M=1
  3. A=1, M=0
  4. A=1, M=1
  对这四种，优先扫描第一种页，若有祭天。扫描过程中不改变任何。
  第二轮，扫描第二种页，若有祭天。扫描过程中将所有扫描过的页的A置0。
  第三轮，将所有页A置0，重复第一轮寻找第一种页的扫描，若有祭天。扫描过程中不改变任何。
  第四轮，若前三轮都没有找到合适的页，则第四轮重复第二轮扫描，即找第二类页。理论证明，此时一定一定可以找到一个页祭天了。
  
  改进型Clock和简单Clock相比，由于需要多轮扫描性能上会差一点。
  ```

综合考虑以上各种页面置换算法后，改进型Clock虽然性能略弱，但是效能不错，是一个比较好的综合选择。

## 抖动与工作集

### 抖动

在请求分页存储管理方式下，一个固定内存的系统，其CPU的利用率随着内存中同时存在的进程数上升而呈现先上升再下降的趋势，即存在一个使得CPU效率最大化的 “合适进程数”。

而在进程数很大的时候，CPU的利用率接近0。这就是因为系统发生了上面说过的，因为过于频繁的页面置换而引起的抖动。
抖动的根本原因就是，分配给每个进程的物理内存块数过少，导致进程为了继续运行不得不频繁地进行页面置换，而页面置换又是需要进行磁盘IO操作，因此过于频繁的置换导致系统几乎就在空转。

### 工作集和抖动预防

因为程序对数据和代码访问都具有局部性。因此，在某一个时刻接下来的一段时间内，要访问的页面可能是相对比较集中的。于是我们就可以将这部分未来访问可能性很高的页面集合，称为工作集。实际上，我们无法得知未来的情况，所以和页面置换算法中的最佳置换与LRU之间关系类似，采用过去的一段时间来近似估计未来。

换言之，过去一段时间内（称为窗口时间）的被访问的多个页整合成工作集。那么工作集有什么用呢？将其融入到页面置换的算法中，就可以减小抖动出现的可能性。除了工作集，还有如下这些方法可以预防抖动发生：

- 采取局部置换策略：在可变分配局部置换的内存分配策略下，当某个进程发生抖动后，因为局部置换使得其可置换的页都是自己的页，所以一个进程发生抖动不会“传染”其他进程。在全局置换策略下则有这种风险。
- 使用L=S准则调节缺页率
- 暂停部分进程以腾出空间

# I/O系统

I/O是输入输出的意思，I/O系统是OS重要的一个组成部分。以上介绍的OS相关的内容，核心是CPU及其一系列组件，以及主存即内存。而为了计算机能够有效的工作，除了这部分核心之外还要再外部接设许多外部设备，这些设备称为I/O设备，I/O系统就是OS的一个子系统，管理这些I/O设备的。

> 老打/有点麻烦，下面就直接用IO来表示"I/O"了

## IO系统的大致架构

IO系统横向上，管理很多不同的IO设备。现代计算机，有些IO设备默认出厂时就带上了，比如硬盘、键盘、网卡等。还有一些IO设备则可能需要在使用的时候通过系统预设的接口进行通信，比如打印机、CD光盘等。

IO系统纵向上，从上至下，又可以分成硬件和软件两部分。
硬件部分，最底层的当然是IO设备本身，在最紧贴IO设备的往上一层，有一个叫做设备控制器的小硬件。其中含有保存相关IO设备指令的寄存器和保存这些指令的参数的寄存器。IO请求到这里就是转化成具体的指令，通过调用寄存器中的指令来实现IO操作。
硬件部分再往上，是一个软硬件接口层。
再往上，顾名思义，就是软件部分了。IO系统软件部分从下向上大概又分成中断处理程序、设备驱动程序、设备独立性软件。
再往上，还有一层OS与IO系统之间的IO接口。这层接口通常也是根据具体IO设备不同而不同。比如存储类的设备的接口叫做块设备接口、键盘等的又叫做流设备接口。

至此就是IO系统的顶了。IO系统从上至下表示如下：

```text
IO接口（块、流、网络等）
设备独立性软件
设备驱动程序
中断处理程序
软硬件接口
设备控制器
IO设备
```

## 自底向上各层介绍

### IO设备

IO设备，正如上面所说的，就是各种各样的可以被接在电脑上或者已经接在电脑上的外部设备。

按照用途分类，IO设备可以分为存储类设备（磁盘、软盘、CD等）、输入设备（键盘、鼠标、扫描仪等）、输出设备（打印机、绘图仪s等）、交互设备（显示屏）。
稍微严格一点分，==IO设备又可以分为块设备和流设备（字符设备）。块设备是指数据通信单位是以数据块为单位的，比如磁盘、光盘之类的存储类设备；流设备则指数据通信单位是字符流，如键盘鼠标等。通常流设备的传输效率比块设备要低很多==。
网络，或者说网卡，也是一种流设备。

> 按照传输速率分又可以分为低速设备（键盘鼠标等每秒只能传递几十几百个字节的）、中速设备（打印机等每秒传输几万个字节的）、高速设备（磁盘等）。

### 设备控制器

关于设备控制器，没必要知道太多。首先需要记住，设备控制器是操作IO设备的“手”。CPU和IO设备之间互相通信，全部要经过设备控制器作为中转。
因为设备控制器要控制设备硬件，所以其本身内部也含有可以执行逻辑的芯片和寄存器。

设备控制器内部通常含有三类寄存器：

- 命令寄存器：CPU发来命令时就存入命令寄存器，由设备管理器读取后执行
- 数据寄存器：类似的，CPU发来的数据存放在这里
- 状态寄存器：设备控制器将正在工作或者工作完成之类的状态写在这里，供CPU读取

其实就可以把设备控制器看做是单独控制相关IO设备的一个小CPU。它和主机的大CPU进行通信，从而让大CPU有通过小CPU控制IO设备的能力。

到此还没完，我们知道CPU发来数据的速率那肯定是很快很快的，而IO设备的处理速度又如刚才提到的，很慢。所以设备控制器中通常还会设置一个缓冲区，以提高通信的效率。

最后还有一个问题，CPU到底是怎么和控制器通信的？有两种办法，稍早的时候，每个控制器都会被OS分配一个IO端口号，CPU通过识别IO端口号来个特定的控制器发送信息。
另一种办法是内存IO，即，将控制器中的几个寄存器全部都映射到内存中去。这样CPU只要读写内存，就可以实现和控制器的通信了。

### 中断机构

上面说了CPU和控制器可以通过如内存IO等方式来通信。但是没说明具体的通信时机。比如一个IO任务做完后，控制器会将状态寄存器置为已完成。难道为了知道任务完成没，CPU要时不时去check一下这个寄存器吗？
显然，更好的办法是让控制器通知CPU，已完成这件事。于是就有了中断机构。

关于中断，我们首先需要知道，整个流程如下：
==首先，一个进程发起IO请求，之后系统将其阻塞，进入阻塞态。==
==收到IO请求后的控制器开始进行IO操作，操作完成后由控制器发送一个中断信号到CPU，CPU将保存当前正在运行的进程的信息，接着自动执行中断处理程序，处理完成后再次加载刚才运行的进程的断点，继续运行。最后当然别忘了，把发出IO请求的进程，从阻塞态重新变为就绪态==。

这里说的中断都是一般意义上的中断，由设备控制器、或者说硬件发起，所以也叫硬中断、外中断。
另一方面，CPU内部发生一些事时也会引起中断，比如发生了非法指令、地址越界等。此时也要做和外中断流程一样的事情。
只不过这里，中断是由CPU内部引起的，所以也成为内中断、软中断。内中断也可以称为陷入（trap）。

- 多重中断的处理方式

  当CPU正在运行一个中断的处理程序时，发生了另一个中断，此时会有两种处理模式。
  第一、屏蔽中断。即让新来的中断等着。
  第二、嵌套中断。将现行中断处理程序也中断，从而运行新中断处理程序，套娃。

### 设备驱动程序

设备驱动程序正如其在模型中的位置，是IO系统高层与设备控制器之间的中间层。用来做一些翻译、校验的工作。

翻译，就是指把上层系统发来的，抽象的IO请求如read, write等转化为具体的适用于该设备的操作。显然设备不同所以具体翻译方式也不同。这也导致每种外设都需要独特的驱动程序。
校验，则是指比如检查上层的IO请求的合法性之类的。

### 更先进的I/O控制方式

IO控制方式是指CPU和IO设备间的通信模式。上面介绍了一种通信模式，中断。但这并非在所有场合中都最好。
因为==设备控制器通常以字节为单位进行IO操作，所以每完成一个字节的操作，就会发起一次中断信号。可想而知，对于磁盘读写这块设备IO任务，因为数据量很大，会频频中断，导致CPU效率减低==。

于是，针对磁盘读写等任务，有人开发了新的IO控制方式称为DMA（直接内存访问）。
在DMA中，在设备驱动层面，额外增加了一个DMA控制器。其和设备控制器差不多，有一些寄存器，有自己的芯片。他的工作，是让磁盘控制器每操作完一个字节的数据后，不发中断信号给CPU，而是直接将数据或者完成信号放到内存中。相当于`CPU -> 磁盘控制器 -> IO操作 -> 中断 -> CPU -> 中断处理程序 -> 数据入内存`这个流程被简化成`CPU -> DMA控制器 -> 磁盘控制器 -> IO操作 -> DMA控制器 -> 数据入内存`。
==抽象地说，DMA控制器就像是CPU的一个代理，CPU只要告诉他，去读写磁盘，完了CPU自己就可以去干其他事情，剩余工作全部交给DMA控制器即可==。考虑到DMA控制器也是一个小CPU，所以这就像是专门为读写磁盘安排了一个CPU，从而让大CPU可以更加专注于其他计算任务。现代IO设备几乎都已经标配了自带的DMA控制器。

上述整个流程张这样：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210714221822162.png" alt="image-20210714221822162" style="zoom:50%;" />

或者表示成这样：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210715111619707.png" alt="image-20210715111619707" style="zoom:50%;" />



## 键盘敲击A后显示屏显示A，发生了什么

接下来我们来看看，当你在键盘上敲击物理按键A时，整个系统发生了什么。

敲击按键后，键盘控制器会产生扫描码数据，并将其缓存在键盘控制器的缓冲区中。键盘是个流设备，所以一个扫描完一个字符后立刻向CPU发送中断请求。
CPU接到中断请求后，保存CPU现场，转而进入中断处理程序。键盘的中断处理程序在键盘驱动程序安装时就已经注册，其功能是将键盘控制器的缓冲区中的扫描码转换成计算机可以理解的二进制数据，比如字符“A”自然就会被转换成A对应的ASCII码。
这个ASCII码会被放入内存中的“读缓冲区队列”。至此，键盘的工作就结束了。

接下来，是显示器工作部分。显示器的控制器会定时检查“读缓冲区队列”，发现有需要输出的内容时，就发起中断，显示器的中断处理程序将队列中内容读取到显示器的缓存里，并且指示显示器在屏幕上显示这些内容。至此，整个流程结束。

## 多路IO复用模型

> 详情见网络篇。这里也顺带再记录一次。
>
> 再次强调，这种多路IO复用模型通常都是在网络IO场景中，即每个描述符都是socket的情况下讲。因为这是最贴合实际的，比如一个服务器想要处理10000个客户端连接（C10K问题），必须得使用这种多路且复用的IO模型才能保证性能。
>
> (1) https://zhuanlan.zhihu.com/p/367591714

### IO过程

根据上面的介绍以及网络篇中讲到的相关内容可以知道，一个进程通过IO读写数据（可以指读取文件，或者读取网络发来的一些包数据等）大概分成两个过程。以读数据为例：
1.让磁盘控制器准备数据。这个过程磁盘控制器将通过DMA中介，将数据写入内核空间的缓冲区中。
2.通知进程数据准备完毕，进程将内核空间缓冲区中内容再复制到用户空间的缓冲区中。（顺便一提，两个缓冲区都在系统内存的Cache即Page Cache中。

但是，第二步，“通知进程数据准备完毕”这件事没有细讲。
实际上，进程并非被动等待通知，否则就又变成了阻塞的IO方式，DMA的设置没有了意义。==这里，进程是主动发起IO系统调用，开启一个新的线程去检查数据是否准备完毕==。以下，“数据准备完毕”这件事我们用术语称为IO描述符就绪。

另外，这里还有一个问题需要考虑。以上所有说明都默认进程当前只有一个IO描述符（一个文件，一个网络包等），但实际上，一个进程可能对应着很多很多描述符。这就需要有一个多路的概念。顺便一提，在Linux上一个进程下属的描述符都维护在了`/proc/<pid>/fd`中，这里面是一些指向相关文件的硬链接。
另一方面，比如你有100个描述符，开100个线程去分别处理显然不太合理。所以这里我们还需要使用复用的概念。即用一个线程就把这些都处理了。

综合以上两方面，IO过程中需要有一种机制，进行多路且可复用的IO就绪描述符处理。这就是这里要介绍的内容。

### 支持多路复用IO的系统调用

大致上总共有三种`select`，`poll`，`epoll`。

#### select

多个描述符，其实互相关系是并列的，所以select方法中用一个数组将他们维护起来。
现在问题变成了，数组中的一些元素处于已就绪状态，如何找出他们呢？一个最朴素的办法，就是全扫描一遍，然后将已就绪的标记出来即可。显然，这种算法的复杂度是`O(n)`。

这就是select的基本思想了。更加具体的，==上面说的这个数组，平时处于用户空间中，当进程发起select系统调用，进程自然进入内核态，随后会将这个数组复制到内核空间，进行扫描。扫描完成后，再将标记出的描述符重新复制回用户空间。==

需要注意，select申请的这个数组，大小受到了Linux内核参数`FD_SETSIZE`限制，默认值是1024。因此select方法下最多只能维护1024个描述符。若想要扩大，需要修改源码并重新编译内核。

#### poll

poll和select基本类似，只不过poll用了链表而非数组来组织描述符。由于链表不限制长度，因此突破了1024的限制。
但是另一方面，进行就绪描述符检查的工作仍然是`O(n)`的，同时也需要进行描述符的 用户空间 -> 内核空间 -> 用户空间 的复制转移过程。

#### epoll

epoll全称是event poll，即基于事件视角的poll。

顾名思义，这是一种发生事件（描述符就绪）而后callback的机制。具体来说，epoll模式总共有`epoll_create`，`epoll_wait`和`epoll_ctl`三个接口。（select和poll都只提供了一个同名的函数作为接口）
`epoll_create`用于初始化，其直接在内核空间建立了一个红黑树与一个就绪链表。
`epoll_ctl`用于向上述红黑树中添加新的描述符。此时描述符还会被注册callback过程。当描述符对应的数据准备完毕，进入就绪状态后，会自动调用注册了的callback，将其转移至就绪链表中。
`epoll_wait`则是负责读取就绪链表，将其中的描述符复制到用户空间。如此用户空间就有了所有就绪的描述符，达到了select和poll一样的效果。

### 多路IO复用模型进阶

关于上面三种模式，特别是epoll，还有不少可以讲的。

#### epoll为什么要红黑树

因为`epoll_ctl`这个接口，以及一些其他的IO操作中，经常要用到搜索。即针对所有描述符，查找某个描述符是否已经存在。
而是用红黑树，可以让搜索效率提升。
通常，描述符有一个统一的递增编号（比如文件的话是文件的inodeID之类的），同时时不时的又会有一些描述符要从集合中删除。所以可使用红黑树这种数据结构来进行组织了。

#### 关于触发方式LT和ET

触发方式分成LT（水平触发，也是三种模式下默认的触发方式）和ET（边缘触发，仅epoll支持）两种。

上面我们说某个描述符就绪后，通过三种模式中的一种，会被复制到用户空间中。
接着，进程应该就会使用系统调用`read`，对描述符中的相关内容进行读取。
但是注意，这里有可能不读取完。若没读完，是否将其重新放回描述符集合中。更深入的说，下次这个描述符来数据的时候，我该从上次的断点开始读，还是直接读取新数据？

这些问题就和出发方式有关。
==LT下，只要描述符中还有未被读取的数据，那么每次进行IO系统调用，这个描述符就会再被拿出来。相当于每次调用系统都在提醒你去处理这些描述符中的内容。==
==ET下，每个描述符在来新数据之前，即便被多次IO系统调用，也只有第一次的时候会被返回。为了避免信息丢失，这也要求程序每次都必须将描述符中的信息读取完。==

==ET存在的意义是这样：一个进程下面的各个描述符，可能有好多都处于就绪状态但无需读写（比如共用的描述符等）。若使用LT，这些描述符每次IO系统调用时都会冒出来，浪费了不必要的算力和内存。而ET，则可以保证这些东西不会重复出现。==

#### epoll的优点

epoll已经成为事实上通用的IO多路复用的解决方案了。这主要是因为其具有很多优点。

==首先，最显而易见的一点，epoll不是使用`O(n)`轮询的办法进行检查描述符，而是采用了事件驱动，复杂度可以认为是`O(1)`的，其只关心“活跃”的描述符。从这一点来说，epoll的效率不随描述符总量增长而改变，只会随着活跃的描述符增长而改变，这也比较贴合实际的网络场景。==
另外，与select相比，其当然也没有描述符最大数量的限制。

另一个epoll更加好的角度是内存的拷贝过程。select和poll都涉及到描述符集合在用户空间和内核空间之间的拷贝，而epoll用到的数据结构直接在内核空间中建立，==并且还使用了mmap将这块空间与用户空间共享，避免了数据在两者之间的拷贝。==

#### epoll的局限性

epoll也并不是完美无缺的。事实上，若描述符整体数量较少且活跃（经常会有新数据）比例较高，此时可能更加直白的select或者poll整体性能会比epoll更好。

#### 这些方法与阻塞/非阻塞IO、同步/异步IO的联系

上述介绍的三种方法，其实都是局限在IO过程的第2步，即将准备完成的数据从内核空间拷贝到用户空间的过程中。
并且，无论使用哪种方法，都只是将就绪的描述符筛选出来，至于后续的读取过程，是同步还是异步，以及IO过程第1步（磁盘控制器准备数据阶段）进程是否阻塞等，都没有直接关联关系。

# Linux文件系统

Linux的系统理念有一个是“一切皆文件”。文件系统管理了Linux中不仅仅是普通的文件和目录，还包括了块设备、管道等等。

## 文件系统基本知识

对上述定义的广义的文件，==文件系统会给每个文件都创建两个东西，inode和目录项==。

- inode是文件在文件系统中的唯一标识，内容包括 inode编号、文件大小、文件权限、创建/修改时间、block指针等。inode本身和文件内容一样都存放在磁盘中。
- 目录项（注意是目录项，不是目录）是记录了文件名、inode指针、一个父目录指针与一个子目录/文件指针列表。目录项不存放与磁盘，而是内核维护在内存中的一个数据结构。

除了上述两种meta信息，磁盘当然还需要用来实际保存内容的部分。一般意义上的磁盘最小读写单位为512B，是一个扇区。目前Linux流行的文件系统，通常都是把8个扇区看做一个整体进行读写，因此实际文件系统读写的最小单位是4K，称为一个数据块。

刚才说inode也会存放在磁盘中，其实一块磁盘在最开始格式化的时候，会被分成三份，分别称为超级块区、inode区和数据块区。超级块区是一些块的meta信息比如块个数、块大小、还有多少块是空的等。

==当系统需要访问某个文件时，其先从内存文件的目录项中找到inode指针，然后再去加载inode块到内存，找出inode块中的block指针，最后去block中读取数据==。上述整个架构如下图所示：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210716204034948.png" alt="image-20210716204034948" style="zoom:50%;" />

## 文件的使用

说到读文件，用`open`函数，再简单不过了。然而细究一下，使用open函数打开文件时到底发生了什么。
准确的说，因为打开文件要去IO磁盘，所以肯定要通过系统调用进入内核态去做这件事的。

打开文件后，内核还会跟踪每个被打开的文件，具体的，还记得进程拥有的资源里有“打开的文件句柄”这一项么。没错，所谓跟踪，就是将文件的“文件描述符”放到进程的“打开文件表”中去。这里的文件描述符也是上面提到过的IO描述符的一种。

文件描述符的具体内容是

- 文件指针：指向进程读写到的文件中的位置
- 文件打开计数器：一个计数器计数多少个进程打开了该文件。计数器归零时这个文件描述符可以被移除
- 文件磁盘位置
- 访问权限

## 文件的存储

这章主要解决的问题是，文件存储在磁盘里后，如何从磁盘读取出完整正确的文件。

之前说过，文件的存储以块为单位。因此，就和内存一样，在将文件存储到磁盘中去的时候会有很多种不同的分配块的方案。类比内存，大的可以分成、连续存放方式和离散存放方式。而离散存放又可以分成链表式和索引式。（其实光看到这都些名词就基本可以脑补出这些方式的具体工作模式了。

### 连续存放方式

连续存放方式中，文件头信息很重要。比如类似于inode的信息结构中，应该可以保存 文件的起始位置 与 文件的长度。这样，只需要无脑从头读取到尾，就可以读出文件所有内容了。

但另一方面，很显然，连续存放方式存在 磁盘空间碎片化 以及 文件长度不易扩展 等问题。

### 离散分配方式之一 链表

链表方式很好脑补，文件头只需要给出开始块，每个块额外安排一个指向下一个块的指针，最后一个块指向None，这就成了一个简单的链表。然而这只是链表方式中的“隐式链接方式”。

还有一种“显式链接方式”，其将隐式中的所有指针都收集起来，统一放在内存的一张表中管理，这个表被称为文件分配表（FAT）。FAT是一个连续表，其`table[i]`项维护的内容，是磁盘中编号为`i`的块的下一块的编号。这样，只要知道某个文件开头的块的编号，不断地访问这个表找出下一块编号，最终就可以读完整个文件。

隐式连接方式中，系统无法立刻指定读取块而只能从头开始一个个块遍历，并且每个块还需要额外安排一点指针空间来存放指针。
显示链接方式克服了上述两个缺点，并且由于一个个块向下找的过程全程在内存中完成，速度很快。但是其要将所有块都一一对应地维护在内存中也就意味着这种方式不适用于比较大一点的磁盘。

### 离散分配方式之二 索引

索引方式的做法是这样的：
首先，针对每个文件创建一个索引数据块，其中存放指向文件各个块的指针。如图所示：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717100557026.png" alt="image-20210717100557026" style="zoom:50%;" />

注意到，索引数据块本身占据一个磁盘块（这也是索引方式的缺陷之一）。而磁盘块大小有容量，如果文件很大，则分块很多，自然指针也会很多，多到一个磁盘块放不下，此时就要考虑混合使用多种方式了。

首先一种是索引+链表的方式，简单来说当某个索引块满了以后，就新开一个索引块并且前一个索引快用一个指针指向新索引。如此，索引块之间用链表，索引块和数据块之间用索引的方式：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717100912803.png" alt="image-20210717100912803" style="zoom:50%;" />

另一种可以考虑的组合是索引+索引。和很多类似的情况一样，采用二级索引的办法，即安排一个索引块的索引块。

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717101008223.png" alt="image-20210717101008223" style="zoom:50%;" />

### Linux中的文件存储方式的实现

在Linux的Ext2/Ext3格式的文件系统中，文件存储方式主要基于索引的存储方式。同时为了能够应对大文件每个文件的文件头除了10个直接指向数据块的指针外，还有一个指向另一个索引块的一级索引指针，一个指向另一个二级索引块的二级索引指针，一个指向三级索引块的三级索引指针。如图所示：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717101440734.png" alt="image-20210717101440734" style="zoom:50%;" />

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717101459530.png" alt="image-20210717101459530" style="zoom:50%;" />

如此，==文件头即inode块中，共有13个指针。其中直接指针10个，一级、二级、三级指针各一个==。
==上图假设一个索引块可以保存`n`个数据块指针的话（注意，索引块本质是数据块，而不是inode块，比inode块还是大多了），那么一个inode块可以对应到的最大的文件，其可以有`10 + n + n^2 + n^3`个数据块==。

若在32位系统中，且一个块大小为1K，所以其总共可以保存`1024 / (32 / 8) = 256`个指针。三级指针一算，总数据量超过`256 ^ 3`K，也就是16G。
即，在上述前提条件下，一个ext2/ext3文件系统中文件的最大大小是16G。

## 空闲空间管理机制

上节主要针对如何分配空闲空间给文件数据做出讨论。但是在那之前，还得解决一个问题就是找到哪些块是空闲的？一个最简单的方法是遍历一遍所有块，但是这肯定不显示，所以这节引入空闲空间的管理机制。空闲空间管理总共下面几种常见的办法。（由于磁盘中不是已经使用的空间就是空闲空间，所以空闲空间的管理某种意义上和分配空间的方式是等价的。因此可能会有很强既视感）

### 空闲表法

在内存中为所有空闲空间维护一张表，表中每一项都是空闲空间的始址以及空闲空间的长度。
显然，空闲表法维护的是连续的空闲空间。与其配合使用的空间分配方法是连续分配的时候还好点，如果是离散分配，那么磁盘中必然会有很多碎片，这就导致空闲表很长，很难维护。

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717102509279.png" alt="image-20210717102509279" style="zoom:50%;" />

### 空闲链表法

和分配方式一样，既然连续方式很僵硬，那就用离散的。离散的第一个想法，就是链表法。
链表法中，每个空闲块都安排了一个指针指向下一个空闲块，当要分配空间的时候，从整个空闲链表列头上依次取下一些空闲块使用。

又和分配方式类似的，空闲链表法的问题在于只能顺序访问，指针在链表上的移动需要比较大的开销。

### 位图法

位图法是指用一个二进制位表示每个块的使用/空闲情况。这样，比方说一个512G的硬盘，每个数据块是4K的话，只要16M的空间，就可以将每个块的使用情况表示出来了。（512G的4K块共有1.34亿个左右，每个块一个二进制位，则表示所有块二进制位的空间需要`1.34亿 / 8 = 16MB`）

事实上Linux就是使用位图法来维护块的使用情况。除了数据块，别忘了磁盘里还有大量inode块，inode块也是用位图法来维护的。
块的位图也是放在磁盘中的（考虑到比如需要拔下磁盘插到别的主机上去，位图信息必须跟着磁盘走）。当分配空间或者回收空间发生，需要对位图进行修改时，先将位图从磁盘读取到内存，修改完成后写回磁盘。

## ⭐️Linux文件系统中磁盘组织形式

仔细想想，位图法是否还有问题？
其实上面提到，位图本身也放在磁盘里，即放在磁盘数据块中。这也就意味着，一个块中的位图，比如4K块，最多也只能维护128M（1个块共有`4096*8`个bit，每个bit对应一个数据块的话，总共可维护空间是`4096 * 8 * 4096`K即128M）空间的数据块的使用情况。
当然，串列使用多个块也可以，但是这样就会对寻址等造成一些麻烦。

Linux的Ext2文件系统的解决办法，是干脆把数据块、数据块位图、inode块、inode块位图、以及一些meta信息给整合成一个块组。通过把磁盘分成若干个连续的块组的形式来组织磁盘。大概长这样：

![image-20210717104404257](/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717104404257.png)

上述各个组件解释如下：

- 引导块：系统启动时进行启动引导和初始化，固定为1024字节。
  引导块只在安装了操作系统的主分区硬盘或逻辑分区硬盘中有。主机开机后，最先加载主引导记录（MBR）中的bootloader程序。MBR的bootloader接着扫描各个分区的引导块并加载引导块中的bootloader，从而加载安装在这个分区中的操作系统。
- 超级块：==包含了文件系统整体的一些meta信息比如inode块、数据块的总个数，每个块组的inode块、数据块总个数等。是在块组中了解文件系统整体情况的一个途径==。
- 块组描述符：==包含了各个块组的信息如各块组内有多少inode块和数据块是空闲的等。这是在一个块组中了解其他块组情况的一个途径==
- 数据位图、inode位图：即本块组内数据块和inode块的位图。
- inode列表：块组内的inode块区。
- 数据块：块组内的数据块区。

注意到，每个块组中，超级块和块组描述符表两部分信息其实都是一样的。这一方面是考虑到信息冗余作为副本，另一方面也是方便在存储大文件时从一个块组直接跳转到另一个块组。

## Linux中的目录信息存储

我们知道目录在Linux中也被视为广义的文件。而且前面说过，目录和普通文件的区别在于普通文件的数据块中存放的是数据，而目录的数据块中存放的是其中的子目录和文件的指针。

更详细的来说，==目录数据块可以是一个`文件inode，文件类型（子目录还是子文件），文件名`的列表==。如此，想要查找某目录下的某特定文件，只要根据其文件名搜索列表，找到文件的inode，然后去寻址就可以找到文件了。
值得一提的是，Linux的目录都默认自带一个`.`和一个`..`分别代表当前目录和上级目录。这俩在目录数据块中也都存在。

由于目录中可能有很多很多子目录，导致上述目录的数据块中维护的列表过长，从而查找效率下降。为了解决这个问题，==现代文件系统中也将文件类型是子目录的列表项单独列出来，组成一个哈希表==。这样，如果你是想查找当前目录下某个子目录，直接去哈希表里，就可以用`O(1)`的时间找到了。

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717112305651.png" alt="image-20210717112305651" style="zoom:67%;" />

另外，目录的层级可能很深，一层层找下去的过程中需要频繁地反问各层目录的数据块，总IO效率太低。
所以如前面所说，所有文件都保存了一个目录项在内存中。只要第一次通过磁盘层层寻找找到文件后，将这部分信息放在内存中，后续再找只需要从内存中直接找文件的inode即可。

## ⭐️软硬链接

==我们知道在系统中看到的一个文件名，其实是一个指向该文件inode块的指针==。当我们想要给文件取别名的时候，就会有硬软链接两种方式。

==硬链接：创建另一个指向同样inode块的别名指针==。
此时，由于inode块还是那个inode块，所以即使将原文件从系统中删除（本质上是打断了原文件名指向文件inode块的链接），通过新建的指针，仍然可以访问到inode块，从而访问文件内容。

> 这里还有一个小知识点：只有当指向某个inode的文件名全部消失，这个文件才会被系统删除。有点像引用计数的意思。

硬链接如图所示：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717115639025.png" alt="image-20210717115639025" style="zoom:50%;" />

==软链接：创建一个独立的文件（自然有独立的inode和数据），这个数据的具体内容是指向了一个路径==。因此通过软链接读取文件的逻辑是，先找到软链接本身的inode，从而找到其数据，其数据是一个路径，因此访问那个路径，再找到源文件的inode和数据并读取。
由于软链接是严格只和一个绝对路径关联，所以当我删除源文件后，软链接仍然存在但是已经无法读取到相关文件了。
软链接如图所示（图中感觉有点不太对，从软链连回源文件的箭头应该是从软链的数据块上出发，而不是软链的inode上）：

<img src="/Users/wyzypa/Pictures/TyporaImages/操作系统教科书笔记.asset/image-20210717120447873.png" alt="image-20210717120447873" style="zoom:50%;" />

## 文件I/O

文件的I/O就是指将内容从文件中读出来或者将内容写入文件这么一件事。然而就这么一件事，具体的做法却可以分成好多好多种。比如：

### 直接IO与非直接IO

==简单来说就是一句话，用不用内存中的Cache作为缓冲区进行文件IO。如果不用那就是直接IO，如果用了那就是非直接IO。==

读文件时，CPU直接将文件内容从文件读取出来后，写入用户程序的内存空间，就是直接IO；如果中途在内核内存空间，即Cache中落地，再从Cache中拷贝到用户程序的内存中，那么就是非直接IO。

写文件时也类似，CPU直接从用户程序的内存中获取要写入的内容并且交给磁盘控制器去写入，那就是直接IO；如果是先把这部分内容复制进内核空间内存的Cache，然后由内核决定某个时候一起将Cache中内容写入文件，就是非直接IO。

在一般程序中，除非特别指出`O_DIRECT`标志，否则默认的IO都是非直接IO。因为在Cache中落地数据可以减少磁盘IO的次数从而提升读写速度。

### 阻塞/非阻塞IO 与 同步/异步IO

这是两组不同的概念，且比较容易混淆。以读取文件为例，先来说说阻塞/非阻塞IO。

当用户程序调用了`read`读取某个文件时，首先进程会进入内核态，然后发起IO请求，磁盘控制器将接收IO请求，读取数据到缓存区，读取完成后通知CPU读取数据。此后，CPU会先将数据复制到内核的内存空间中，即上面说过的Cache。最后再将Cache中的数据拷贝到用户程序的空间中，完成读取文件的操作。
==上述流程大体可以分为 1.内核准备数据过程 2.内核将数据从内核空间拷贝到用户空间过程 两个阶段==。如图：

![img](https://pic3.zhimg.com/80/v2-89162cb4d5cc7fe4071ade36d3000d8a_720w.jpg)

阻塞IO，就是指当用户进程发起IO请求后，进程就被阻塞，一直等到上述1和2两个阶段全部完成，才解除阻塞，读取数据往后运行。
非阻塞IO，是指用户进程发起请求后，在1阶段开始后进程并不阻塞而是可以继续往下运行。在合适的时候，进程可能会调用之前提到过的多路复用IO模型的方法，检查数据是否准备完毕。若OK，则进行2阶段。这个阶段进程还是会被阻塞，或者说是同步的，直到2阶段完成数据从内核空间被拷贝到用户空间后，程序继续往下运行。

可以看到，==阻塞/非阻塞IO之间，效果上最主要的区别是两者是否在阶段1开始时被阻塞。而两种模式，对于阶段2的运行，还是无可避免地需要等待==。

另外，上述非阻塞IO的描述中，阶段1开始之后虽然不阻塞但是还是要轮询检查阶段1是否结束，效果上和阻塞也差不多。其实这里可以应用IO多路复用模型，调用比如select/poll/epoll之类的多路复用函数。这样，阶段1完成后系统会通知进程来处理，期间进程就可以去干其他事了。

不论是阻塞还是非阻塞IO，两者在发起`read`后，将数据从内核空间拷贝到用户空间的过程都是同步的，需要等待的。这也说明两者都属于同步IO这个大范畴内。

相对的，==异步IO的两个阶段，都是不用等待的==。
异步IO通过系统调用`aio_read`进行。调用后，函数立即返回，因此程序可以接下来去做其他事。而上述阶段1、2的执行和主线程没有关系。直到阶段1、2全部完成，此时内核才会通知主线程，让他来处理这些数据。
显然，异步IO是完全异步的，因为阶段1和2，两个阶段都不用等待。

# 其他零碎内容

## 按下开机键后发生的事

1. 主板通电
2. 主板上有个BIOS芯片，芯片中存放着一些写死的程序。（更高端的有UEFI，UEFI提供彩色的启动界面）BIOS程序首先进行通电自检，检查各个硬件（尤其是内存，因为要把磁盘上的OS读取到内存当中）是否正常。
3. BIOS加载bootloader（引导程序）到内存。bootloader是存放在Master Boot Record(MBR)中的程序。因此BIOS可以直接读取到。
4. 由bootloader选择相应的操作系统，启动操作系统。操作系统接管整个计算机。t
