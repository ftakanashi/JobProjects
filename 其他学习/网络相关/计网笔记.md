#就活笔记 #网络

# ⭐️OSI的七/四层模型

现代网络通信通常将网络以分层模型建模。分层的好处是层之间隔离性、灵活性、易于维护、促进标准化等。

七层模型从上到下以及各个层级下的代表性协议分别是：

```
应用层     HTTP, FTP, DNS, TELNET, DHCP, POP3...
表示层     JPEG, ASCII...
会话层
传输层     TCP, UDP
网络层     IP, ICMP...
数据链路层   MAC, ARP, RARP...
物理层
```

将上三层合并可以成为新的“应用层”，将下两层合并可以成为“网络接口层”，每一层数据单位的名字是:

```
应用层
传输层				段（segment）
网络层				包（package）
网络接口层		 帧（frame）、比特流
```

两者的关系：四层是七层的一种简化，也是实际使用如TCP/IP协议族下的模型。七层模型是理想化理论模型。

## 每层作用和设备

 ![image-20210706105927695](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210706105927695.png)

## 每层的工作状态

TCP/IP五层模型中，应用层工作在用户态，传输层及以下工作在内核态。

# 应用层诸协议

## SSH基本

> https://zhuanlan.zhihu.com/p/46235721
>
> https://zhuanlan.zhihu.com/p/108161141

SSH协议也是应用层协议，基于TCP传输，用于提供登录会话与文件传输等服务的加密通信。
OpenSSH是一种开源的SSH协议实现，广泛应用于各种Linux系统，提供登录、SFTP等服务。

### SSH连接过程

以从客户端（C）通过SSH连接登录服务端（S）为例，整个登录过程大概可以分成两个阶段：连接阶段和验证阶段。下面来详细说一说。

#### 连接阶段

1. 协议协商

   C发起TCP连接请求，经过三次握手后与S先建立TCP连接。
   随后S向C发送自己支持的协议版本，C响应确认，返回自己选择的某个版本。S接到确认后决定使用的协议版本以及加密算法等。
   若无法协商得到双方都支持的版本则断开TCP连接。

2. 身份确认、会话密钥协商

   接着，S会将自己的主机公钥，以及其选择的加密算法和其他一些信息发送给C。
   C接到后，可用主机公钥对S的身份做简单验证（第一次访问时会要求输yes保存信息，后续只是简单的和这个信息做对比）。
   另一方面，==C和S会基于Diffie-Hellman算法进行会话密钥的生成。这个算法简单来说，是在双方多次通信之后，使得双方各自都保有一部分对方的公有信息以及另一部分自身的私有信息。此时可以在双方各自内部独立生成一个共通的会话密钥==。大概的原理如图所示：

   <img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/v2-f4522aefeae10ed7084e9fe4f13d121f_1440w.jpg" style="zoom:33%;" />

   会话密钥生成后，就是后续双方通信用的对称密钥。

#### ⭐️验证阶段

验证阶段就是验证用户的登录信息是否正确。登录可以用密码或者公钥。密码登录时只需要用会话密钥加密密码发送，S解密后对比密码是否一致即可。这里只介绍公钥的情况。

在连接阶段结束后，C将自己的登录用户名，发送给S进行登录验证请求。
S接到请求后，先检查`authorized_keys`中是否有与C的签名匹配的公钥。若没有拒绝登录，若有，则随机生成一个字符串str，将其用C公钥加密后发给C。
C接到后用私钥进行解密得str，并用会话密钥和str一起做一个散列。发送给S。
S接到散列后的哈希值，在自己这也用会话密钥和str散列，对比两者结果。若结果一样，验证通过。

之后，S和C之间，就可以愉快地用会话密钥进行加密通信了。

#### 总结

==整个登录过程，涉及到了三类密钥==。

| 密钥          | 生成时机                               | 作用                                           |
| ------------- | -------------------------------------- | ---------------------------------------------- |
| S的主机公私钥 | 在安装SSH服务软件时生成                | 让C验证S的身份是否属实<br />辅助会话密钥的生成 |
| 会话密钥      | 连接阶段生成                           | C和S间通信加密用的会话密钥                     |
| C的登录公私钥 | C事先生成好，并且将公钥放到S的指定位置 | 让S验证C的身份                                 |

### 常见的加密算法总结

SSH连接过程中可选的加密/散列算法很多。下面是一些加密算法的总结。

- 对称加密算法

  对称加密算法主要包括DES和AES两大类。其中AES从各个角度来说都更好。
  AES具体包括了AES-128, AES-192, AES-256等。后面的数字指的是密钥的长度。

- 非对称加密算法

  常见的费对称加密算法包括RSA，DSA，ECC等。
  RSA是DSA的升级版，也是目前最为常用的算法之一。ECC是尚在开发完善中的一种新算法，主要改善了RSA计算时开销较大的缺点。

- 散列算法

  常见的散列算法包括MD5，SHA-1，SHA-256等。这几种算法最明显的区别在于哈希映射空间的大小，即哈希出来的字符串的长度。
  MD5算法产生一个128位（16字节，常用32个16进制数表示）的哈希串。目前MD5已经被证明哈希碰撞可能性较大，不再适用于安全领域。
  SHA-1指第一代SHA算法，产生一个160（20字节）的哈希串。最新研究也表示不再安全。
  SHA-256是SHA-2即二代SHA算法的代表性例子。二代SHA算法用更长的空间表示哈希，SHA-256自然用了256位（32个字节）表示

## DNS基本

==DNS是应用层协议，DNS查询本身基于UDP进行传输==。DNS就是做域名解析的协议。

### DNS多级缓存与查询过程

解析过程中会涉及很多缓存内容，若缓存有命中，则可以不去DNS服务器请求解析，加快解析速度。缓存包括了：

```
浏览器缓存
系统缓存（如/etc/hosts等）
路由器缓存
ISP服务器缓存
根域名服务器缓存
顶级域名服务器缓存
主域名服务器缓存
```

当试图解析一个域名时，系统从上至下依次去访问这些缓存。前两个很好理解，就是计算机本地带有的一些缓存信息。

第三个路由器缓存，是指路由器本身通常会带有一些域名解析记录，从而路由器本身可以作为局域网内的一个DNS服务器。对局域网内的DNS服务器发起解析请求，只需要ARP解析其IP成物理地址，然后再局域网内发起访问即可。

若局域网内DNS没有找到解析记录，则转到ISP服务器，这是指网络接入商提供的一个DNS解析服务器。通常一般的DNS解析到这里大概率能找到答案。若还是没解决，则ISP服务器将会和国际上通用的DNS服务器进行联系。现在假设访问的地址是`mail.cctv.com`。这个地址可以分成三个层次：`mail.cctv.com`是三级域名、`cctv.com`是二级域名、`.com`是顶级域名。

第一步，ISP服务器先行联系根域名服务器。根域名服务器不直接返回解析结果（这和解析模式是迭代还是递归有关，这里以迭代为例说明），而是返回一个顶级域名服务器地址，比如这例中的负责`.com`系列顶级域名的服务器。
第二步，ISP服务器再请求顶级域名服务器，顶级域名服务器也不直接返回解析结果，而是返回一个负责了`mail.cctv.com`的主域名服务器地址。
第三步，请求主域名服务器，这次主域名服务器中有相关解析记录，返回给ISP服务器。ISP服务器将IP记录到本地缓存中，并且返回给用户。

### 递归解析与迭代解析

上述ISP服务器解析地址的过程中，其实存在两种方式。递归和迭代。

递归方式解析，指ISP服务器接到请求后，去请求更高层级的服务器A。而服务器A接到请求后若无法自己解析，再去递归地请求更更高层级的服务器B。如此一层层递归下去，直到找到后再一层层返回到ISP服务器。

迭代方式解析，指ISP服务器接到请求后，去请求更高层级的服务器A。A接到请求后知道接下来要去请求B，但是它不自己做而是将B告诉ISP服务器，意思是“你自己去找他”。如此，是ISP服务器跑好几个办事窗口最终找到记录，称为迭代方式。

### 基于DNS的负载均衡

一般负载均衡，在DNS层面是无法感知的，通常DNS都将域名解析到负载均衡器上。

而基于DNS的负载均衡是指，在DNS服务器上设置同一个域名解析到多个不同的IP地址，这些IP地址形成一个后端集群。当有大量访问来袭时，按访问顺序轮转返回解析结果，从而尽可能把多个请求平均分配到后端各个IP上。

这也就是基于DNS的负载均衡策略。和一般的软件负载均衡策略相比，DNS负载均衡比较容易实现、配置。但是负载策略的灵活性很小，基本只有轮询策略。

更多关于负载均衡的信息，看那个专题笔记。

### DNS中的UDP和TCP

不同层级的DNS服务器之间，进行数据的交流和同步，基于TCP。因为TCP可靠且一次性可以传输的数据量大。

客户端向DNS服务器发起DNS解析请求时，因为通常只要一次性通信并且数据量不大，所以使用更快的UDP。

# ⭐HTTP基本

## HTTP的各类方法

前三种方法由HTTP/1.0定义，后来HTTP/1.1又追加定义了六种方法

| 方法    | 描述                                                         |
| ------- | ------------------------------------------------------------ |
| GET     | 请求指定信息的页面                                           |
| HEAD    | 类似GET，只是返回响应无响应体，只获取报头                    |
| POST    | 提交数据并请求服务端进行处理。POST会发两个包，一个包含头信息，一个包含数据信息 |
| PUT     | 提交数据（完整）覆盖原数据。                                 |
| PATCH   | 提交数据（部分字段）覆盖原数据。                             |
| DELETE  | 请求从服务器删除指定页面。                                   |
| OPTIONS | 允许客户端查看服务器当前性能。                               |
| TRACE   | 回显服务器收到的请求，主要用于测试和诊断                     |
| CONNECT | HTTP/1.1中预留给能将连接方式改为管道方式的代理服务器。       |

### ⭐️GET和POST有什么区别

- 规范上来说，GET用来请求数据，POST用来修改数据
  - GET纯粹是读取数据，因此理论上是幂等的。基于此，==<font color="red">浏览器一般对失败的GET会自动重发</font>==。如果你的逻辑用GET进行了数据增删改操作，可能就会引起重复操作的风险。因此还是要遵照规范进行操作。
- GET将请求参数直接合并在URL中，通常浏览器会对URL长度做限制（如2K，注意这是浏览器的限制而非HTTP本身限制，原因是处理长URL开销大且容易引入安全风险）因此GET能够提交的参数也受到限制；POST将请求放在HTTP的请求体中，理论上参数不受限制。
- GET产生一个数据包，将header和body一起发送。若服务端处理成功，则响应200；==POST产生两个数据包，先发送header，服务器响应100 continue，再发送body，服务器响应200==（注：这种行为不是HTTP协议规定，只是一些实现是这样）。
- GET请求会被浏览器自动缓存，而POST默认情况下不自动缓存。
- POST方法和GET方法在安全性上并没有区别。虽然POST的数据没有写在明面URL上，但是其数据包并没有加密，只要截取，就能看到数据。要安全，只能用HTTPS

## HTTP中的缓存控制

为了加速响应，减少重复计算，HTTP通信中存在多种缓存机制。
离用户最近的，自然是浏览器的缓存。再远一点，代理服务器也可以有缓存。更远的，根据后台的架构，源服务器可能也会带有缓存，甚至后台就有专门进行缓存响应的缓存服务器。

在HTTP中使用/控制缓存主要通过HTTP报文中的`Cache-Control`字段。
在HTTP请求的报文头中，`Cache-Control`可以设置为`no-cache`，`no-store`等值（其他的不写了）。`no-cache`表示客户端要求服务端不直接使用缓存，而是请求源服务器获取最新数据。`no-store`表示客户端要求本次请求服务端不要保存任何数据进缓存。
在HTTP响应的报文头中，也有`Cache-Control`字段，这次比较值得注意的是其值可能是`public`和`private`。分别用来指示本次返回的缓存内容是多用户可见的，还是就当前用户可见。

> 更多HTTP缓存相关内容，可参考：https://blog.csdn.net/u012375924/article/details/82806617

## ⭐️HTTP常见状态码

| 状态码 | 类别             | 类含义                             |
| ------ | ---------------- | ---------------------------------- |
| 1XX    | 信息性状态码     | 告知客户端接收了请求正在处理       |
| 2XX    | 成功状态码       | 告知客户端请求正常处理完成         |
| 3XX    | 重定向状态码     | 需要对客户端请求进行重定向再做处理 |
| 4XX    | 客户端错误状态码 | 因客户端请求的问题，无法处理请求   |
| 5XX    | 服务端错误状态码 | 因服务端内部的问题，无法处理请求   |

更具体的说说各个类别的代表性的码。

- 【100 Continue】收到请求的初始部分，要求客户端继续发送剩余部分。通常出现在比如客户端想上传一个大文件，正式上传前先发送一个请求问一下是否可行，当服务端认为可行就返回100，提示客户端可以。不行则可能返回【417 Expectation Failed】
- 【200 Success】成功，返回了数据
- 【204 No Content】成功，不返回任何数据
- 【301 Moved Permanently】资源被永久重定向到新路径，以后应该从新路径访问
- 【302 Found】资源正临时性被重定向到新路径
- 【400 Bad Request】客户端请求报文中有语法错误
- 【401 Unauthorized】客户端未提供HTTP认证信息。浏览器碰到401后通常会弹出用户名密码输入框
- 【403 Forbidden】该客户端对该资源的请求被禁止了。通常返回信息中会有更具体的禁止原因
- 【404 Not Found】请求的资源不存在
- 【405 Method Not Allowed】请求的资源不允许客户端请求的方法访问。
- 【500 Internal Server Error】服务器内部错误，通常是web程序bug了
- 【502 Bad Gateway】通常在有代理、网关服务器等情况下给出。表示其无法从上游的应用服务器获取到资源
- 【503 Service Unavailable】服务器停机维护中，无法提供服务

## HTTP报文头中常见字段

- Host: 目标主机，通常是域名或者IP
- Content-Length: 数据长度，通常出现在HTTP响应中
- Connection: HTTP/1.1以后默认都是keep-alive了，但是为了兼容老版本，通常显式地加上keep-alive值
- Accept：C端明确自己接收什么格式的内容，`*/*`为任意格式
- Content-Type：S端明确本次响应的数据格式内容，例：`text/html; charset=utf-8`
- Accept-Encoding：C端明确自己接收什么样的压缩方法，例：`gzip, deflate`
- Content-Encoding：S端明确本次响应的数据压缩方法，例：`gzip`
- User-Agent：C端指出发起访问的设备、软件是什么。可以用作简单的DDos流量筛查。

## Session和Cookie

HTTP协议是==无状态的==，这主要是为了让HTTP数据处理方便一些。HTTP/1.1引入了Cookie来辅助性地保存状态。
无状态，是指服务端和客户端之间无法识别对方。比如服务端接收到第一个请求并处理，若客户端发送第二个请求，服务端无法得知这个请求与上一个是同一个客户端发出的。

### Cookie

Cookie本质是==服务器发送到用户浏览器并保存在本地的一小块数据==。之后，每次访问同一服务器时，浏览器会将这块数据一并带上。如此，服务器就可以通过Cookie中的信息识别客户端的身份，从而解决了无状态的问题。

经常使用Cookie的场景有==会话状态管理（如登录状态等），个性化设置（个性化的主题界面等），浏览器行为跟踪==。值得注意的是，曾经Cookie常用于存储大量的客户端数据，后来随着发展，很多浏览器都单独推出了客户端数据存储功能，于是就不用Cookie来存储这么重量的信息了。

==Cookie根据有效期，可以分为会话Cookie（在关闭浏览器后失效并被删除）和持久Cookie（保存在磁盘中，在指定失效期前持久有效）。==

#### Cookie安全性的提升

由于Cookie是不加密保存在客户端的，因此安全性得不到保证，提升Cookie的安全性就很有必要。思路大概可以分成以下几个：

- 对Cookie中的信息进行加密

  手动对信息加密可以避免Cookie攻击者获得后直接被破译信息。当然这么做仍然无法防范攻击者使用这个Cookie冒充身份。

- 设置Cookie属性Secure为true

  这样可以让Cookie在传输到服务端的过程是加密的。保证传输过程的安全。但是同样无法防范冒充。

- 为Cookie设置合理的有效期

  具体的方式可以是利用Cookie本身的过期机制，或者在Cookie中写上时间戳然后在服务端判过期等。反正就是尽量减短有效期，尽可能保证Cookie不会被盗用

总的来说，Cookie由于其本身机制的原因，很难做到真正的安全（比如杜绝冒用等）。
因此上述措施也都只是尽可能地保证安全，对于有意的攻击者，最好的办法就是别用Cookie。

### Session

Session也是用于解决HTTP无状态这个缺点的。不同的是，Session将要保存的信息以键值对的形式存放在服务端。至于具体在哪里由架构者自己选择，通常可以存放在文件、内存，也可以存放在诸如Redis之类的软件中。

以登录状态为例，用户发送登录请求后服务端进行校验，通过后将用户信息保存在Session中，并且生成一个Session ID，将其通过响应报文中的`Set-Cookie`头字段返回给客户端，并让客户端将这个ID保存在Cookie中。之后客户端再请求时，只要带上SessionID，服务端就可以识别客户端了。

乍一看，Session本质上还是得要依赖于Cookie，感觉很鸡肋。实际上，Session机制下服务端和客户端之间交流的额外数据只有Session ID而没有实际的数据内容（which单纯Cookie机制中可能要传输），因此更加安全。==当然，SessionID也有可能会被盗用，应对这方面安全问题，通常服务端会比较频繁地更新session ID并且加二次验证之类的办法。==

### 两者区别

```
1. 本质上，保存位置不同，Cookie在客户端，Session在服务端
2. 因为Session信息在服务端，更安全
3. 因为Session信息在服务端，过多session影响服务器性能
4. 因为Session信息在服务端，可以存储更加复杂的数据object，Cookie一般只存储ASCII码
5. 因为Session信息再服务端，通常存储容量更大。Cookie大小、个数则受到浏览器限制
```

### 如果禁用了Cookie，Session还能发挥作用吗？

以上描述中提到了==使用Session机制还必须要让前端把sessionID给上传。而SessionID通常可以用Cookie来保存。==
==当Cookie被禁用了，显然就不能用Cookie来保存SessionID了，此时可以用其它办法比如URL里带上SessionID之类的==。
因为Cookie本身就是无加密的，所以从安全性上来说，这两种方式没有本质区别。

## HTTP各版本

目前，HTTP主要有了1.0, 1.1, 2.0, 3.0这些版本。简单记录下各个版本都有什么特点。

- HTTP 1.0

  最早的HTTP协议版本。以现在的标准来看很多方面都很拉胯

- HTTP 1.1

  ==引入了长连接（keep-alive）以及异步请求==。
  原来发送一个HTTP请求都要建立一次TCP连接，并且在第一个请求得到回应前第二个请求无法发出。
  现在一个TCP连接可以复用给多个HTTP请求，并且请求异步。

- ⭐️HTTP 2.0

  ==2.0版本的HTTP协议自动基于HTTPS（包括了TLS协议在体系内）==。
  报文头不再是每个请求必须有，==通信双方都保存了一些头信息在缓存中，在装包拆包时直接取缓存中数据。==
  1.1中请求虽然异步了，但仍然是串行发送的。==2.0中串行改为并行==。
  ==增加了服务器推送机制==，当客户端请求某个静态文件时，服务端自动把客户端可能用到的一些其他静态文件也提前推送给客户端。

- HTTP 3.0

  目前仍然还在开发中。
  详细不说了，将HTTP基础的TCP改成了UDP（当然为了保证可靠传输，多加了不少东西）

### 如何开启HTTP2.0

实际项目中，通常这个工作由Web服务器来进行实现，而不涉及后端web应用的代码修改。
比如用Nginx的话，可以在开启HTTPS的前提下，往server的listen字段配置中加入http2参数，自动开启http2.0，如：

```nginx
server {
    listen 443 ssl http2 default_server;
 
    ssl_certificate     server.crt;
    ssl_certificate_key server.key;
    ...
}
```

# HTTPS基本

HTTPS就是HTTP + SSL/TLS。
简单说说两者的区别：HTTPS在HTTP外面套上一层安全壳，互相之间的传递的信息报文被加密从而不易被第三方读取。HTTPS需要额外的SSL证书和CA证书、端口通常是443。

## 什么是SSL/TLS

SSL是安全套接字层。他是用于加密和验证客户端-服务端通信数据的协议。其加密机制综合并用了不对称、对称加密两种方式。
TLS是SSL的另一种叫法（更准确的说是标准协会对SSL进行了标准化后得到的东西，其实两者只是同一事物的不同阶段的称呼。严格来说现在应该都叫TLS协议了，但是习惯上还是叫SSL）

### 【旧】~~SSL建立连接的流程~~

> 更严格详细的流程，看下面TLS四次握手

1. 客户端发起SSL连接请求，协商加密算法、摘要算法等
2. 服务端发送公钥（S~pub~）给客户端
3. 客户端用S~pub~加密送通信的对称密钥C，并发送给服务端。这个密钥每个会话生成一次，也称会话密钥。
4. 服务端用私钥S~pri~对C进行解密，得到通信用对称密钥。
5. 之后，服务端和客户端对任何通信数据，都使用共同知晓的对称密钥C进行加密解密。
6. ==客户端发送数据时，除了明文，还将明文的哈希值计算出来作为“摘要”，与明文共同加密传送==。服务端收到后解密，并计算收到数据的摘要，比对客户端提供的摘要。两者一致则说明数据未受到篡改。

上面这个流程，并非绝对安全。比如有一个黑客劫持了2中的S~pub~然后将自己的公钥H~pub~发送给客户端。此时客户端并不知情， 就会将C用H~pub~加密发送给黑客，黑客经过解密，可以知道C的内容。然后再将其用S~pub~加密发送给真的服务端，黑客隐身。这么一来，黑客就能偷窥到之后服务端和客户端之间的通信了。

换言之，==若SSL中服务端的公钥被篡改，则还是会发生安全风险==。这个问题的解决办法是将公钥放进一个由第三方认证过的证书。可以这么理解：第三方是可信任的，而他会把上述可能被篡改的公钥本身 用第三方自己的私钥加密。作为用户，我们可以获取到第三方的公钥，只要这个公钥可以解密这段内容，那么这段内容一定可信，因此就一定是可信的，没有被篡改的。

## HTTPS的好处

- 加密（防窃听）：由会话密钥的加密实现
- 认证（防伪装）：由CA证书的背书实现
- 完整性保护（防篡改）：由摘要算法+摘要比对实现

## HTTPS用到的证书

HTTPS建立连接的过程中，服务端要向客户端发送服务端的公钥以保证生成会话密钥前的机密性。
==而公钥传输的载体，是服务器的HTTPS证书。从功能上来说，该证书保证了其中保存的公钥的确是相关服务器的公钥，从而保证了安全==。

一个HTTPS证书包含了如下内容：

```
服务器的公钥
证书持有者信息
证书认证机构（CA）信息
CA对这份证书的签名算法
证书有效期
其他一些信息
```

更具体的，HTTPS证书需要CA（Certificate Authority）即证书认证机构的认证才有效。
==CA机构是现实中绝对可信的机构，他们会给每个通过认证的HTTPS证书签名（用私钥加密），并且开放公钥给公众。
当某个客户端想要验证某个HTTPS证书的可靠性时，只要拿来CA的公钥（通常被保存在了本地缓存）验证一下签名是否正确即可==。若证书内容被篡改过，则签名验证就通不过。

### 证书的层级

通常考虑到安全性以及签发效率等因素，CA机构不可能仅仅靠一个密钥就签发所有证书。
通常的实践是采用层级证书的方式。

也就是说，CA机构有一个根证书。根证书带有的密钥签发了一批带有密钥的中间证书。即用根密钥保证了每个中间证书的密钥的可信性。接着再由中间证书的密钥签发底层的HTTPS证书。

比如百度的`baidu.com`的证书，可以看到其签发者并不是根证书而是中间证书。由于我们的浏览器一般只保留根证书的密钥，所以此时根据百度证书中签发者的信息，我们再去请求到中间证书。
由于中间证书由根证书签发，所以可以用根证书的密钥验证其签名，从而信任之。
由于可以信任中间证书，所以可以信任由其签发的百度的证书。

 <img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210802232817999.png" alt="image-20210802232817999" style="zoom:67%;" />

## ⭐️TLS四次握手流程

上面简单讲了TLS建立连接的流程。实际上TLS根据事先方式不同，建立连接的机理也不太一样。最常见的TLS，基于RSA密钥进行加密连接，过程中需要收发消息两次，相当于四次握手。下面以此为例来详细说一下四次握手每次都干什么。

==另外需要注意，TLS连接建立在TCP连接基础上。因此到达这个时间点时，TCP三次握手已经完成==。

先放上图：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210806123332407.png" alt="image-20210806123332407" style="zoom:80%;" /><img src="/Users/wyzypa/Pictures/TyporaImages/逆袭进大厂计网篇笔记.asset/image-20210806123443270.png" alt="image-20210806123443270" style="zoom:80%;" />

### 第一次握手

第一次握手也成为Client Hello。
客户端将生成一个随机数C，随同客户端支持的TLS版本以及加密算法版本一起发送给服务端。

### 第二次握手

第二次握手也叫Server Hello，是服务端对Client Hello的回复，也是确认协议版本等的协商结果。
服务端会生成随机数S，返回选择的客户端某TLS版本以及某加密算法。至此，协议和算法的协商完成。
上述信息，外加上服务器的HTTPS证书，被打包发送给客户端。证书中含有服务器RSA公钥。

#### 验证证书

客户端接收到二次握手包后，先进行证书的验证。如上面所说，客户端用绝对可靠的CA公钥对证书上CA机构做的签名做验证，以确保证书没有遭到篡改。
验证通过后即可取出证书中的服务器RSA公钥。

### 第三次握手

此时，客户端上有了C、S这两个随机数，也有了服务器RSA公钥。
接下来，客户端会再生成一个随机数叫做pre-master。用RSA公钥加密后，发送给服务端。

==此时，服务端上有了C、S、pre-master三个随机数。而客户端也有这三个随机数。==
记着，两端都按照最开始协商好的算法进行会话密钥的生成。不出意外，两者应该是完全一致的。

接着，客户端继续发包（虽然和之前的包是不同的，但是仍属于第三次握手的范畴），
这次包中带有一个Change Cipher Spec提示，表示后续通信都将用会话密钥加密通信。
还带有一个Encrypted Handshake Message Finished消息，这个消息是将之前所有握手信息做一个摘要然后用会话密钥加密后的产物。

### 第四次握手

服务端收到三次握手包的后半部分后，会用会话密钥解密摘要并比对。若顺利，则表明服务端的解密和客户端加密都没问题。
而服务端也返回最后一次握手，内含会话密钥加密了的Encrypted Handshake Message Finished消息。
最终，客户端也将确认客户端解密与服务端加密无误。

四次握手结束后，双方将利用会话密钥，进行加密的HTTP通信。

# ⭐️TCP基本

TCP是最常用的传输层协议之一，与网络层的IP协议形成了实际上现实中互联网的基石TCP/IP协议组。

## TCP报文段内容

TCP段分为头部和数据部分。数据部分是指从上面应用层封装好传递下来的数据，而头部则是本层传输层额外包裹的一些信息。分析TCP协议的各种东西时，主要关注头部中的信息及其变化。头部数据大概长这样：

![](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/70.jpeg)

- 源端口、目的端口：顾名思义

- 序号(**seq**, 32bit)：主要标识本数据段在整个TCP数据流中的位置。通信建立时，seq初始化成一个随机数（Initial Sequence Number, ISN）。==之后每个段的seq都是`初始值 + 已经发送的字节数`。这样就保证了段之间互相有序==。

- 确认号(**ack**, 32bit)：接收方对发送方的TCP响应，为收到的段的序号+1

- 标志位(6bit)：这是六个1bit的开关位，如下：

  ```
  URG: 表示紧急指针是否生效
  ACK：表示确认号是否有效，即表示段是否是一个回应确认的数据段。事实上除了建立连接和断开时部分数据段，所有数据段这个位置都是1
  PSH：完整写法是PUSH，提示接收端立即从缓存中读取数据
  RST：要求对方重新连接（复位报文段）
  SYN：表示请求建立一个连接（连接报文段）
  FIN：表示关闭连接（断开报文段）
  ```

- 窗口 (16bit)：告知对方本机的缓冲区还有多少剩余。解决流量控制问题。
- 校验和(16bit)：用于检验报文段有无数据损坏。
- 紧急指针(urgent pointer)：指一个偏移量。序号+这个偏移量，是紧急数据的开始。紧急数据，指正常通信过程中，由于突发情况而想要高优先级传输给对方的信息。比如想要提前中断传输。

### 大小限制

==TCP/IP协议族下的一个传输单元（IP数据包）最大大小称为**MTU (maximum transmission unit)**，通常由硬件决定，大概在比如1500字节。==
除此之外还有一个概念叫==最大分节大小 **MSS (maximum segment size)**，这个值是指一个IP数据包中数据部分最大的值。通常等于MTU减去TCP头部（20字节）和IP头部（20字节）两部分信息==。

## ⭐️⭐️TCP连接

### 三次握手

![](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/70.png)

- 第一次握手

  ```
  客户端发出TCP段，SYN=1，seq=初始化随机值x
  客户端状态：CLOSED 变为 SYN_SENT
  ```

- 第二次握手

  ```
  服务端发出TCP段，SYN=1，seq=另一个初始化随机值y，ACK=1，ack=x+1
  服务端状态：LISTEN 变为 SYN_RECV
  ```

- 第三次握手

  ```
  客户端发出TCP段，seq=x+1，ACK=1，ack=y+1
  客户端：SYN_SENT 变为 ESTABLISHED
  (收到后)服务端：SYN_RECV 变为 ESTABLISHED
  ```

#### 三次握手的意义

通俗的说，握手的意义在于==<font color="red">**双方都可以确认自己&对方的发送/接收功能正常**</font>==。

第一次握手成功，S可以确认：C发送功能正常、S接收功能正常。
第二次握手成功，C可以确认：S发送/接收功能正常，C发送/接收功能正常（因为第一次发送的包确实被S收到了，所以C发送正常）

此时C已经完全确认，可S还无法确认C的接收、S的发送功能是否正常。因此需要第三次握手。
第三次握手成功，S确认了C接收功能，S发送功能正常。

==若不进行第三次握手，可能会出现以下情况（迟到的首个一握包）==：

```
C发送了第一个请求连接包a一段时间后无响应，于是发送第二个包b重连。b到达了S，于是CS间连接，并且正常通信完成。
结束通信后，a包终于到达了S，S进行回应。若只有两次握手，那么这个连接就建立了，而显然，C不会向S传送数据。
这么一来，S上就多了一个永远不会有数据，但是却一直开着的连接。
```

#### 三次握手如果异常怎么办

这里，异常指发出请求后一直没有回应的情况。

- 第一次握手异常
  即发出SYN包后服务端一直没回应。此时客户端会每隔数秒后重复尝试发送，在尝试过一定次数（Linux默认5次）后放弃连接并报超时错误。值得注意的是这里每次间隔的秒数还不一样，第一次是1秒，之后是呈指数级上升的。

- 第二次握手异常

  这也是SYN攻击中常见的套路了。和第一次握手异常类似，第二次握手异常即服务端的SYN+ACK包无响应时，服务端也是同样的尝试5次重传，时间间隔也是指数上升。5次后若还是失败，则放弃该连接，将其移出半连接队列。

  DDos攻击就是发出大量握手包的同时，不给予第二次握手的回应。导致服务端会维护大量连接在半连接队列中。而半连接队列一旦塞满，就丢包其他主机发来的正常的连接请求包，从而攻击者达到了瘫痪服务的目的。

- 第三次握手异常

  第三次握手发出后，服务端处于SYN_RECV而客户端已经处于ESTABLISHED。服务端这边，正如前面提到的那样，服务端不断尝试重传SYN+ACK包，但5次没反应后就舍弃了连接。因此大概一分钟后，服务端的SYN_RECV连接会被删除。

  另一方面，客户端这里分成两种情况讨论。
  情况一，若客户端如果在发出ACK包后无其他动作，根据TCP的保活机制（TCP的keepalive，下面会详细讲），需要在相当长（2小时左右）一段时间后，TCP发现本连接已经死亡，从而断开连接回收资源。
  情况二，正常来说客户端ACK发出后，会直接开始发数据了。然而发出的数据不会被已经关闭连接的服务端收到，因此就变成了普通的超时重传机制。通常Linux配置的超时重传是15次，即尝试15次后如果仍失败，则断开连接。

#### 三次握手其他

- 半/全连接队列：S端处于SYN_RECV的状态时，相关连接信息被放入一个称为“半连接队列”的队列中。而那些已经完成三次握手的连接放在“全连接队列”中。全连接队列满时，若C发起新的连接请求可能导致丢包。
- 携带数据问题：三次握手中，==第三次握手可以携带数据，因为C接收到第二次握手的包时就意味着连接已经建立。前两次握手则不允许携带数据==，因为如果允许，那么就意味着接收方必然需要处理这些数据（至少得安排内存来保存），若我是攻击者，就可以发送大量握手包，来攻击对方的内存。

### 四次挥手

![](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/70-20210708093118050.png)

C或S端都可以主动发起关闭连接，从而进入四次挥手流程。主动发起关闭连接一方称为主动断开方，另一边则是被动断开。以C主动断开为例：

- 第一次挥手

  ```
  客户端发出TCP段，FIN=1，seq=u
  客户端：ESTABLISHED 变为 FIN_WAIT_1
  ```

  服务端收到第一次挥手包后，通知应用程序进行连接关闭操作。异步地，发送第二次挥手的包。

- 第二次挥手

  ```
  服务端发出TCP段，seq=v，ACK=1，ack=u+1
  服务端：ESTABLISHED 变为 CLOSE_WAIT
  （收到后）客户端：FIN_WAIT_1 变为 FIN_WAIT_2
  ```

  进入FIN_WAIT_2状态后，C就没有了数据发送能力，但仍然保持数据接收能力，可以接收来自S最后发送的一些数据。

- 第三次挥手

  应用程序将连接关闭后，发生第三次挥手。

  ```
  服务端发出TCP段，FIN=1，seq=w，ACK=1，ack=u+1
  服务端：CLOSE_WAIT 变为 LAST_ACK
  ```

- 第四次挥手

  ```
  客户端发出TCP段，seq=u+1，ACK=1，ack=w+1
  客户端：FIN_WAIT_2 变为 TIME_WAIT，持续2MSL，TIME_WAIT 变为 CLOSED
  （收到后）服务端：LAST_ACK 变为 CLOSED
  ```

#### 四次挥手的意义

- 为什么不是三次是四次？

  四次挥手的包分别是FIN, ACK, FIN-ACK, ACK。和握手比较后发现多了第二个ACK包。
  这个现象的根本原因是，关闭连接需要进行进程处理一些后续工作，比如将缓冲区中剩余未发出的报文发完。
  因为这些工作需要一些时间，所以==暂且先给出一个ACK包回应，旨在说明“你的FIN包我收到了，现在正在尝试关闭连接”==。而真的关闭连接后，才能发送FIN-ACK，说“你的FIN包我收到了，我也可以关闭连接”。

  相对的，握手的时候服务端没有什么额外工作要做，所以在收到客户端的SYN包后直接可以回复SYN-ACK说明“你的SYN包我收到了，我也同意建立连接”。

- 2MSL是什么，有什么意义？

  > MSL全称Maximum Segment Lifetime，即报文最大生存时间
  >
  > 默认C和S间传递一个报文最久只能是这个时间上限。超过这个上限则认为丢包。

  设置2MSL等待时间的原因是防止下面这样的情况出现：当C发出第四次挥手包时，S处于LAST_ACK状态。若此包中途丢失了，作为S来说，因为没收到最后一个ACK包，所以需要尝试重发第三个挥手包。若没有2MSL等待机制，C此时早已CLOSED，所以不能回应。因此S将永远无法从LAST_ACK变为CLOSED。

  相反，有了2MSL之后，在C发出第四次挥手包后，如果真的丢包了，S会在1MSL后察觉并重发第三次挥手包。此包又会最长花1MSL时间到达C。即，若真的丢包了，只要给C端2MSL的额外时间，C就能知道丢包事实，并且重发第四次挥手包。当然，若重发了，则需要重置2MSL计时器。

  总体而言，2MSL机制是为了给C一段额外的时间，给予其重发第四次挥手包的机会，防止因为丢包导致S端无法CLOSED。

#### TIME_WAIT过多的原因与解决

> https://www.cnblogs.com/whx7762/p/9413787.html

由于TCP连接总是从客户端发起断开，因此传统意义上的服务器可能很少会有这种情况。然而在一些特定场景比如爬虫服务器，其本身虽然是客户端，却要开启大量连接爬内容，此时就有可能发生TIME_WAIT过多的情况。

TIME_WAIT过多的坏处很显然，当大量socket处于TIME_WAIT而滞留时，后续想要新建立连接的客户端，就无法分配到相关socket资源，从而显示连接不上。

通过命令`netstat -nltpa`可以查看机器上所有TCP连接及其状态，如果TIME_WAIT状态的很多，表明这个问题发生了。
解决办法通常是==通过修改内核参数，使得内核可以复用TIME_WAIT中的socket。复用具体是指在某个socket进入TIME_WAIT之后，如果新来的连接请求socket不够用了，就不等2MSL了而是强制收回这个socket，并将其用作另一个连接==。
显然，开启TIME_WAIT复用违背了四挥的设计初衷，会对TCP可靠性做出一定牺牲。

具体做法：一个修改运行中linux内核参数的方法是修改`/etc/sysctl.conf`文件。而具体参数是其中的`net.ipv4.tcp_tw_reuse`。将其置1后，`sysctl -p`刷新参数即可。

#### CLOSE_WAIT过多的原因与解决

相比于TIME_WAIT，查看一下四挥的流程就知道，CLOSE_WAIT过多的根本原因只有一种，就是在被动断开方试图关闭进程时遇到了麻烦。因此，这通常与实际的代码相关，需要检查代码中存在什么问题。

举个常见的例子，比如C端设置的超时断开时间过短，S端还没来得及关进程C端就断开，导致S端一直处于CLOSE_WAIT。
另一种可能，比如数据库服务器S端发起断开连接请求，C端接收请求后代码却无法关闭数据库连接，导致处于CLOSE_WAIT状态。

### TCP连接中HTTP的限制

- 一个TCP连接可以对应多个HTTP请求（只要HTTP开了Connection=keep-alive，那么TCP连接就不会立刻中断，因此可以收发多个HTTP请求）
- 对同一个Host，客户端理论上可以建立非常多的连接。但是考虑到实际的开销问题，实际实现中通常还是有限制的。比如从客户端的视角看，在Chrome的实现中，规定了对一个Host最多只能建立6个TCP连接。
- 到HTTP/1.1为止，多个HTTP请求在一个TCP连接中只能按顺序逐个发送处理，不能混着发。

### TCP的保活机制

上面也简单提到了一下。其实具体来说是这样的。

当一个C和S之间的TCP建立之后，==若C不清楚S是否仍然在线，这时候要分两种情况讨论。即C会不会向S发送数据。==

第一，正常来说是要进行数据传输的。比如C要发出数据给S并且接收来自S的确认。
但是如果此时S已经宕机，显然无法回复确认。此时TCP协议下，C就会开启超时重传。
即一个RTO时间过后仍然未收到确认，那么C就重传数据。重传的尝试次数当然有限制，由`tcp_retries2`参数控制，默认通常是15次。如果15次之后仍未收到确认，那么该TCP连接就会被C关闭。而上述过程其实并未涉及到TCP的保活机制。

真正的TCP保活机制，指的是第二种情况，即网络中没有数据交流时对连接的检测。
网络中没有数据交流自然就不会有确认信息，若不做任何事，C就无从知晓S是否还在线。此时就轮到了保活机制出场。
保活机制有三个参数，各个参数及其默认值是（`sysctl -a`可以查看没有写在配置中的默认内核参数值）

```python
tcp_keepalive_time = 7200
tcp_keepalive_intvl = 75
tcp_keepalive_probes = 9
```

==这三个参数的意思是，如果连接内没有数据传输，达到`tcp_keepalive_time`即默认的7200秒，两个小时，C会开始发送心跳检测包到S以验证其是否还在线。如果S给出回应，那么万事大吉，只需要重置计时器即可。若S迟迟不给回应，则C会每隔`tcp_keepalive_intvl`秒发送一个心跳包，连续发送`tcp_keepalive_probes`个。==
这些包全发完后仍然无响应，就主动断开该TCP连接。按照上述参数的设定，也就是说，在没有数据传输的前提下，TCP保活机制大约会在2小时11分钟多后认为对方已经不在线，因此关闭连接。

以上操作是从C向S探测的视角而言，反过来其实也一样。但是对于服务端来说，显然默认的7200秒有些过长，如果对方早就宕了，那么保持连接那么久显然是对资源的浪费。因此服务端通常要把`/etc/sysctl.conf`中的`tcp_keepalive_time`改小。

## TCP拥塞控制四大算法

> 资料：https://www.bilibili.com/video/BV1c4411d7jb?p=61

==需要指出的是，这节提到的拥塞控制四大算法并不是四个独立可以做到拥塞控制的算法，而是相辅相成，共同组成了TCP拥塞控制体系的四个算法。==

### 什么是拥塞

拥塞，就是指网络过于拥挤导致堵塞。一条网络链路中的资源，包括带宽，交换机等是有限的，但可以请求使用这些资源的传输数据是无限的，于是过多的传输数据和过少的资源可能会引起网络响应时间过长。响应过长又可能进一步引起重传等操作，导致网络更加拥挤，形成恶性循环。更有甚者，还可能引起“竞争消耗性资源的死锁”。

简单来说，就把网络链路想象成普通道路，传输数据就是一辆辆车。如果车过多就会堵车，而一堵车就会有车加塞干嘛的，导致路况进一步混乱，最终导致谁也无法通行。

### 一些基本概念

假定有C和S，C向S发送TCP段数据。具体的发送方式是==“逐轮发送”==。可以简单这样理解：C发送数据时，一轮发送若干个段，并期待收到S的对于这若干个段的若干个确认报文。这个一来一回的时间又被称为RTT (Round-Trip Time)。

于是问题来了，若干个到底是几个？这其实是由C端的一个变量==“拥塞窗口”（cogestion window，简称cwnd）==控制的。顾名思义，C端可以根据当前网络的拥塞情况来动态调整这个窗口，这也是TCP进行拥塞控制的核心所在。
显然，cwnd越大，一个RTT内能传的数据越多，传输效率越高。但是如果网络很拥挤而窗口又过大的话，那么可能会引起拥塞问题。

此外，TCP数据传输中通常有重传机制。即C发送一个段给S后，在重传超时时间后（RTO，Re-Transmission Timeout）仍未收到确认，则自动重传该数据段。称为==“自动重传机制”==。

### ⭐️慢开始 与 拥塞避免算法

下面正式开始讲拥塞控制算法。先讲前两个。

慢开始算法指是，最开始时不能对网络情况估计过于乐观，因此将cwnd初始化为1。同时我们还需要设置一个==慢开始阈值（slow start threshold, ssthresh）==比如16。随后开始传输。
我们将一个RTT内传输了`cwnd`个数据段，并且全部收到了正确的确认报文的情况，称为一个正常的传输轮次。
在慢开始算法阶段，每完成一个正常的传输轮次，`cwnd *= 2`，呈指数速度增大。

当`cwnd >= ssthresh`时，停止执行慢开始算法，转而执行拥塞避免算法。
拥塞避免算法阶段，每完成一个正常的传输轮次，`cwnd += 1`，呈线性速度增大。

上述两个阶段，cwnd都在不断增大。但显然，其不能无限增长下去，到一个比较大的值比如24的时候，C可能会发现轮次不正常，即丢包发生，无法收到完整的确认信息了。
此时，两个算法的策略是：==将cwnd重置为1，并将当前cwnd值的一半设置为ssthresh。随后重新开始执行慢开始==。

慢开始，强调从1开始指数增加负荷，快速逼近网络的承载极限。拥塞避免强调线性增加负荷，谨慎逼近网络的承载极限。

慢开始&拥塞避免两个算法结合，形成了一个简单的拥塞控制体系。这也确实是TCP早期的（1988年左右）实现方案，称为TCP Tahoe。

### ⭐️快重传 与 快恢复

在更新的TCP实现中，在上面两种算法的基础上还引入了快重传和快恢复两种机制。

上面提到，当丢包发生，我们就认为轮次不正常，从而进行拥塞控制。但是在实际网络中，很多时候因为网络抖动会突发丢包现象。这种丢包是偶然的，并不意味网络拥挤。这么一来，直接将ssthresh腰斩，还将cwnd变成1重新开始“慢开始”，会损失很大一部分通信效率。

作为解决办法，在较为新的TCP实现中，引入了快重传机制。新的实现称为TCP Reno。

#### 快重传

上面的描述中，我们认为当C很久得不到发出报文的确认，就默认进行超时重传。而所谓的快重传是指不等超时，而是结合TCP的序列号进行尽快的重传。

假设C向S发送包，0，1，2号发送正常，都收到了S的确认。3号丢包，暂时无S确认。随后发送4号包成功。==按原有套路，S应该给出4号的确认信息。但是按照序号序列来说，S认为你应该给我3号但是却给了我4号，这是不正常的，于是不返回4号确认，而是继续返回一次2号的重复确认。==
同理，C继续发5号包，S仍然返回2号重复确认确认；C继续发6号包，S仍然返回2号的重复确认。此时C这端，==连续收到了三个2号重复确认==。这就是一个快重传的信号，C端此时直接将`2+1=3`号包进行重传。若这次成功，S端接收到了3号包，于是他会返回6号确认，提示C端，按照序列号，一直到6号包位置都成功接收了。以上过程是很快的，通常到这个时间点，仍然还未超出RTO时间。所以这种做法被称为“快重传”。

以上就是快重传机制。一言蔽之，<font color="red">当连续收到三个重复确认时触发快重传</font>。画个图大概长这样：

![image-20210708212926382](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210708212926382.png)

#### 快恢复

发生快重传后，执行快恢复算法策略。具体的，将ssthresh和cwnd两个都设置为当前cwnd的一半，然后开始执行拥塞避免算法，即线性增大cwnd。
有的快恢复实现也会将`cwnd += 3`之后再开始拥塞避免算法。因为发生快重传后，至少有三个包（发生重传的包以及其后两个正常到达S的包）已经离开网络，可以适当加大窗口。

==总体来说，快重传+快恢复是对原来实现中发生重传就直接一下子打回解放前的做法的一种修正。兼具了效率和拥塞控制的做法。==

综合了慢开始、拥塞避免、快重传、快恢复四种机制的发送轮次与窗口大小的示意图大致如下（图中包括了Tahoe和Reno两种机制）：

![image-20210708232934962](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210708232934962.png)

#### 为什么是三次重复确认后快重传？

应该意识到，快重传的触发条件应该是明确判断到了“丢包发生”，可是重复确认机制本质上是进行的“包到达顺序乱序”。
实际上，因为网络抖动问题很多时候会引起包到达的顺序异常，因此要确定一个合适的值。

实践证明，两次重复确认（即`n+1`和`n+2`号包比`n`提前到）的情况由网络抖动引起的概率还较大，而三次基本可以确认是真的丢包而不是网络抖动了。因此确立了“三次重复确认后快重传”的规则。

## TCP流量控制

### 原理与注意点

TCP通信中如果发送方发送速率过快而接收方接收处理数据过慢，就会导致接收方会大量堆积还没确认的包。这些包不多的话可以暂时放缓存里稍后确认，但缓存如果也满了，那么就只能丢包。造成了网络资源的浪费。

==流量控制，就是通过控制发送方的发送速率，来使收发双方处于动态平衡==。

==具体的，接收方每接收一个包并且发送确认信息给发送方时，带上自己的缓冲区还有多少空间这一信息。这个信息也称为“接收窗口”。这部分信息存放在上面TCP头数据构成中提到过的“窗口”段。单位是MSS。==
发送方接到确认，就知道了接收方目前的接收窗口大小，从而调整自己的发射窗口大小，尽量去匹配接收方的接收能力。显然，当接收窗口变成0时，发送方最好不再发送，防止大量丢包。

注意以下几点：

- 以上两种窗口，其单位都和之前提到过的拥塞窗口一样，是MSS，或者简单理解成多少个TCP报文段。

- TCP是双工通信协议，发送/接收双方随时互换角色，因此双方都要有一个接收窗口值，一个发送窗口值，从而保证双方的发送效率都是合理的。
- 发送窗口值并不是和对方接收窗口值设置同样大小，通常考虑到对方告知当前缓冲区剩余大小会会立即开始处理缓冲区，腾出更多的空间来，发送窗口会设置得比对方接收窗口更大一些。

### 与拥塞控制的区别与联系

流量控制和拥塞控制是两回事。
拥塞控制是指对传输的整个链路进行评估，从而动态调整发送的数据量，保证传输效率。
而==流量控制只着眼于发送方和接收方两台主机，是点对点的控制==。
但是显然，两者都会参与到通信控制中，所以一般==对于一个主机而言，其真实发送窗口大小，应该是`min(流量控制中发送窗口大小, 拥塞窗口大小)`==。

## TCP粘包问题

> 参考： https://www.zhihu.com/question/20210025/answer/1744906223
> 业界对于“粘包”这个事情也有一些不同的看法。

TCP粘包，并不是一个世界通用的计数名词，而是国内业界的土话。根据上面那篇知乎回答，所谓的“粘包”，其实可以解释成两种现象。
下面先过一过一些基础概念，然后再来解释一下这件事。

### 面向字节流的TCP、封包与拆包

常说，TCP是面向字节流的，而UDP是面向报文段的。这就有些离谱，上面的描述中TCP发的不也是报文段吗？
其实是这样的：说TCP面向字节流的意思，其实是指TCP发送的实际数据，即TCP报文段的数据部分，是一个字节流。
换言之，只要发送缓冲区中有数据，TCP并不关心你这些数据包括几条消息，有多长之类的，反正就是看做一个连续的流，切1个单位的流出来，套上报文段头，就发出去了。==这个过程也叫做封包==。相应的，接收方的传输层对报文段去掉报头的过程就是拆包。

### 粘包的两种含义

第一种：
程序在应用层通过调用send，将一些数据放入TCP发送缓冲区中。然而TCP是面向字节流的协议，发送时不关心数据的边界，有可能截取上个数据的一部分与这个数据的一部分，组成一个包发送出去。此时接收方调用receive后，发现数据是混着的，不符合其对有明确消息边界的期望，因此称之为一个问题，叫粘包问题。但其实这个更应该叫“粘数据”问题吧。
但是实际上，既然你期望明确的消息边界，则可以尝试用UDP而非TCP，因为UDP是面向报文而不是流，send一次那就是send一次，不存在缓冲什么的。

这种含义的粘包问题要解决也十分简单，虽然不同消息在TCP层没有明确边界，但是可以在应用层对其进行分割。于是就有两种思路：
==1.在应用层手动添加一些如空白符等特殊字符，作为消息的边界。
2.在应用层固定消息的大小。==

第二种：
TCP一般默认开启nagle算法。这个算法在TCP包发出前进行检查，如果TCP包很小，那直接发出不如等后续几个小包都来了一起发出，从而减少网络中传输中的包的数量。可这导致有些包不能预期时间内到达接收端。所以有人称这个也是一个问题，叫做粘包问题。
这个问题其实也不是问题，据说在99%的情况下，nagle算法并不能导致有体感的延迟。要不然人家TCP实现也不能默认开启nagle。

==解决办法也很简单，将nagle算法关闭即可==。

## ⭐️TCP可靠性

常说TCP是可靠的传输协议，UDP则是不可靠的。那么TCP到底可靠在哪？可以从下面几个维度来解释

- 确认机制：每个报文段都需要得到确认
- 重传机制：当超过RTO时间或者满足某些条件触发快重传之类的情况，TCP会自动重传，保证数据完整
- 数据校验：TCP头中如上所述，带有校验部分，供接收方检查报文是否损坏
- 流量控制：从点对点控制的角度，防止丢包率过高
- 拥塞控制：从全链路控制的角度，防止丢包率过高
- 合理的分块：我们知道TCP面向流，但是实际传输中将数据分割成以MSS为单位的段进行传输。结合重传等机制，加入某一个段传丢了，问题也不大只需要将那个块重传即可获得完整信息。另一方面，若是UDP，一次传输就要传一整个报文，一旦传丢整个都丢，整个都要重新传（虽然UDP协议都不要求要重传）

# UDP基本

说到TCP就不得不说UDP。一句话解释UDP，就是这是一个提供无连接，尽最大努力的数据传输服务，不保证数据传输的可靠性。
这一章主要着眼于TCP和UDP的不同进行UDP性质的讲述。

## UDP的特点及其与TCP的区别

| UDP                                              | TCP                                         |
| ------------------------------------------------ | ------------------------------------------- |
| 无连接                                           | 面向连接，通信前必须先连接                  |
| 不可靠，尽最大努力                               | 可靠传输，可靠性见前述                      |
| 面向报文：应用层给多长的报文，加个头之后直接发送 | 面向流：应用层给的报文按MTU分割、封包，发送 |
| 支持一对多、多对多通信                           | 只支持一对一通信                            |
| 无拥塞控制，适合实时应用如zoom等                 | 有拥塞控制                                  |

## 常见的基于UDP和TCP应用层协议

- 基于UDP的应用层协议有

  ```
  DNS（指客户端向DNS发送DNS查询请求时用UDP）
  SNMP：简单网络管理协议
  TFTP：简单文件传输协议
  ```

  可以看到，很多都有简单作为定语。说明UDP不可靠，但是对可靠性要求不高时可以使用，因为实现方便，效率高。

- 基于TCP的应用层协议

  ```
  HTTP
  FTP
  Telnet
  SMTP
  POP3
  ```

# ⭐️IP基本

## IPv4 和 IPv6

v4就是现行常见的地址，通常用四个0-255数字表示。

v6地址长度是v4的4倍，即有128位（16字节，32个16进制数）表示地址。
通常表示方法是32个16进制数每4个一组分成8组表示，如：`ABCD:EF01:2345:6789:ABCD:EF01:2345:6789`。

## IP包头

IP的数据包有包头，其中有大量网络层控制信息。这个包头大概长这样：

![image-20210710113055091](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710113055091.png)

其中比较重要的有源IP，目标IP，协议号（比如1是ICMP，6是TCP等等）。TTL是一个计数器，包每经过一个路由器路由后都会减去1，直到归零时返回ICMP超时报文。这部分解释下面有。

## IP地址与其分类

众所周知，IPv4地址是一个32位二进制数。为了表示方便分成了四组0-255的数。理论上整个IPv4地址池可以支持2^32^约43亿个IP。

当然，整一个大网把这43亿IP都整合进去不现实，现实中需要的是更多个规模更小的网络。于是，IP地址被分为了网络号部分和主机号部分，两者各占32位中的一些。这么一来，网络的变种就很多很多了。早期科学家觉得IP资源还很丰富，为了方便管理，认为规定了以下标准来分类一些IP地址。

| 地址分类 | 描述                             | 范围                        | 网内最大主机数 |
| -------- | -------------------------------- | --------------------------- | -------------- |
| A类      | 分类号0，7位网络号，24位主机号   | 0.0.0.0 - 127.255.255.255   | 16777214       |
| B类      | 分类号10，14位网络号，16位主机号 | 128.0.0.0 - 191.255.255.255 | 65535          |
| C类      | 分类号110，21位网络号，8位主机号 | 192.0.0.0 - 223.255.255.255 | 256            |

整个地址域中还有部分未被分到这三类地址中的地址，是有他用或者目前未被启用的备用段。

后来人们发现，按照最初的标准进行IP地址分类并不是特别合理。尤其是因为网络/主机位数被定死了，导致网络的大小选择余地太小。所以就又找出了掩码这种机制，通过他来灵活地分配网络位和主机位。掩码也可以用`/xx`的形式表示，表示32位中前`xx`位是网络号，剩余是主机号。需要注意，使用掩码进行灵活网络划分只是对这43亿个地址进行的重新编排，使得每个地方都能尽量用上合适大小的网络，并不会增加地址的数量。

### 子网划分

笔试题中经常会碰到这类问题。子网划分，本质上，是对已有网络表示中，进一步从高位选择几个主机号作为子网号。而剩余的主机号仍作为主机号。显然，这个过程结束后，每个子网的掩码比原网络的掩码要更大一些。

以划分一个C类网络`192.168.1.0/24`为例。若我想将其划分成n个子网，我就必须要在现有的8个主机位中匀出`k`个作为子网号，并且满足`2^k >= n`。剩余的`8-k`个主机号，则构成每个子网最多的主机数是`2 ^ (8-k)`。
举个具体例子，比如我们想要分20个子网出来。显然，`k=5`，即我们需要额外的5个二进制位表示子网。于是此时子网掩码是`11111111.11111111.11111111.11111000`，即`255.255.255.248`。
而每个子网最大主机数是`2^3 = 8`。（严格来说，每个子网还应该去掉一个网络地址和一个广播地址，所以应该再减去2）

#### 子网与VLAN

> https://www.zhihu.com/question/51675361/answer/127319076

和子网相关的，经常被提起的一个概念称为VLAN。VLAN顾名思义，就是虚拟局域网。

我们知道，实际的局域网通常通过一台交换机联结彼此。在局域网内部，可以通过交换机进行二层的通信。
现在考虑这么一个场景：假设我有一台24口交换机，其中12口连接着`192.168.1.0/24`网段的机器，另外12口连接着`192.168.2.0/24`网段的机器。
当我从`192.168.1.1`出发试图访问同网段的某台机器时，就会拿着其地址做ARP广播。然而交换机作为二层设备，并不关心接入主机的IP地址，因此这个广播同样会被分发到`192.168.2.0/24`网段上。然而这个网段里不可能有目标主机，因此这个广播是不必要的，造成了资源浪费，更可能引起安全风险。

VLAN技术将一个物理交换机给分割成几个逻辑交换机，称为不同的几个VLAN。不同的VLAN树立起了广播域的边界，减少了不必要的广播扩大。上述例子如果构建起两个VLAN，就可以让两个VLAN内的ARP广播都只广播12个端口。

==从上述例子中不难看出，一个VLAN内有多个子网是不合理的，必然会引起广播浪费。因此可以将VLAN细分。==
==理想情况下，一个VLAN恰好对应一个子网，管理起来最为方便清晰。==
有时候可能会有一个子网内有多个VLAN，看似部分同网段主机间无法通过二层直接互相通信，但是可以借助外部VLAN桥接设备将两个VLAN间可以直接通信。

### 公/私有地址

为了进一步提升IP地址分配与网络构建的灵活性，在A/B/C三类地址中，还额外划分了一些私有地址，范围如下：

| 地址分类 | 私有地址范围                  |
| -------- | ----------------------------- |
| A类      | 10.0.0.0 - 10.255.255.255     |
| B类      | 172.16.0.0 - 172.31.255.255   |
| C类      | 192.168.0.0 - 192.168.255.255 |

私有地址是指，这个范围内的IP地址的分配和管理权在网络构建者手上。因此，不同人构建的不同网络中，这范围内的IP是有可能重复出现的。
相对的，不在这范围内的都叫做公有地址。公有地址在整个互联网唯一，由互联网地址分配机构统一管理。

### localhost/127.0.0.1/0.0.0.0

除了泛泛的公私有地址外，这里的三个地址也都是比较特殊的。

`0.0.0.0`不是一个真实存在的IP地址，而是泛指本机所有IPv4地址。监听`0.0.0.0`的端口，就是监听了所有本机IPv4地址的相应端口。
==运行`ping 0.0.0.0`的时候，通常会将地址自动替换成`127.0.0.1`处理，所以可以`ping`通，但是并不是通了`0.0.0.0`==

`127.0.0.1`其实是`127.0.0.1-127.255.255.254`的一个代表，这个范围内的IP地址全部都表示“本机环回地址”。发向这个地址的网络包，就是发给自身的，因此网络包在到达网络层后不会继续往下走，而是转了个弯返回给了上层。因此称为环回。

==`localhost`和`127.0.0.1`的关系就是域名与IP地址的关系==。当然，因为所有机器上的`localhost`都是对应`127.0.0.1`，所以这个解析关系通常被写在诸如`/etc/hosts`之类的配置中（换言之如果修改了这个文件中localhost的指向，那么访问localhost就会访问到其他IP去），所以DNS解析也是非常快的。
通常而言，访问`localhost`由于涉及到要去做一次DNS解析（尽管很快），比访问`127.0.0.1`多一个步骤。==但是大多数应用如MySQL中都对`localhost`做了特殊处理，若发现目的主机是`localhost`，就直接原地解析==，甚至不用装包发去网络层。从这个意义上说，localhost会更快一些。

## IP地址与路由

==IP地址中的网络号部分，主要的一个应用就是拿来进行路由==。

路由要用到路由器。路由器可以视作是拥有两块以上网卡的特殊主机。其两块网卡分别配置于不同的网络中。比如`192.168.1.0/24`和`192.168.2.0/24`间可能有一个路由器。其两块网卡的IP分别是`192.168.1.1/24`和`192.168.2.1/24`。这样他就作为一个桥梁，将两个网络粘合起来。

![image-20210710103720276](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710103720276.png)

所有主机和路由器在网络层都维护了一个路由表，路由表是`网络：下一跳`的对应。当一个IP包来到这里时，首先分析其目的IP地址的网络号部分。然后在路由表中寻找其下一跳。所谓下一跳，指当前机器所在的网络中的另一个主机地址，通常这也是一个路由器。

Linux系统中，可以通过`route -n`命令查看当前系统中维护的路由表。路由表的输出示例如下：![image-20210710114256310](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710114256310.png)
Destination和Genmask字段形成一个网络。对于一目标地址，我们逐条分析匹配，看目标地址是否是该行对应的网络，如果是，则将数据通过Iface字段指定的网卡，发送给Gateway指定的网关即路由器。
Gateway是`0.0.0.0`表示已经不需要网关，即目标主机与本机处于同一个局域网中，直接基于MAC地址发送即可。

最后一行网络是`0.0.0.0/0`，指代默认网关，即无法匹配路由表之前所有规则的包，将通过默认网关发出。后面的路由交给默认网关做。

## IP与MAC（ARP）

> 在说具体的事情之前，先来理清这么一个事：所谓的点对点通信，本质都是物理信号的广播。只不过信息中带有接收方的一个ID。所有主机都需要解析物理信号之后看这个ID是否与自己的相同，若相同则接收数据，从而实现点对点通信。
>
> 在计算机网络内部通信中，IP虽然也能扮演这个ID的角色，但是IP在网络层，每次主机解析都要从物理层跨过链路层到达网络层，开销很大。因此，计算机选择在链路层解决这个问题。链路层每个网卡都有mac地址，以这个mac地址作为ID。因为其最贴近物理层，解析很快，所以可以高效实现点对点通信。
>
> 用MAC来实现点对点通信的底层不仅仅因为其更靠近物理层，其包头结构也更简单，一个MAC的包头长这样：
>
> ![image-20210710115119441](https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710115119441.png)
>
> 协议类型基本也只有两种选择，IP协议或者ARP协议。设置为IP协议时表明这个MAC帧是一个普通的传输帧，设置为ARP协议时表示这个MAC帧是某主机发出的ARP请求/应答帧。

上述利用IP地址进行路由的过程，关键是在每一步都能找到目标主机所在的网络以及去往那个网络的下一跳。
可问题是，到达目标网络的入口的那个路由器后，数据该怎么进一步传输给目标主机呢？由于是最后一步的网络内点对点，所以可以利用MAC地址。

我们泛泛地知道，==ARP协议是将IP转换为MAC地址的协议==。更具体的，发送数据的主机会对当前网络内进行一个广播，称为==ARP请求==，要求查找目的IP地址的MAC地址是多少。此时匹配的那个主机会进行==ARP响应，将自己的MAC地址放进响应包返回==。
获得回应后的发送方，还会将IP-MAC对应关系缓存起来，下次直接用。在Linux中可以使用`arp -a`命令查看当前主机的所有ARP缓存。

基于ARP的传输是网络内的传输，本质上是广播寻址然后点对点传输。
实际上，在网际的路由器间传输时，两两路由器之间身处同一个网络，在这个网络内部，传输也还是基于ARP的。

#### RARP

顺便提一下RARP。第一个R是reverse的意思，顾名思义，这个协议和ARP相反，是拿着MAC找IP的协议。这个协议的应用场景大概是这样的：在一些物理地址固定的设备比如打印机等接入网络时，其可以向网路中已经存在的某RARP服务器发起RARP请求，其中带有该设备的物理MAC地址。
随后RARP服务器将会为其分配一个IP地址，并将MAC和IP的对应关系记录下来，并且返回告知该设备其被分配的IP是多少。

## IP与NAT

虽说IPv4有40多亿个地址，但是总归还是不够用的。于是就有了NAT技术。

一言以蔽之，NAT服务器可以将其公网IP借用给其管理的局域网中的主机，以访问外界网络。这么一来，局域网里的很多主机只需要一个IP就可以参与到互联网中了。

更具体的，借用IP这个行为并不仅仅是网络层，应该升华到传输层。（否则两个局域网内主机同时想访问外网怎么办）
换言之，==局域网内主机借用到的，其实是NAT服务器的一个TCP端口，以此为跳板和外界进行信息交互。==

和路由表、ARP中的IP-MAC对应表等缓存一样，NAT服务器会将`局域网内主机:端口`和`NAT端口`的对应关系缓存起来，以便下次进行NAT时可以迅速找到并建立NAT。

### NAT的作用

首要的作用当然是上面说的，将一个公网IP分享给一个子网中所有机器使用，从而节省公网IP。

另一方面，由于负责外网通信的全是那个转换后的IP，所以对子网内真实服务器也有一定保护作用。外界扫描端口时扫不到真实服务器的端口，只能扫到NAT服务器。

# ICMP协议

ICMP全称Internet Control Message Protocol，即互联网控制报文协议。

## IP与ICMP

在网络层基于IP协议进行数据传输的时候，会发生各种各样的故障比如数据包传丢了之类的。此时发出方自然希望能知道是因为什么原因引起了故障而无法将数据包传递到目的主机。有了ICMP之后，故障节点可以向发出方返回一个ICMP数据包，说明到底发生了什么事。
以上是ICMP的一个功能。知道了故障原因之后自然还希望能够调试排查，这也是ICMP可以做的。
总之，ICMP就像是IP协议的一个助手和工具包，可以用来诊断、排查IP传输问题。

ICMP的报文其实是和IP头一起组成一个IP包传输的。换言之，ICMP的报文代替了一个TCP段。ICMP报文中还带有ICMP头，其中包含了报文类型等信息。

## ICMP报文类型

上面说了，ICMP的两大功能是 1.向发送方报告传输故障  2.进行网络调试。这两个功能分别对应了两种ICMP报文类型，称为 “差错报文类型” 和 “查询报文类型”。

两大类型下又可以细分成各个具体的报文种类，每个种类都用一个数字来表示（这个数字被写在ICMP报文头中）。对应如下：

| 数字ID | 报文种类   | 报文类型     |
| ------ | ---------- | ------------ |
| 0      | 回送应答   | 查询报文类型 |
| 3      | 目标不可达 | 差错报文类型 |
| 4      | 原点抑制   | 差错报文类型 |
| 5      | 重定向     | 差错报文类型 |
| 8      | 回送请求   | 查询报文类型 |
| 11     | 超时       | 差错报文类型 |

### 查询报文类型

==查询报文也称回送消息，分为回送请求和回送应答两个过程。发送方A向接收方B发出`8.回送请求`，若B可达，则返回`0. 回送应答`。（ping原理）==这个过程结束后，认为从A可以达到B，说明两者间网络层面是互通的。注意，这里的A和B既可以是主机也可以是路由器。

### 差错报文类型

挑两个重要的说说

- 3.目标不可达

  目标不可达又细分为网络不可达、主机不可达、协议不可达、端口不可达、需分片但不能分片。
  目标地址的网络号本身就在路由中找不到，称网络不可达，错误代码为0
  网络可达但无法在目标网络中找到主机，称主机不可达，错误代码为1
  网络层的通信没问题了，但是目标主机的传输层禁止访问比如禁止了TCP协议而你发了TCP包过去，就是协议不可达，代码2
  传输层没有禁止，但是对方主机没有监听相关端口，端口不可达，代码3
  数据包到达路由器，要进入下一个网络时，由于网络的MTU可能不匹配， 导致包过大。通常路由器会在此时进行包分割，逐个传入下一网络，但若包头的“不可分片”位为True，则路由器直接将包丢弃并返回ICMP不可达差错报文，代码4

- 11.超时

  ==我们知道IP中有TTL字段，包每经过一个路由器，TTL就减1。当减到0时，这个包被原地丢弃，并且该节点向包的发出方发出一个ICMP超时差错报文。（traceroute原理）==

## ping命令执行

说到ICMP就不得不提到ping了。显然ping命令使用的是查询类型ICMP报文。下面假设从`192.168.1.1`发起命令ping`192.168.1.2`，来看看这整个过程。

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710111729576.png" alt="image-20210710111729576" style="zoom:50%;" />

首先，在192.168.1.1中

1. 进行ICMP报文组装。ICMP头部中，报文类型设置为8，并设置一个序号（设置序号主要是为了连续发多个ICMP包时可以进行区别），另外为了计算RTT报文头上还会加上发送时间字段。
2. ICMP报文组装完成后IP协议在这个报文外面加装IP头。IP头主要就是源地址、目标地址、以及协议类型（具体是1，表示ICMP协议）。
3. 接下来，数据被送到链路层，再套上MAC协议的头。这个头主要是源MAC，目标MAC。目标MAC率先尝试在本级缓存中找，找不到的话则通过ARP协议发起查询。

接着这个包就被发送出去，经过交换机进行局域网内广播。接下来，从192.168.1.2的视角，接收到了这个包。解析到网络层后，发现这是一个ICMP包，于是构建一个ICMP回送响应消息报文。类型为0，序号等于请求的序号。再一层层套回IP头，MAC头，然后发送。

响应包回到源主机后，源主机上显示ping的结果，通常包括了`icmp_seq`, `ttl`, `time`三个字段。
==其中`time`指的是RTT，即一个往返的总耗时。==`ttl`则是指客户端发包到达目标主机时经过了多少个跳。

以上是局域网内的ping的工作流程。如果涉及跨网段的ping，则还需要经过网际路由器进行路由转发。这部分操作就是之前IP与路由中提到过的通过多个路由器进行跳跃的转发过程，就不赘述了。

### 关闭ping

修改内核参数`net.ipv4.icmp_echo_ignore_all=1`可以永久关闭ping响应。
另外也可以通过在iptables设置相关的过滤项来禁止对ping做出应答。

## traceroute命令执行

traceroute命令是另一个利用了ICMP中差错类型报文的命令。其有多种用法

- 用法一：追踪到达某目标主机的沿途路由器

  其工作原理是这样的，开始时，将发出一个包裹了ICMP报文的IP数据包，并设置其TTL为1。我们知道IP包每经过一个路由器TTL会减1，而TTL归零时当前路由器会返回ICMP超时差错报文。所以，发送者只要解析这个超时报文的发起源，就能找到链路中的第一个路由器。

  同理，第二次，将TTL设置为2，就可以找到第二个路由器，以此类推直到到达目标主机。

  当然，有些公网的路由器被配置为对那些TTL归零的包不回应ICMP超时报文，那么我们也就无从知晓这些中间节点了。

- 用法二：确定MTU

  我们知道IP层一个数据包最大的size称为MTU，通常以太网中这个值是1500字节。但是路由途中，有些中途的网络其MTU可能不为1500。为了得知达到某个主机需要的合理的MTU是多少，可以采取如下策略：

  包一个大IP包并设置报头“不可分片”位为1，发送。如果图中某些路由器的网络，其MTU比较小，则会返回ICMP不可达差错报文，错误类型是需分片但未分片。这个响应中带有那个网络的MTU。因此下一次就包一个适应那个网络的MTU大小的值继续发包。以此类推直到目标主机，就知道了到达目标主机的MTU大小是多少了。

# ⭐️一次完整的HTTP请求

上面，从HTTP说到TCP，再说到IP，MAC，现在我们祭出常见面试题：“浏览器中打入URL到页面显示，发生了什么？”，顺着这几个协议一层层的思路，将这个过程细致说一遍。

## URL解析/HTTP报文组装

浏览器对URL首先要进行解析。注意这里的解析指单纯文本层面上的解析，而不是指域名解析。
URL解析主要关注这几个部分：协议、域名、文件路径、请求参数。
对URL解析完成后，将其中的信息组装成HTTP的报文头和消息体。因为输入URL的话必然是使用GET方法，所以这里消息体是空的，如果是其他比如POST方法，那么这个消息体中应该是需要上传的数据：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710143300410.png" alt="image-20210710143300410" style="zoom:50%;" />

## DNS解析

有了HTTP报文后还知道要往什么地方发送。此时就要进行DNS解析了。具体做法在DNS那一章说了，简单那来说就是能用缓存就用缓存，缓存里没有的去找DNS服务器。DNS服务器的请求方式还有迭代和递归两种，其中迭代比较常见。

将HTTP报文中的域名部分提取出来，拿去做DNS解析，得到一个目标IP地址。

## TCP包组装

至此，所有行为都还是应用层行为，CPU运行状态也都是用户态。接下来，因为HTTP一般基于TCP，所以要对HTTP报文进行TCP封装，工作也进入了传输层。
这个过程由用户态的程序调用`socket`库中相关函数开始。socket库中的函数一开始运行，就进入了系统态。即，传输层开始往下的工作都是在系统态中进行的。

TCP封装，是指给从上层传递来的HTTP报文加上一个TCP头。这个头的结构在TCP章里讲过了。
值得注意的是，如果HTTP报文过大，那么TCP在这里其实是会对报文做一个切割的。之前提到过，TCP段刨去头部，剩下的最大长度是MSS，就以这个作为标准切割：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710144104107.png" alt="image-20210710144104107" style="zoom:50%;" />

在加上TCP头部之后，TCP段的机构是这样的：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710144158008.png" alt="image-20210710144158008" style="zoom:50%;" />

## IP包组装、路由表

IP包组装就是给从传输层传来的TCP段再套上一层IP头部信息。IP头的结构也在IP那章讲过了。这里需要注意，IP头部中有一个协议字段，通过一个数字表示上面传输层用的是什么协议。由于现在传输层用的是TCP，所以当前加的IP头，协议字段也应该是06，代表TCP。

网络层负责将数据传输到非本地局域网其他网络。根据IP头中的目标IP地址，结合本地的路由表，可以得出下一跳需要发送的主机是什么。通常是局域网的网关，如果目标IP已经在本局域网内，则网关在路由表中显示0.0.0.0，此时说明可以直达目标主机了。
Linux的路由表可以通过`route -n`查看。

加上IP头后，数据变成了IP数据包，长这样：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710144612970.png" alt="image-20210710144612970" style="zoom:50%;" />

（下面HTTP报文部分因为太长，截图截不过来了）

##  MAC帧组装、ARP缓存

数据到链路层，给IP数据包再套一个MAC头。而且这个MAC头的信息非常简单直接，只有源MAC地址，目标MAC地址以及上层协议（这里因为是传输数据，所以是IP协议，ARP请求和回应的时候是ARP协议）。

源MAC地址写死在网卡里，很好获取。目标MAC地址是指上面网络层解析后得知的下一跳的MAC地址。因为下一跳肯定在局域网内，所以用ARP缓存查找其MAC地址。若缓存未命中则发出ARP请求广播，寻找MAC地址，更新缓存。Linux中的ARP缓存用`arp -a`查看。

组装上MAC头之后的帧长成这样：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710145022307.png" alt="image-20210710145022307" style="zoom:50%;" />

## 物理层网卡送出

最后，得到的帧仍然是数字型号，由网卡驱动程序将其转换为电信号并通过网卡发送出去。
在这里，网卡会最后为帧前面加上一个分界符，后面加上一个帧校验序列（FCS）检查传输过程中帧是否损坏。
经过网卡处理后，被转化为电信号发送前的数据长这样：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210710151058438.png" alt="image-20210710151058438" style="zoom:50%;" />

## 交换机转发、交换机缓存

现在局域网通常都使用交换机作为基于MAC点对点通信的实现设备。交换机有多个网线接口，局域网内所有机器都接入在交换机上。

上面说到，网卡将电信号发出。而发向的目的地第一站就是交换机。交换机接收到信号之后先将其解析为数字信号，简单的检验一下FCS看传输时是否有损坏。接着，交换机会检查这个帧的目标MAC地址对应哪个网线接口，并通过那个接口进行发送，实现点对点通信。
那么交换机是怎么知道MAC地址和接口的对应关系的呢？还是缓存。

交换机内部维护了一个各个接入交换机网卡MAC地址和物理接口的对应关系的表。对于拿着MAC地址找接口的活儿，缓存命中直接用缓存，缓存没有则对除了源接口的所有接口进行广播，让对应MAC地址现身。当然别忘了更新缓存。

注意到，交换机本身需要有像主机的网卡那样，将数字信号和电信号互相转换的设备。但是另一方面，交换机并不需要MAC地址，他只是做了数据的转发。当然其内部还需要一定缓冲区，用来保存缓存等信息。

## 路由器

说了一大通，别忘了我们现在是在做一个HTTP请求。而HTTP服务器通常是在外网而不是在局域网内。所以上一步交换机转发数据，通常是将数据转发到了当前局域网的网关处，即路由器。

路由器接收电信号后解析成数字型号，分析MAC头之后又发现是发给自己的，所以接收这个包进行进一步解析。
此时，解析IP头，路由器可以根据IP头中指定的目标IP，以及其自身的路由表，进行下一跳的选择。

通常下一跳是当前路由器所在局域网的另一个网关，若网关是0.0.0.0则表示目标IP直接可达。不管哪种情况，路由器都应该知道了下一跳的IP（另个网关或者目标IP）。有了IP，通过ARP就可以知道其MAC，也就为这个数据包再次套上一个新MAC头，发送出去了。

在一次HTTP请求中，上面的不断寻找下一跳，转发到下一个网关的过程周而复始要重复好多次。最终，最后一个路由器将数据包传送到了目标主机上。
==在整个传输过程中，IP头的信息其实一直没有变化，每个路由器会解析IP头，查看其目标IP地址等信息，但是并不会修改。
相对的，MAC头每经过一个局域网就会被更改一次。因为其负责的是局域网内点对点通信==。

### 路由器与交换机

路由器又被称为3层交换机，两者的功能十分相似。不同的是，交换机工作在第二层，其网络接口没有MAC地址，所做的工作是纯粹的转发。
路由器的每个接口，其实和主机的网卡一样，既有MAC地址也有IP地址。因为路由器进行的中介工作比交换机复杂得多，其路由表也有可能随时动态变化，所以纯粹的转发无法满足需求。代替的方案，则是将路由器也视作网络内的一个主机，用其来做数据的接收和转发。

## 服务端与客户端的互动

数据包经历了千辛万苦，终于到达了服务端主机。服务端主机进行层层拆包，最终拆到了HTTP报文。
根据HTTP请求报文的要求，服务端将返回内容也组装成一个HTTP响应报文，不出所料的，这个报文也通过服务端的层层加套，最终变成一个电流信号。

网卡将信号发出，返回给客户端。客户端收到后，再次层层拆包，解析出HTTP响应报文。

最后，客户端的浏览器将报文中的内容渲染到页面上，形成一个网页。

至此，一次完整的HTTP请求完成。

# 网络攻击

## DDos攻击

DDos攻击指攻击者控制大量机器向我服务器发起TCP请求，我服务器回应，进行第二次握手，但请求方不再给第三次回应确认信息，导致服务器花费大量资源维持这写连接一段时间。
其直接表现就是，大量的连接，服务端处于SYN_RECV状态，导致半连接队列很满。当半连接队列塞满，那么服务器会将新来的发起连接请求的包丢包，导致服务瘫痪。

### DDos流量识别

这目前还是一个业界的难题。

一个常见的办法，是基于连接请求的各属性（比如请求间隔，源IP等）进行统计，对异于一般情况的流量做出限制。但是在某些特定场景比如秒杀时，本来就是会有异常流量，因此不具有广泛适用性。
还有一种比较朴素的解决办法是读取包头的一些比较容易被忽视的字段如`User-Agent`并查看其值是否异常。因为一般而言，通过浏览器正常发起的请求这些值都是会有一些具体含义的正常值，而攻击者有时不会考虑这么周全。当然随着现在攻击手段越来越高明，这些字段值也都是可以模拟的。

更加fancy的方法则是基于机器学习或者深度学习模型，对异常流量进行检测。最常用的一个办法，首先是特征工程将流量的特征量提取出来，然后基于这些数据训练模型，接着做test来检测恶意流量。

## SQL注入攻击

指在HTTP请求中，部分字段故意写成一些恶意SQL代码。因为后台要将这些内容编写成SQL从而去更新数据库，会一并执行这些恶意代码从而造成损失。

防范方法：
Web端进行有效性检验，限制输入长度等
服务端不要使用SQL拼接，对SQL中的特殊字符进行过滤等

## XSS攻击

XSS全称跨站脚本攻击。现在大多数网站都支持和用户之间的互动，即用户可以发布一些自己的内容，其他用户则可以浏览其相关网页看到其发布的内容。
XSS攻击就是指将恶意代码植入到用户可编辑内容中发布，从而让别的用户在浏览时浏览器被迫执行这些代码。
举个例子，假如我发布一条微博，内容为`<script> alert('surprise')</script>`。如果后台校验不严格，逻辑是直接将输入内容放到一个`<div></div>`中，并发布了出去。此时别的用户浏览我这条微博时，他们的浏览器会将这段`<div><script>xx</script></div>`解释为javascript执行，于是就达到了我的攻击目的。

防范方法：

- 对输入长度做限制，校验输入内容中的<,>等字符，将其转义。
- 启用CSP机制（Content Security Policy）。其基本原理是设置一个白名单，里面添加上网页需要用到的一些静态JS脚本。在开启机制后，只有白名单中的脚本代码内容可以被执行。

## CSRF攻击

CSRF全称跨站点请求伪造。CSRF和Cookie相关，通常描述成攻击者盗用你的Cookie从而可以冒充你的身份做一些事。
而攻击者通常通过架设另一个危险站点，在危险站点中对被攻击网站发起访问，从而实现CSRF攻击。

举个例子，如果某银行网站转账方式以GET方法进行的，如GET`bank.com?toBankId=A&amount=1000`就是向A账号转账1000。
通常首次转账需要密码，而第二次以后为了方便，将密码以token的形式保存在Cookie中，这样就可以不输密码直接送token进行校验。
现在攻击者架设一个网站，其中有这样一段代码：`<img src="bank.com?toBankId=B&amount=1000" />`。
如果你在之前转账密码token没失效前打开了这个网站，浏览器自动执行去GET这个src，此时token有效所以校验通过，于是你就给攻击者的B账户转账了1000元。

防范方法包括了

- token机制

  在用户第一次看到页面的时候，给页面中埋藏一个隐藏token。要求用户提交数据时必须带上这个token才有效。因为CSRF攻击者可以跨站获取Cookie的使用权，但却无法跨站访问页面，因此无从知晓这个token
  验证码：通过为请求设置一些只有人才能计算的验证码，来过滤掉由机器发起的CSRF攻击

- referer识别

  识别请求的referer，拒绝以别的不明站点为referer的请求。

# Linux如何收发网络包

这章是稍微深挖一下Linux的网络通信的整个流程，从而复习上面所讲的各层协议以及一些细节。

## Linux网络协议栈

协议栈是指用于通信的一组协议。通常网络都是基于四层TCP/IP模型，一份应用数据从生成到发出要在各层套头，对应关系如图：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210715094806415.png" alt="image-20210715094806415" style="zoom:50%;" />

### 分片

为了通信的灵活性，通常不会吧一份大数据给整个发出。在网络层，根据网络传输的MTU（Maximum Transport Unit）对网络包进行分割。在常用的以太网中，这个MTU值是1500字节。这种操作也称为分片。
显然，每分一个片，其本身还要带上IP头和帧头帧尾，附加这些信息有时间、空间成本。所以整体来说，MTU越大分片次数越少，网络通信效率就相对高一点，否则反之。

## Linux接收网络包流程

我们知道网络或者说网卡也是一种IO设备，和磁盘类似，因为涉及到比较大的数据读写，采用DMA技术，网卡将网络包加载到内存的一个称为 环形缓冲区（Ring Buffer）的区域中。
为了通知CPU网络包到达，此时网卡应该发起一次中断请求。但是如果每个包到了都中断一次，会很影响CPU的工作效率。Linux2.6之后，引入了NAPI机制作为网络包接收的处理方式。

NAPI机制下，网络包到达后网卡发起中断。但是CPU的中断处理程序并不是真的去做拆包解析工作，而是发起一个称为“软中断”的线程。这个线程和其他线程类似，只不过其工作内容是轮询Ring Buffer，对当前网络包以及后续短时间内到达的网络包进行拆包解析工作。

正如操作系统篇中提到的，快速的硬中断+真正进行处理的软中断（轮询），这样结合的机制，可以提高接收网络包的效率的同时，不至于影响CPU干其他事情。

至于拆包解析，就是简单地从网络接口层一层层扒皮到应用层而已，就不多说了。

## 文件传输与零拷贝

### 关于DMA

DMA技术是指，当CPU试图和磁盘等IO设备发生交互的时，以读取文件为例，整个流程是CPU发起IO请求、磁盘控制器进行IO操作将数据充入控制器的缓冲区、操作完成后发送中断请求、CPU响应中断并将数据从磁盘控制器缓冲区拷贝到内存中（Page Cache）。

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210715134045686.png" alt="image-20210715134045686" style="zoom:50%;" />

在将数据拷贝进内存的过程中，CPU无法做其他事情，而拷贝这种事又那么简单，很浪费CPU的算力。
于是，在CPU和磁盘中间，插入一个中介的角色叫做DMA控制器。这个控制器带有自己的芯片，可以做一些简单的逻辑操作。他将接受来自CPU的指示，并实际和磁盘控制器通信，将磁盘控制器缓存中内容拷贝到内存中等。==注意：这里的内存，是系统态的内存，因为上述整个流程都是在系统态内运行的。==

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210715134227726.png" alt="image-20210715134227726" style="zoom:50%;" />

可以这么来理解DMA：==可以认为DMA控制器是CPU的一个承包商。本来拷贝数据这种脏活要CPU亲自下场干，有了DMA之后，CPU只要提出需求，我要拷贝什么数据到哪里，之后的事情全部交给DMA，CPU可以自己去干其他事情了。==

不仅仅是读写磁盘，像网络收发信息之类的IO情形，如之前所说也可以通过借助DMA技术来促进IO效率。

### 文件传输

我们这里说的文件传输，特指通过网络将一个主机中的某个文件传输到另一个主机中。对于发出方的主机来说，从IO的角度讲要做的页很简单，只需要读取文件，然后将文件内容通过网卡发出即可。上述过程抽象为：

```text
read(file, buffer, len);
write(socket, buffer, len);
```

但是真的那么简单吗？
实际上我们知道，用户态的进程无权直接操作读磁盘和用网卡发送数据这两件事。在进行读写前，用户态进程首先经过系统调用进入系统态。而在系统态，比如从磁盘中读到的数据，当然存在系统态的内存中，要在用户态的进程中使用这些数据，在系统态切回用户态时，CPU需要将这部分数据拷贝到用户态内存内。写的过程也与之类似。

最终，传统的文件传输可以描述为这样一幅图：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210715135218652.png" alt="image-20210715135218652" style="zoom:50%;" />

期间总共进行了4次用户态和系统态的切换，并且进行了4次拷贝。其中两次若有DMA优化，则是DMA进行的拷贝工作，另外两次则是CPU亲自进行的拷贝工作。进行用户态和系统态的切换时，涉及到栈内容等的上下文切换，要花时间；进行拷贝就更花时间了。
所以，要优化以上流程，思路是尽量减少用户/内核态的切换以及减少拷贝次数。

### 零拷贝技术

零拷贝旨在优化上述流程。其具体做法是，用`sendfile`函数配合`SG-DMA`控制器代替了原先的`read`和`write`函数。
这样之后，工作流程变成了，用户进程通过调用`sendfile`，完成第一步的DMA拷贝。接着`sendfile`会将此时处于内核缓存区中的数据的始址、长度等信息写入socket缓存区，而`SG-DMA`相比于普通DMA的高明之处在于，他不仅可以去socket缓存区中读数据，还能根据此部分信息直接去内核缓存区中读数据。

相当于在socket缓存区中，其得知的是一个地址，而拿着这个地址直接去内存缓存中拿实际的数据。这么一来，==整个流程就只有两个DMA拷贝，CPU全程没有参与。同时原先要进行`read, write`两次系统调用，现在只有一次`sendfile`的调用，上下文切换也只需要两次。因此可以大大加快读取数据并传输文件的速度==。因为无需要CPU参与的拷贝过程，因此称为零拷贝技术。

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210715142210304.png" alt="image-20210715142210304" style="zoom:50%;" />

许多有名的开源组件都采用了零拷贝技术。比如Kafka和Nginx。Nginx的Server配置中可以加上`sendfile on;`项以开启零拷贝（实际上内核版本2.1后的Nginx都默认开启了）。这样，作为静态文件服务器使用的Nginx可以以较快地速度项客户端提供文件。

零拷贝技术对小文件的传输有较大改善作用。但是对于大文件传输来说，零拷贝并不是很理想。通常大文件传输需要通过“异步IO + 直接IO”的办法来做。（TODO：详情见小林图解系统，不多写了）

## 网络IO模型

> 这部分内容与操作系统篇的IO部分互相补充

网络IO模型，是指两个主机通过网络进行通信时IO的处理方式。一般两个主机通信通常是一个客户端，一个服务端。我们重点关注服务端如何尽可能多地接收来自客户端的连接和请求，这也是设计一个合理的网络IO模型的必要性所在。

一般网络IO主要讨论传输层的一些东西。

### socket

socket是对网络的文件化抽象。两个主机要在传输层建立连接，就需要在各自主机内部维护一个socket文件。通过文件进行数据的收发。因为系统对文件的打开数量是有限制的，这也就意味着我们不可能在系统上创建无限多的socket（事实上，可打开文件数量默认值是1024，通过`ulimit`查看，比可用端口数量65535小多了）。

这也意味着当有大量用户请求时，必须想一些办法，即设计一个好的网络IO模型，来保证有有限的socket服务比那大得多了的请求数。
让一个服务端可以接入10000个客户端请求，这个叫做C10K问题。好的网络IO模型应该可以解决C10K问题。（当代的硬件强度已经可以轻松hold住C10K，所以主要就在于设计好的模型）

### 几种基本网络IO模型

- 多进程模型

  一种最基本的想法。首先创建一个根进程作为监听者。当有请求来时，父进程首先创建一个子进程，然后用子进程去服务请求。这相当于对于每个请求都单独分配一个子进程响应。

  想想就知道，这种方法效率很低，因为进程创建、销毁、切换上下文都要花很多时间空间。

- 多线程模型

  既然进程太重了，那么换成线程行不行。事实证明，虽然多进程比多线程好多了，但是仍然效率不高。因为线程虽然轻型，但是创建销毁等操作还是需要耗时的。对于高并发的访问场景，表现一般。

- 线程池模型

  在多线程的基础上再进一步。设立一个线程池，每个线程入池后等待调度。被调度了就拿去响应请求。
  对于线程池来说，线程的创建和销毁只需要进行一次，因此开销主要在线程的上下文切换上。
  但是治标不治本，如果同时有一万个请求过来，线程池还是得有一万个线程那么大，系统仍然不堪重负。

### 多路IO复用模型

上面的集中基本模型，有一个大前提，就是一个进/线程只能处理一个socket。而多路IO复用的意思，就是让一个进/线程可以维护多个socket。
并且虽然在同一时刻，进线程只能处理一个socket上的请求，但是通过告诉地不停轮转处理，可做到分时的虚拟化。就像在CPU上并发执行线程一样，虽然某一时刻只能执行一个线程，但是通过合理的时间片分割以及调度，可以做到分时复用CPU。
这种IO模式，就是多路IO复用模型。

提到多路复用系统，就不得不提三种具体的多路复用实现方案：`select / poll / epoll`。下面挨个来讲一讲。

#### select / poll

==select实现多路复用的方式是，先将所有socket挨个复制到内核内存，接着内核遍历检查每个socket是否有网络事件发生。对检测到事件的，内核给相关socket打上可读或者可写的标记。
接着再将所有socket复制回用户态内存，用户进程再遍历一遍所有socket，确定可读or可写的socket，接着开始进行相关读写工作==。

显然，select这种方式，整个操作过程包括了两次遍历和两次拷贝。
值得注意的是，select方式使用固定长度的BitsMap作为存放socket的容器，其容量有限。在Linux中，内核参数`FD_SETSIZE`是限制，默认值是1024。

==poll方式与select方式唯一不同的一点在于其不是用BitsMap而是使用链表保存各个socket==。因此没有了BitsMap的大小限制。但是仍然受到系统最大文件句柄数的限制。
另一方面，poll只是改变了存储容器，算法没有改变，所以仍然需要两次遍历和两次复制。

select和poll两种方式，都需要遍历整个线性结构来寻找有动态的socket进行处理，整体算法在`O(n)`，还需要两次复制。
整体来说效率比较差。

#### epoll

select/poll其实都没有解决C10K问题，而epoll可以。
首先，epoll方式下不再使用一个简单的线性结构维护所有socket。这里，采用了一个红黑树。并且这个红黑树最开始就通过`epoll_create`函数在内核内存中创建。接着，每新有一个待检测的socket时，进程将这个socket通过`epoll_ctl`加入到红黑树中。
我们知道，红黑树的增删查操作都是`O(logn)`的。

除了红黑树外，epoll方式还在红黑树边上维护一个链表，红黑树中这些socket触发的读写事件。即当某个socket变成可读或可写，需要进程做相关操作时，一个回调函数会将这个socket状态发生改变这件事加入到链表中。称之为就绪链表。
顺便一提，这个回调函数是运行`epoll_ctl`时注册到内存中的。

最终，在任意时刻，进程可以通过系统调用`epoll_wait`，将就绪链表中的事件从内核内存复制回用户内存，进行相关处理即可。

上述三个接口图示如下：

<img src="https://localblog-1258020778.cos.ap-shanghai.myqcloud.com/uPic/2022/03/18/image-20210715203937894.png" alt="image-20210715203937894" style="zoom:50%;" />

调用`epoll_wait`，顾名思义，就是会让进程进入阻塞态等待socket事件。而进入阻塞态之后，socket发生IO事件，要求进程来处理时，有两种触发进程处理的模式。术语分别称为水平触发（Level Trigger, LT）和边缘触发（Edge Trigger, ET）。以读数据为例说明：

- 水平触发（LT）

  ```
  当socket发生可读事件，进程会来读取、并且不断地读取缓冲区中的内容，直至读完。
  ```

- 边缘触发（ET）

  ```
  当socket发生可读事件，进程只会来读取一次。如果一次没读完（比如缓冲区太小或者其他原因），那么剩余没读到的部分就相当于被抛弃了。
  ```

select/poll只支持LT模式，而epoll默认情况下是LT，也可以改成ET。

==最后指出，以上使用了网络IO多路复用的情景来解释了select/poll/epoll。但是实际上，这三种IO多路复用模式不仅仅适用网络，更适用于广泛、泛泛的IO。当IO对象是文件、管道等等情况时，依然可以套用这三种模式，使得IO操作多路复用，节省系统的开销==。

