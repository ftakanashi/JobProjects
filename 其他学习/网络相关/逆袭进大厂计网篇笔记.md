> 这是读《逆袭进大厂》（InterviewGuide）的笔记。计网篇。

# OSI的七/四层模型

现代网络通信通常将网络以分层模型建模。分层的好处是层之间隔离性、灵活性、易于维护、促进标准化等。

七层模型从上到下以及各个层级下的代表性协议分别是：

```
应用层     HTTP, FTP, DNS, TELNET, DHCP, POP3...
表示层     JPEG, ASCII...
会话层
传输层     TCP, UDP
网络层     IP, ICMP...
数据链路层   MAC, ARP, RARP...
物理层
```

将上三层合并可以成为新的“应用层”，将下两层合并可以成为“网络接口层”，每一层数据单位的名字是:

```
应用层
传输层				段（segment）
网络层				包（package）
网络接口层		 帧（frame）、比特流
```

两者的关系：四层是七层的一种简化，也是实际使用如TCP/IP协议族下的模型。七层模型是理想化理论模型。

## 每层作用和设备

 ![image-20210706105927695](/Users/wyzypa/Pictures/TyporaImages/逆袭进大厂 计算机网络.asset/image-20210706105927695.png)

# DNS

**DNS是应用层协议，基于UDP进行传输。**DNS就是做域名解析的协议。

## DNS多级缓存与查询过程

解析过程中会涉及很多缓存内容，若缓存有命中，则可以不去DNS服务器请求解析，加快解析速度。缓存包括了：

```
浏览器缓存
系统缓存（如/etc/hosts等）
路由器缓存
ISP服务器缓存
根域名服务器缓存
顶级域名服务器缓存
主域名服务器缓存
```

当试图解析一个域名时，系统从上至下依次去访问这些缓存。前两个很好理解，就是计算机本地带有的一些缓存信息。

第三个路由器缓存，是指路由器本身通常会带有一些域名解析记录，从而路由器本身可以作为局域网内的一个DNS服务器。对局域网内的DNS服务器发起解析请求，只需要ARP解析其IP成物理地址，然后再局域网内发起访问即可。

若局域网内DNS没有找到解析记录，则转到ISP服务器，这是指网络接入商提供的一个DNS解析服务器。通常一般的DNS解析到这里大概率能找到答案。若还是没解决，则ISP服务器将会和国际上通用的DNS服务器进行联系。现在假设访问的地址是`mail.cctv.com`。这个地址可以分成三个层次：`mail.cctv.com`是三级域名、`cctv.com`是二级域名、`.com`是顶级域名。

第一步，ISP服务器先行联系根域名服务器。根域名服务器不直接返回解析结果（这和解析模式是迭代还是递归有关，这里以迭代为例说明），而是返回一个顶级域名服务器地址，比如这例中的负责`.com`系列顶级域名的服务器。
第二步，ISP服务器再请求顶级域名服务器，顶级域名服务器也不直接返回解析结果，而是返回一个负责了`mail.cctv.com`的主域名服务器地址。
第三步，请求主域名服务器，这次主域名服务器中有相关解析记录，返回给ISP服务器。ISP服务器将IP记录到本地缓存中，并且返回给用户。

## 递归解析与迭代解析

上述ISP服务器解析地址的过程中，其实存在两种方式。递归和迭代。

递归方式解析，指ISP服务器接到请求后，去请求更高层级的服务器A。而服务器A接到请求后若无法自己解析，再去递归地请求更更高层级的服务器B。如此一层层递归下去，直到找到后再一层层返回到ISP服务器。

迭代方式解析，指ISP服务器接到请求后，去请求更高层级的服务器A。A接到请求后知道接下来要去请求B，但是它不自己做而是将B告诉ISP服务器，意思是“你自己去找他”。如此，是ISP服务器跑好几个办事窗口最终找到记录，称为迭代方式。

## 基于DNS的负载均衡

一般负载均衡，在DNS层面是无法感知的，通常DNS都将域名解析到负载均衡器上。

而基于DNS的负载均衡是指，在DNS服务器上设置同一个域名解析到多个不同的IP地址，这些IP地址形成一个后端集群。当有大量访问来袭时，按访问顺序轮转返回解析结果，从而尽可能把多个请求平均分配到后端各个IP上。

这也就是基于DNS的负载均衡策略。

## DNS中的UDP和TCP

不同层级的DNS服务器之间，进行数据的交流和同步，基于TCP。因为TCP可靠且一次性可以传输的数据量大。

客户端向DNS服务器发起DNS解析请求时，因为通常只要一次性通信并且数据量不大，所以使用更快的UDP。



# HTTP基本

## HTTP的各类方法

前三种方法由HTTP/1.0定义，后来HTTP/1.1又追加定义了六种方法

| 方法    | 描述                                                         |
| ------- | ------------------------------------------------------------ |
| GET     | 请求指定信息的页面                                           |
| HEAD    | 类似GET，只是返回响应无响应体，只获取报头                    |
| POST    | 提交数据并请求服务端进行处理。POST会发两个包，一个包含头信息，一个包含数据信息 |
| PUT     | 提交数据（完整）覆盖原数据。                                 |
| PATCH   | 提交数据（部分字段）覆盖原数据。                             |
| DELETE  | 请求从服务器删除指定页面。                                   |
| OPTIONS | 允许客户端查看服务器当前性能。                               |
| TRACE   | 回显服务器收到的请求，主要用于测试和诊断                     |
| CONNECT | HTTP/1.1中预留给能将连接方式改为管道方式的代理服务器。       |

### GET和POST有什么区别

- 规范上来说，GET用来请求数据，POST用来修改数据
  - GET纯粹是读取数据，因此理论上是幂等的。基于此，==浏览器一般对失败的GET会自动重发==。如果你的逻辑用GET进行了数据增删改操作，可能就会引起重复操作的风险。因此还是要遵照规范进行操作。
- GET将请求参数直接合并在URL中，通常浏览器会对URL长度做限制（如2K，注意这是浏览器的限制而非HTTP本身限制，原因是处理长URL开销大且容易引入安全风险）因此GET能够提交的参数也受到限制；POST将请求放在HTTP的请求体中，理论上参数不受限制。
- GET产生一个数据包，将header和body一起发送。若服务端处理成功，则响应200；==POST产生两个数据包，先发送header，服务器响应100 continue，再发送body，服务器响应200==（注：这种行为不是HTTP协议规定，只是大多数实现是这样）。
- GET请求会被浏览器自动缓存，而POST默认情况下不自动缓存。
- POST方法和GET方法在安全性上并没有区别。虽然POST的数据没有写在明面URL上，但是其数据包并没有加密，只要截取，就能看到数据。要安全，只能用HTTPS

## HTTP中的缓存控制

为了加速响应，减少重复计算，HTTP通信中存在多种缓存机制。
离用户最近的，自然是浏览器的缓存。再远一点，代理服务器也可以有缓存。更远的，根据后台的架构，源服务器可能也会带有缓存，甚至后台就有专门进行缓存响应的缓存服务器。

在HTTP中使用/控制缓存主要通过HTTP报文中的`Cache-Control`字段。
在HTTP请求的报文头中，`Cache-Control`可以设置为`no-cache`，`no-store`等值（其他的不写了）。`no-cache`表示客户端要求服务端不直接使用缓存，而是请求源服务器获取最新数据。`no-store`表示客户端要求本次请求服务端不要保存任何数据进缓存。
在HTTP响应的报文头中，也有`Cache-Control`字段，这次比较值得注意的是其值可能是`public`和`private`。分别用来指示本次返回的缓存内容是多用户可见的，还是就当前用户可见。

> 更多HTTP缓存相关内容，可参考：https://blog.csdn.net/u012375924/article/details/82806617

## 常见HTTP状态码

| 状态码 | 类别             | 类含义                             |
| ------ | ---------------- | ---------------------------------- |
| 1XX    | 信息性状态码     | 告知客户端接收了请求正在处理       |
| 2XX    | 成功状态码       | 告知客户端请求正常处理完成         |
| 3XX    | 重定向状态码     | 需要对客户端请求进行重定向再做处理 |
| 4XX    | 客户端错误状态码 | 因客户端请求的问题，无法处理请求   |
| 5XX    | 服务端错误状态码 | 因服务端内部的问题，无法处理请求   |

更具体的说说各个类别的代表性的码。

- 【200 Success】成功，返回了数据
- 【204 No Content】成功，不返回任何数据
- 【301 Moved Permanently】资源被永久重定向到新路径，以后应该从新路径访问
- 【302 Found】资源正临时性被重定向到新路径
- 【400 Bad Request】客户端请求报文中有语法错误
- 【401 Unauthorized】客户端未提供HTTP认证信息。浏览器碰到401后通常会弹出用户名密码输入框
- 【403 Forbidden】该客户端对该资源的请求被禁止了。通常返回信息中会有更具体的禁止原因
- 【404 Not Found】请求的资源不存在
- 【405 Method Not Allowed】请求的资源不允许客户端请求的方法访问。
- 【500 Internal Server Error】服务器内部错误，通常是web程序bug了
- 【502 Bad Gateway】通常在有代理、网关服务器等情况下给出。表示其无法从上游的应用服务器获取到资源
- 【503 Service Unavailable】服务器停机维护中，无法提供服务

# HTTPS

HTTPS就是HTTP + SSL/TLS。
简单说说两者的区别：HTTPS在HTTP外面套上一层安全壳，互相之间的传递的信息报文被加密从而不易被第三方读取。HTTPS需要额外的SSL证书和CA证书、端口通常是443。

## 什么是SSL/TLS

SSL是安全套接字层。他是用于加密和验证客户端-服务端通信数据的协议。其加密机制综合并用了不对称、对称加密两种方式。

### SSL的流程

1. 客户端发起SSL连接请求
2. 服务端发送公钥（S~pub~）给客户端
3. 客户端用S~pub~加密送通信的对称密钥C，并发送给服务端。这个密钥每个会话生成一次，也称会话密钥。
4. 服务端用私钥S~pri~对C进行解密，得到通信用对称密钥。
5. 之后，服务端和客户端对任何通信数据，都使用共同知晓的对称密钥C进行加密解密。

上面这个流程，并非绝对安全。比如有一个黑客劫持了2中的S~pub~然后将自己的公钥H~pub~发送给客户端。此时客户端并不知情， 就会将C用H~pub~加密发送给黑客，黑客经过解密，可以知道C的内容。然后再将其用S~pub~加密发送给真的服务端，黑客隐身。这么一来，黑客就能偷窥到之后服务端和客户端之间的通信了。

换言之，==若SSL中服务端的公钥被篡改，则还是会发生安全风险==。这个问题的解决办法是将公钥放进一个由第三方认证过的证书。可以这么理解：第三方是可信任的，而他会把上述可能被篡改的公钥本身 用第三方自己的私钥加密。作为用户，我们可以获取到第三方的公钥，只要这个公钥可以解密这段内容，那么这段内容一定可信，因此就一定是可信的，没有被篡改的。

## HTTPS的好处

- 加密（防窃听）
- 认证（防伪装）
- 完整性保护（防篡改）

# Session和Cookie

HTTP协议是==无状态的==，这主要是为了让HTTP数据处理方便一些。HTTP/1.1引入了Cookie来辅助性地保存状态。
无状态，是指服务端和客户端之间无法识别对方。比如服务端接收到第一个请求并处理，若客户端发送第二个请求，服务端无法得知这个请求与上一个是同一个客户端发出的。

- Cookie

  Cookie本质是==服务器发送到用户浏览器并保存在本地的一小块数据==。之后，每次访问同一服务器时，浏览器会将这块数据一并带上。如此，服务器就可以通过Cookie中的信息识别客户端的身份，从而解决了无状态的问题。

  经常使用Cookie的场景有==会话状态管理（如登录状态等），个性化设置（个性化的主题界面等），浏览器行为跟踪==。值得注意的是，曾经Cookie常用于存储大量的客户端数据，后来随着发展，很多浏览器都单独推出了客户端数据存储功能，于是就不用Cookie来存储这么重量的信息了。

  Cookie根据有效期，可以分为会话Cookie（在关闭浏览器后失效并被删除）和持久Cookie（保存在磁盘中，在指定失效期前持久有效）。

- Session

  Session也是用于解决HTTP无状态这个缺点的。不同的是，==Session将要保存的信息以键值对的形式存放在服务端==。至于具体在哪里由架构者自己选择，通常可以存放在文件、内存，也可以存放在诸如Redis之类的软件中。

  以登录状态为例，用户发送登录请求后服务端进行校验，通过后将用户信息保存在Session中，并且生成一个Session ID，将其通过响应报文中的`Set-Cookie`头字段返回给客户端，并让客户端将这个ID保存在Cookie中。之后客户端再请求时，只要带上SessionID，服务端就可以识别客户端了。

  乍一看，Session本质上还是得要依赖于Cookie，感觉很鸡肋。实际上，Session机制下服务端和客户端之间交流的额外数据只有Session ID而没有实际的数据内容（which单纯Cookie机制中可能要传输），因此更加安全。当然，SessionID有可能会被盗用，应对这方面安全问题，通常服务端会比较频繁地更新session ID并且加二次验证之类的办法。

- 两者区别

  ```
  1. 本质上，保存位置不同，Cookie在客户端，Session在服务端
  2. 因为Session信息在服务端，更安全
  3. 因为Session信息在服务端，过多session影响服务器性能
  4. 因为Session信息在服务端，可以存储更加复杂的数据object，Cookie一般只存储ASCII码
  5. 因为Session信息再服务端，通常存储容量更大。Cookie大小、个数则受到浏览器限制
  ```

# TCP基本

TCP是最常用的传输层协议之一，与网络层的IP协议形成了实际上现实中互联网的基石TCP/IP协议组。

## TCP报文段内容

TCP段分为头部和数据部分。数据部分是指从上面应用层封装好传递下来的数据，而头部则是本层传输层额外包裹的一些信息。分析TCP协议的各种东西时，主要关注头部中的信息及其变化。头部数据大概长这样：

![](https://img-blog.csdn.net/20180717201939345?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTUwMzE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

- 源端口、目的端口：顾名思义

- 序号(**seq**, 32bit)：主要标识本数据段在整个TCP数据流中的位置。通信建立时，seq初始化成一个随机数（Initial Sequence Number, ISN）。之后每个段的seq都是`初始值 + 已经发送的字节数`。这样就保证了段之间互相有序。

- 确认号(**ack**, 32bit)：接收方对发送方的TCP响应，为收到的段的序号+1

- 标志位(6bit)：这是六个1bit的开关位，如下：

  ```
  URG: 表示紧急指针是否生效
  ACK：表示确认号是否有效，即表示段是否是一个回应确认的数据段。事实上除了建立连接和断开时部分数据段，所有数据段这个位置都是1
  PSH：完整写法是PUSH，提示接收端立即从缓存中读取数据
  RST：要求对方重新连接（复位报文段）
  SYN：表示请求建立一个连接（连接报文段）
  FIN：表示关闭连接（断开报文段）
  ```

- 窗口 (16bit)：告知对方本机的缓冲区还有多少剩余。解决流量控制问题。
- 校验和(16bit)：用于检验报文段有无数据损坏。
- 紧急指针(urgent pointer)：指一个偏移量。序号+这个偏移量，是紧急数据的开始。紧急数据，指正常通信过程中，由于突发情况而想要高优先级传输给对方的信息。比如想要提前中断传输。

### 大小限制

TCP/IP协议族下的一个传输单元（IP数据包）最大大小称为**MTU (maximum transmission unit)**，通常由硬件决定，大概在比如1500字节。
除此之外还有一个最大分节大小 **MSS (maximum segment size)**，这个值是指一个IP数据包中数据部分最大的值。通常等于MTU减去TCP头部（20字节）和IP头部（20字节）两部分信息。

## TCP连接

### 三次握手

![](/Users/wyzypa/Pictures/TyporaImages/逆袭进大厂计网篇笔记.asset/70.png)

- 第一次握手

  ```
  客户端发出TCP段，SYN=1，seq=初始化随机值x
  客户端状态：CLOSED 变为 SYN_SENT
  ```

- 第二次握手

  ```
  服务端发出TCP段，SYN=1，seq=另一个初始化随机值y，ACK=1，ack=x+1
  服务端状态：LISTEN 变为 SYN_RECV
  ```

- 第三次握手

  ```
  客户端发出TCP段，seq=x+1，ACK=1，ack=y+1
  客户端：SYN_SENT 变为 ESTABLISHED
  (收到后)服务端：SYN_RECV 变为 ESTABLISHED
  ```

#### 三次握手的意义

通俗的说，握手的意义在于 **双方都可以确认自己&对方的发送/接收功能正常**。

第一次握手成功，S可以确认：C发送功能正常、S接收功能正常。
第二次握手成功，C可以确认：S发送/接收功能正常，C发送/接收功能正常（因为第一次发送的包确实被S收到了，所以C发送正常）

此时C已经完全确认，可S还无法确认C的接收、S的发送功能是否正常。因此需要第三次握手。
第三次握手成功，S确认了C接收功能，S发送功能正常。

若不进行第三次握手，可能会出现以下情况：

```
C发送了第一个请求连接包a一段时间后无响应，于是发送第二个包b重连。b到达了S，于是CS间连接，并且正常通信完成。
结束通信后，a包终于到达了S，S进行回应。若只有两次握手，那么这个连接就建立了，而显然，C不会向S传送数据。
这么一来，S上就多了一个永远不会有数据，但是却一直开着的连接。
```

#### 三次握手其他

- 半/全连接队列：S端处于SYN_RECV的状态时，相关连接信息被放入一个称为“半连接队列”的队列中。而那些已经完成三次握手的连接放在“全连接队列”中。全连接队列满时，若C发起新的连接请求可能导致丢包。
- SYN-ACK包重传问题：第二次握手时，S发给C的包称为SYN-ACK包。这个包发出后若一定时间内没收到C的确认包，服务器会进行重传。重传次数超过系统设置上限时，将停止继续尝试并且放弃这个连接。
- 携带数据问题：三次握手中，第三次握手可以携带数据，因为C接收到第二次握手的包时就意味着连接已经建立。前两次握手则不允许携带数据，因为如果允许，那么就意味着接收方必然需要处理这些数据（至少得安排内存来保存），若我是攻击者，就可以发送大量握手包，来攻击对方的内存。

### 四次挥手

![](/Users/wyzypa/Pictures/TyporaImages/逆袭进大厂计网篇笔记.asset/70-20210708093118050.png)

C或S端都可以主动发起关闭连接，从而进入四次挥手流程。以C主动结束连接为例：

- 第一次挥手

  ```
  客户端发出TCP段，FIN=1，seq=u
  客户端：ESTABLISHED 变为 FIN_WAIT_1
  ```

  服务端收到第一次挥手包后，通知应用程序进行连接关闭操作。异步地，发送第二次挥手的包。

- 第二次挥手

  ```
  服务端发出TCP段，seq=v，ACK=1，ack=u+1
  服务端：ESTABLISHED 变为 CLOSE_WAIT
  （收到后）客户端：FIN_WAIT_1 变为 FIN_WAIT_2
  ```

  进入FIN_WAIT_2状态后，C就没有了数据发送能力，但仍然保持数据接收能力，可以接收来自S最后发送的一些数据。

- 第三次挥手

  应用程序将连接关闭后，发生第三次挥手。

  ```
  服务端发出TCP段，FIN=1，seq=w，ACK=1，ack=u+1
  服务端：CLOSE_WAIT 变为 LAST_ACK
  ```

- 第四次挥手

  ```
  客户端发出TCP段，seq=u+1，ACK=1，ack=w+1
  客户端：FIN_WAIT_2 变为 TIME_WAIT，持续2MSL，TIME_WAIT 变为 CLOSED
  （收到后）服务端：LAST_ACK 变为 CLOSED
  ```

#### 四次挥手的意义

- 为什么不是三次是四次？

  四次挥手的包分别是FIN, ACK, FIN-ACK, ACK。和握手比较后发现多了第二个ACK包。
  这个现象的根本原因是，关闭连接需要进行进程处理一些后续工作，比如将缓冲区中剩余未发出的报文发完。
  因为这些工作需要一些时间，所以==暂且先给出一个ACK包回应，旨在说明“你的FIN包我收到了，现在正在尝试关闭连接”==。而真的关闭连接后，才能发送FIN-ACK，说“你的FIN包我收到了，我也可以关闭连接”。

  相对的，握手的时候服务端没有什么额外工作要做，所以在收到客户端的SYN包后直接可以回复SYN-ACK说明“你的SYN包我收到了，我也同意建立连接”。

- 2MSL是什么，有什么意义？

  > MSL全称Maximum Segment Lifetime，即报文最大生存时间
  >
  > 默认C和S间传递一个报文最久只能是这个时间上限。超过这个上限则认为丢包。

  设置2MSL等待时间的原因是防止下面这样的情况出现：当C发出第四次挥手包时，S处于LAST_ACK状态。若此包中途丢失了，作为S来说，因为没收到最后一个ACK包，所以需要尝试重发第三个挥手包。若没有2MSL等待机制，C此时早已CLOSED，所以不能回应。因此S将永远无法从LAST_ACK变为CLOSED。

  相反，有了2MSL之后，在C发出第四次挥手包后，如果真的丢包了，S会在1MSL后察觉并重发第三次挥手包。此包又会最长花1MSL时间到达C。即，若真的丢包了，只要给C端2MSL的额外时间，C就能知道丢包事实，并且重发第四次挥手包。当然，若重发了，则需要重置2MSL计时器。

  总体而言，2MSL机制是为了给C一段额外的时间，给予其重发第四次挥手包的机会，防止因为丢包导致S端无法CLOSED。

### TCP连接中HTTP的限制

- 一个TCP连接可以对应多个HTTP请求（只要HTTP开了keep-alive，那么TCP连接就不会立刻中断，因此可以收发多个HTTP请求）
- 对同一个Host，客户端理论上可以建立非常多的连接。但是考虑到实际的开销问题，实际实现中通常还是有限制的。比如在Chrome的实现中，规定了对一个Host最多只能建立6个TCP连接。
- 到HTTP/1.1为止，多个HTTP请求在一个TCP连接中只能按顺序逐个发送处理，不能混着发。

## TCP拥塞控制四大算法

> 资料：https://www.bilibili.com/video/BV1c4411d7jb?p=61

==需要指出的是，这节提到的拥塞控制四大算法并不是四个独立可以做到拥塞控制的算法，而是相辅相成，共同组成了TCP拥塞控制体系的四个算法。==

### 什么是拥塞

拥塞，就是指网络过于拥挤导致堵塞。一条网络链路中的资源，包括带宽，交换机等是有限的，但可以请求使用这些资源的传输数据是无限的，于是过多的传输数据和过少的资源可能会引起网络响应时间过长。响应过长又可能进一步引起重传等操作，导致网络更加拥挤，形成恶性循环。更有甚者，还可能引起“竞争消耗性资源的死锁”。

简单来说，就把网络链路想象成普通道路，传输数据就是一辆辆车。如果车过多就会堵车，而一堵车就会有车加塞干嘛的，导致路况进一步混乱，最终导致谁也无法通行。

### 一些基本概念

假定有C和S，C向S发送TCP段数据。具体的发送方式是==“逐轮发送”==。可以简单这样理解：C发送数据时，一轮发送若干个段，并期待收到S的对于这若干个段的若干个确认报文。这个一来一回的时间又被称为RTT (Round-Trip Time)。

于是问题来了，若干个到底是几个？这其实是由C端的一个变量==“拥塞窗口”（cogestion window，简称cwnd）==控制的。顾名思义，C端可以根据当前网络的拥塞情况来动态调整这个窗口，这也是TCP进行拥塞控制的核心所在。
显然，cwnd越大，一个RTT内能传的数据越多，传输效率越高。但是如果网络很拥挤而窗口又过大的话，那么可能会引起拥塞问题。

此外，TCP数据传输中通常有重传机制。即C发送一个段给S后，在重传超时时间后（RTO，Re-Transmission Timeout）仍未收到确认，则自动重传该数据段。称为==“自动重传机制”==。

### 慢开始 与 拥塞避免算法

下面正式开始讲拥塞控制算法。先讲前两个。

慢开始算法指是，最开始时不能对网络情况估计过于乐观，因此将cwnd初始化为1。同时我们还需要设置一个==慢开始阈值（slow start threshold, ssthresh）==比如16。随后开始传输。
我们将一个RTT内传输了`cwnd`个数据段，并且全部收到了正确的确认报文的情况，称为一个正常的传输轮次。
在慢开始算法阶段，每完成一个正常的传输轮次，`cwnd *= 2`，呈指数速度增大。

当`cwnd >= ssthresh`时，停止执行慢开始算法，转而执行拥塞避免算法。
拥塞避免算法阶段，每完成一个正常的传输轮次，`cwnd += 1`，呈线性速度增大。

上述两个阶段，cwnd都在不断增大。但显然，其不能无限增长下去，到一个比较大的值比如24的时候，C可能会发现轮次不正常，即丢包发生，无法收到完整的确认信息了。
此时，两个算法的策略是：<font color="red">将cwnd重置为1，并将当前cwnd值的一半设置为ssthresh。随后重新开始执行慢开始</font>。

慢开始，强调从1开始指数增加负荷，快速逼近网络的承载极限。拥塞避免强调线性增加负荷，谨慎逼近网络的承载极限。

慢开始&拥塞避免两个算法结合，形成了一个简单的拥塞控制体系。这也确实是TCP早期的（1988年左右）实现方案，称为TCP Tahoe。

### 快重传 与 快恢复

在更新的TCP实现中，在上面两种算法的基础上还引入了快重传和快恢复两种机制。

上面提到，当丢包发生，我们就认为轮次不正常，从而进行拥塞控制。但是在实际网络中，很多时候因为网络抖动会突发丢包现象。这种丢包是偶然的，并不意味网络拥挤。这么一来，直接将ssthresh腰斩，还将cwnd变成1重新开始“慢开始”，会损失很大一部分通信效率。

作为解决办法，在较为新的TCP实现中，引入了快重传机制。新的实现称为TCP Reno。

#### 快重传

上面的描述中，我们认为当C很久得不到发出报文的确认，就默认进行超时重传。而所谓的快重传是指不等超时，而是结合TCP的序列号进行尽快的重传。

假设C向S发送包，0，1，2号发送正常，都收到了S的确认。3号丢包，暂时无S确认。随后发送4号包成功。==按原有套路，S应该给出4号的确认信息。但是按照序号序列来说，S认为你应该给我3号但是却给了我4号，这是不正常的，于是不返回4号确认，而是继续返回一次2号的重复确认。==
同理，C继续发5号包，S仍然返回2号重复确认确认；C继续发6号包，S仍然返回2号的重复确认。此时C这端，==连续收到了三个2号重复确认==。这就是一个快重传的信号，C端此时直接将`2+1=3`号包进行重传。若这次成功，S端接收到了3号包，于是他会返回6号确认，提示C端，按照序列号，一直到6号包位置都成功接收了。以上过程是很快的，通常到这个时间点，仍然还未超出RTO时间。所以这种做法被称为“快重传”。

以上就是快重传机制。一言蔽之，<font color="red">当连续收到三个重复确认时触发快重传</font>。画个图大概长这样：

![image-20210708212926382](/Users/wyzypa/Pictures/TyporaImages/逆袭进大厂计网篇笔记.asset/image-20210708212926382.png)

#### 快恢复

发生快重传后，执行快恢复算法策略。具体的，将ssthresh和cwnd两个都设置为当前cwnd的一半，然后开始执行拥塞避免算法，即线性增大cwnd。
有的快恢复实现也会将`cwnd += 3`之后再开始拥塞避免算法。因为发生快重传后，至少有三个包（发生重传的包以及其后两个正常到达S的包）已经离开网络，可以适当加大窗口。

总体来说，快重传+快恢复是对原来实现中发生重传就直接一下子打回解放前的做法的一种修正。兼具了效率和拥塞控制的做法。

综合了慢开始、拥塞避免、快重传、快恢复四种机制的发送轮次与窗口大小的示意图大致如下（图中包括了Tahoe和Reno两种机制）：

![image-20210708232934962](/Users/wyzypa/Pictures/TyporaImages/逆袭进大厂计网篇笔记.asset/image-20210708232934962.png)

#### 为什么是三次重复确认后快重传？

应该意识到，快重传的触发条件应该是明确判断到了“丢包发生”，可是重复确认机制本质上是进行的“包到达顺序乱序”。
实际上，因为网络抖动问题很多时候会引起包到达的顺序异常，因此要确定一个合适的值。

实践证明，两次重复确认（即`n+1`和`n+2`号包比`n`提前到）的情况由网络抖动引起的概率还较大，而三次基本可以确认是真的丢包而不是网络抖动了。因此确立了“三次重复确认后快重传”的规则。

## TCP流量控制



## TCP粘包问题

## TCP可靠性

## 常见的TCP协议





# IP基本

## 子网数量、主机数量和子网掩码

笔试题中经常会碰到这类问题。这里就特地挑出来说一说。问题的背景，是将一个局域网划分成几个子网。
首先我们要确定当前要分割的局域网是哪型的，以C型网络为例，原生C型网络地址范围是`192.168.0.0 ~ 192.168.255.255`。当然，实际的局域网通常不会用那么全，通常会是`192.168.1.0/24`。

注意，这是一个局域网，其中有256个IP（刨去网络地址和广播地址，实际可用表示主机的应该是254个）。现在，加入我想将其分成n个子网，该怎么办。分成n个子网，就意味着我们需要在上述256个IP范围内找出n个，将其作为网络地址。一般情况我们都平均分，即让每个子网的主机IP数尽量相等。
于是就有了，在256的8个位中，从高位开始用若干个位数来表示网络，剩余的表示每个网络中的主机地址，这样的方案。

比如我想要分8个子网，每个子网IP数量是32。所以取3位作为网络位，剩余5位做地址位。
3位是网络位的意思就是，`000, 001, 010, 011, 100, 101, 110, 111`这8个作为网络地址，或者说子网网段的起始（别忘了后面补上5个0）。
即`192.168.1.0, 192.168.1.32, 192.168.1.64, 192.168.1.96 ... `当然这些都不是网络的表达方式，还缺一个子网掩码呢。而这个掩码相比于原来的`255.255.255.0`在最后一字节的高位3个是1，所以是`255.255.255.224`。

上述刚好分成8个，恰好能用若干个1后面跟若干个0表示。如果不是二进制整数，比如20，那么应该向上取整。
若要分20个子网，显然4个1只能分16个，不够，所以分配5个1。换言之，`192.168.1.0/24`划分20个子网时，子网掩码应该是`255.255.255.248` ，因为248 = 11111000~(2)~。

# 其他

## ARP与RARP协议

在局域网内，由于主机之间互相都处于同一个网段，互相之间通信可以不走到网络层，直接在网络接口层就可以解析完毕。然而应用程序为了保证通用性，通常都是用IP作为目标主机的标识。为了能够更有效率地通信，就需要将IP转换为局域网中的物理mac地址。

简单来说，ARP协议实现知道IP找mac地址，RARP实现允许知道mac找IP地址。两者都是内网通讯时用的协议。



```
TODO
TCP/IP协议族
	三次握手四次挥手
	TCP拥塞控制四大算法
	流量控制
	DDos攻击与TCP的联系
	TCP与UDP
		区别、常见的代表性应用层协议
IP计算（子网、掩码等
几种常见的网络攻击
	SQL注入
	DDos
	XSS
	CSRF
	文件上传漏洞
	
```

