# Python中的基本数字表达
>参考：https://zhuanlan.zhihu.com/p/91967268?utm_source=wechat_session

## 二进制码
在数学中，我们可以将一个十进制数转化为一串0和1变成二进制数。而正负号是额外加的。
比如5的二进制表示是`101`。那么-5可以写作`-101`。

而在实际的计算机中，因为要做到在计算机中区分正负数，通常选择将固定位数表示整数时，最高位当做符号位。
自然的，符号位0表示正数，1表示负数。

这么一来，在计算机中表示的二进制数就有一个"机器数"和"真值"之间的对应关系。
比如5和-5在计算机中用8位表示分别可以写作`0000 0101`，`1000 0101`。
对于-5，其虽然表示成`1000 0101`，但是其真值是`-5`，因为考虑了符号。而不是机器数的`133`。

### 原码、反码、补码的定义以及转换规则
以上定义的，最高位作为符号位，其余位表绝对值的表示形式，称为"原码"。
比如1的原码是`0000 0001`。
比如-1的原码是`1000 0001`。
原码还是比较接近人类的表达习惯，看起来并不难懂。

反码是计算机中原码之外另一种二进制表示整数的方式。（不要问为什么需要这么一种拐弯抹角的表示方式，下面会说。
具体的，反码分类讨论。如果是正数，则保留其原码形式。
如果是负数，则是在原码的基础上保留符号位，反转其余所有位置得到的结果。
比如1的反码是`0000 0001`。
比如-1的反码是`1111 1110`。

补码是原码和反码外的第三种方式。
仍然分类讨论，如果是整数，保留原码形式。
如果是负数，则在原码的基础上保留符号位，反转其余所有位置，再+1。即在反码的基础上再加一。
比如1的补码是`0000 0001`。
比如-1的补码是`1111 1111`。

简单总结一下，
==对于正数，三码合一。
对于负数，反码是原码的"真值部分取反"，补码是原码的"真值部分取反+1"。==

#### 补码的小性质
在n位表示的前提下，若一个负数`a`，将其补码的符号位置零得到一个正数`b`之后，有如下关系：
`b = a + 2^(n-1)`。
比如8位的-5是`1111 1011`。通过置零符号位得到`0111 1011`即123。
-5 + 2^7 = 123 或者表示为 123 - 2^7 = -5。

另一方面，8位整数中`-5`的表示若放到更高的位数比如32位中，显然这就是一个正数了。
这个数显然就是`0111 1011` + `1000 0000`，即123 + 2^7 = 251。

以上几个数之间的关系整理如下， 最好能运用的滚瓜烂熟：
```text
8位整数的前提下、
-5 和 123 是差一个符号位。
-5 = 123 - 2^7
-5 和 251 是8位和更高位定义的同一个二进制表示， 251 = 123 + 2^7
```


### 为什么要用反码、补码
本来，如果可以愉快地使用易懂的原码表示整数并且进行运算，那么最好了。

但是人们发现用原码表示计算机中的整数并不是很方便。
这也主要是因为受到了计算机的机能限制。计算机的计算有两个特点。
第一，只计算加法，因此减去一个数其实是当做加上一个负数来计算的。
第二，算一个加法可以说是计算机中最最基本的操作，为了计算效率应该让电路设计的十分简单。

于是，用原码保存数据并进行计算的缺点出现了。由于第二个特点，我希望不要在电路上多余设计一个模块来分割判断符号。
同时，减去一个数是加上其相反数的操作。
如果使用原码，则做`1 - 1 = 0`的计算时，会发生以下情况：

```text
1是 0000 0001
-1是 1000 0001
两者相加得到 1000 0010 = -2
```
于是聪明的科学家尝试采用反码计算。如果用反码，上述计算可以变成：
```text
0000 0001 + 1111 1110 = 1111 1111 == -0
```
结果是`1111 1111`，别忘了这也是个反码所以转换成原码后我们发现其恰好是`-0`，从数学意义上来说已经得到正确答案了。

但是显然，使用反码也不是最佳方案。究其根本，反码的0对应了两种编码`0000 0000`和`1111 1111`。
我们当然希望数和编码时一一对应的。

于是，最终方案，补码登场。
用补码计算上述`1-1=0`时，由于-1的补码，是原码"真值部分取反+1"，是`1111 1111`：
```text
0000 0001 + 1111 1111 = 1 0000 0000
由于我们限定做8位整数的加法，因此截除首位1，得到0000 0000，这也恰好是0的补码。 
```
另一方面，看`-1 + -127`这个计算：
```text
1111 1111 + 1000 0001 = 1 1000 0000 => 1000 0000
```
这个计算正确结果应该是-128，绝对值超出了7个真值位可表达的范围，本来算溢出了。
而在补码形式中，`1000 0000`这个编码又不对应任何数。
（补码转回原码时要"真值部分-1取反"，可此处真值已经是0，不能再减小）

于是，将`1000 0000`这个编码定义为`-128`，一举两得。
一方面解决了`-0`问题，另一方面还扩大了一个可表示的数字范围。

## Python中的整数表示
Python中提供了int和long两种整数类型，但是并没有明确位数，这也就带来了很多比较迷惑的问题。

通常，在确定某个数字可以用n位带符号整数表示的时候，可以通过类似以下的办法来获得其二进制表达：
```python
def show_binary(num, bit):
    res = []
    for i in range(bit):
        res.append(num >> i & 1)
    res.reverse()
    return ''.join(str(i) for i in res)
```
换言之，如果以上函数输出的二进制表达，首位符号与输入的num的实际符号不匹配，则说明出现了溢出的情况。

另一方面，从二进制去构造一个数的时候也要注意限制条件的位数。比如告诉你要构造一个32位整数的时候，
当遍历到第32位二进制位，就该意识到这个是个符号位。
如果其值是0还好办，如果是1，那么就该意识到要求的输出是个负数，不能直接`|= 2**31`（因为那样会变成更大的正数），
而是采用上面那条补码的性质，`-= 2**31`
上述可见`LC.137`作为练习题。

## Python中的浮点数表示
>参考https://zhuanlan.zhihu.com/p/58731780

计算机中所有数据都得用二进制存储。
整数数据总体来说比较方便理解，毕竟二进制和整数是一一对应的。

可带有小数点的浮点数该如何处理呢。

其实这和Python也没太大关系，而是所有计算机语言实现时，都统一采用了IEEE.754这个标准。
这个标准，其实就是一个二进制和浮点数之间互相映射的协议，大家都遵守。

这个标准中规定了两种类型的浮点数，占32位字节的单精度型(float)和占64位字节的双精度型(double)。

两者大同小异，下面默认以双精度型进行说明。

### 二进制转换浮点数
下面看这样一串64位二进制字符串：
```text
0100000000101001000101111000110101001111110111110011101101100100
```
顺便一提，如果这串字符串表示的是一个整数（因为是64位，还是个long型整数），那么他是
`4623252388170382180`。
转换规则很简单，首位是0说明其是一个正数，完了一位一位解析即可。

现在，我们要把这串字符串当成一个double型浮点数进行解析。
我们将其分成下面三个部分：
```text
0               (第1位)
10000000010     (第2位-第12位，共计11位)
1001000101111000110101001111110111110011101101100100    （剩余所有位）
```
为什么按照这样的长度分成这样三部分？这是IEEE规定的。

#### 每一部分的解析规则
这三部分分别表示了组成一个浮点数的三部分，分别是sign(符号位)，指数(exponent)，小数(fraction)。
我们只要从字符串中将这三个要素解析出来，然后进行简单的计算组合就可以得到浮点数的值。

先来说说三个部分分别如何解析。
首先，符号位，很好理解，和符号整型数一样，0代表正数、1代表负数。

然后，指数部分表示的是一个不带符号的整形数`c`，但`c`并不直接表示指数，而是取用`c - 1023`表示指数exponent。
其中，1023称为"指数偏移量"。
因为10位表示的不带符号的整数`c`的范围是`[0, 2047]`，所以此处`c-1023`即exponent的取值范围是`[-1023, 1024]`。
在最后计算结果的时候，乘以`2 ^ exponent`，这也是这部分被称为指数部分的理由。

最后，fraction表示的是一个范围在`[1,2)`间的小数。和指数部分一样，fraction中的二进制并不直接表示什么内容。
这52位的解析方式是这样的：
如果将其写作`m1 m2 m3 ... m52`，那么其表示的数是`sum(2 ** (-i) for i in {1...52} if mi == '1')`。
也就是说，第`i`位（注意i不是下标）如果是1，那么结果就加上`1 / (2^i)`。
显然，如果这52位都是1，那么得到的结果是`1 - 2**(-52)`，这是一个很接近1的数了。
另外别忘了定义的这个fraction是一个`[1,2)`之间的数，所以还要再加上1，才得到fraction。
没有加1的这部分小于1的数被称为尾数，也写做`m`。
根据上面描述，fraction部分的取值范围显然是`[1, 2-2**(-52)]`。

得到上面三部分的结果之后，最后计算总的结果，公式如下：
```text
res = (-1)^(sign) * 2^(exponent) * fraction
```
显然，当exponent最大，fraction也最大时，能取到double型数据的上限大约是`2*10^(308)`
当exponent最小，fraction也最小的时候，能取到double型表示的最小正数大约是`2*10^(-308)`
另外，当上述`c=0,m=0`的情况，即整个二进制表示都是0的时候，此时虽然数学值是`2^(-1023)`，但是为了和浮点数定义统一，这种情况定义为0。

#### 实际操作
好的，根据以上规则我们来实际演示一下如何解析。
再次重申一下，最初的64位二进制字符串，被分成了如下三部分：
```text
0               (第1位)
10000000010     (第2位-第12位，共计11位)
1001000101111000110101001111110111110011101101100100    （剩余所有位）
```
我们看到，符号位是0，说明这是一个正数。

接着解析指数部分。`10000000010`解析出来是`c = 1026`。
得到`exponent = c - 1023 = 3`。

再解析尾数部分。可以用下列代码解析：
```python
m, base = 0, 1
for c in s:
    if c == '1':
        m += 2**(-base)
    base += 1
```
运行上面代码得到`m = 0.56825`

接着拼凑各个部分：
```python
res = -1**(0) * 2**(3) * (1 + m)
```
也就得到了最终结果res是`12.546`。
即，上面这个二进制字符串如果被解析成double型数据，将会是12.546。

#### 解析用Python代码
```python
def bin2double(s):
    assert len(s) == 64
    sign, expo, frac = s[0], s[1:12], s[12:]

    sign = 1 if sign == '0' else -1
    expo = int(expo, 2) - 1023

    def str2mant(subs):
        m, base = 0, 1
        for c in subs:
            if c == '1':
                m += 2**(-base)
            base += 1
        return m

    frac = str2mant(frac) + 1

    return sign * 2**(expo) * frac
```

### 单精度型float以及浮点数的精度问题
以上例子以双精度型为例，其实单精度型大同小异。
只不过单精度型中，exponent和fraction的位数分别是8位和23位。

从上面的实操中可以看到，即使double尾数有52位，但是其表达的精度始终是有限的。
如果一个数的精细度低于`2^(-52)`这个量级，那么double也是能对其做一个近似而非准确的表达。
这也是浮点数大部分情况下都是近似而非准确表达的原因。
当然因为尾数的位数double比float要多，所以其精度自然也就高。

这种思想倒和量子力学有点像。我们的世界看似是连续的，其实是一个个非常小的普朗克单位的时间和能量叠加起来的。
在double的世界中，一个"普朗克"量是`2 ** (-52)`约等于`2.22 * 10^(-16)`。
所以用double表示数据时，只保证前15位有效数字，而第16位及以后只能做到部分精确。
类似的，float是前7位有效数字，往后是部分精确。

### 浮点数转换二进制
具体的算法这里先不提了，先给个工具：
>http://www.binaryconvert.com/convert_double.html
>这个网站可以基于IEEE协议，将某个小数转化成相应形式的二进制数据。

# Python3中的基础数据类型

Python(3)中的基础数据类型包括了int, float, str, tuple, list, set, dict这些。（注意，Python3中不再区分int和long）
这些基础数据类型的使用以及一般常用的接口早就滚瓜烂熟了，就不多说了。这章更多的是想说说这些基础数据类型的底层实现原理相关的一些内容。

## List

### 动态扩容机制

相比于传统数组，Python中的列表好用就好用在于，1.他可以装任意类型的数据， 2.他不用在声明时声明固定长度并且使用时不能超过。

第一点，因为Python中所有东西都是对象，所以列表只需要维护对象的引用，就可以做到装任意东西（事实上列表是一个引用的数组）。
第二点，则是因为Python的List的动态扩容机制了。动态扩容机制十分简单易懂，在标准CPython实现中是这样的：

空列表时，只申请保留一些列表meta信息的空间，大概在50-60字节。之后持续的append元素进来。
当长度到达4时，第5个进来前，扩容一倍，长度变成8。又来4个后，再扩容一倍，长度变成16。
之后第17个元素进来前，16扩容9个单位，变成25。之后每次扩容，扩容步长+1，所以整个需要扩容的长度形成的一个序列是：`0 4 8 16 25 35 46 58...`。

更具体的，上面==每一个单位，其实是一个引用的长度，64位系统的话就是8个字节==。所以，运行下面这段程序可以得到所示输出：

```python
import sys
lst = []
for _ in range(27):
	print(f'length = {len(lst)}, size = {sys.getsizeof(lst)}')
  lst.append(None)
  
'''
length = 0, size = 56
length = 1, size = 88
（略）
length = 4, size = 88
length = 5, size = 120
（略）
length = 8, size = 120
length = 9, size = 184
（略）
length = 16, size = 184
length = 17, size = 256
（略）
length = 25, size = 256
length = 26, size = 336
'''
```

另外，==所谓的“大小从m扩容n”的过程，其实是指在内存中申请一个全新的n大小的空间，然后将原空间中的m个元素复制到这片空间的前m个位置==。非常单纯的做法。

### 列表生成式

列表生成式是Python中一个比较有特色的语法了。
这个本身并不复杂，也早就用习惯了。这里主要提两点。

第一，列表生成式的默认形式是生成一个实际的列表。换言之`[i for i in range(n)]`之类的表达，实际上就是会生成一个长度为`n`的列表，因此如果`n`较大，则会占据较大内存。

第二，生成式两端的括号还可以不是中括号。比如，如果是小括号，这不是说生成元组，而是将上述列表变成了一个生成器（这也恰好解决了第一点提到的问题如`(i for i in range(n))`）。
除了小括号，还可以换成大括号。换成大括号后，分两种情况：
如`{i for i in range(n)}`是生成一个set。
如`{i: i for i in range(n)}`则是生成一个dict。

## Dict

### 实现原理

我们知道，字典就是一个哈希表。

### ⭐️哈希表

来复习一下基础数据结构知识。哈希表是内存中一片连续的空间。但是和数组不同，哈希表的存储方式并不是从前往后一个个存储的。
构成一个哈希表，除了这片空间，还==需要指定一个哈希函数以及哈希冲突解决方案两个东西==。

哈希函数的作用，是将一个key映射到一个当前哈希表合法的index值。当然，通常`|key| >> |index|`，即key的数量总是很多的，于是就不可避免地出现哈希冲突，即不同的key经过哈希函数处理，得到的输出index相同。此时第二个要素，哈希冲突的解决法就发挥作用了。

哈希冲突的解决大的，可以分成内消解和外消解两种。我们先看内消解。

#### 哈希冲突的内消解

内消解，顾名思义，就是将哈希冲突在存储区内部想办法解决。通常的思路就是当哈希冲突，就找数组中其余还空着的空间，插入进去。
这种方法也被称为开地址法。
显然，开地址法还需要确定，找剩余空着的空间的策略，称为探查方式。下面是两种比较有代表性的探查方式：

- 线性探查法

  顾名思义，哈希冲突后，从冲突位置开始向右扫描，找到第一个空格就填入数据。
  线性探查虽然实现简单，但是由于总是遇到空格就填上，就会导致整个数组的前半部分比较拥挤，随着元素增加，探查时间将越来越长。

- 双散列探查法

  双散列探查，首先在原哈希函数的基础上，设置第二个辅助哈希函数。
  当哈希冲突发生时，即`hash(x)`下标出已经有值，此时将尝试把x放入`hash(x) + sub_hash(x)`中。

  双散列探查利用了第二个哈希函数，尽可能地减少线性移动以及哈希码的局部堆积。

#### 哈希冲突的外消解

- 桶散列（链表哈希）

  这里，线性空间中每一项不再是简单的单个value，而是values，values是发生哈希冲突的各个value形成的链表。
  桶散列中，只要不是脸特别黑，所有元素都哈希冲突了的话，性能就还可以。同时实现起来也很方便。
  值得一提的是，桶散列除了链表实现，每个哈希冲突的哈希值下的东西，除了链表，还可以用顺序表，或者一个小哈希表等方式实现。

- 外部溢出区

  这里，哈希冲突的解决方法就是不解决。发生哈希冲突后，就将这个元素给扔到外部溢出的区域中。外部溢出区可以是一个简单的顺序表，或者链表，或者又一个哈希表等等。

#### 平均检索长度

显然，评价一个冲突机制好不好，得看在这个机制下一个key可以再计算多少次之后找到相应的value。而具体的量化指标，就是称为平均检索长度（ASL）的指标。

这里我们先看检索一个key的情况。通过哈希函数，可以计算得到其在哈希表中的下标，然后检查下标中保存的key值是否与之匹配；若否，说明哈希冲突，则根据哈希冲突处理方法进行相应的下一步计算，以此类推。假设这个key在最终找到值或者认定哈希表中没有当前key的时候，进行了`c`次计算，即进行了`c`次key值匹配比较。

对于哈希表中的所有key，都会有一个`c`。另外还需要考虑哈希表中各个key是否会等概率地被检索。通常认为等概率。假设共有`n`个key。在这个情形下，这个哈希表中，检索一个key时需要的key值匹配比较次数的期望是

$ASL=\dfrac{1}{n}\sum_{i=0}^{n-1}c_i$

这也就是所说的这个哈希表的平均检索长度ASL了。

### 至于Dict…

其实以上哈希表是对标set讲的，因为只出现了value，没出现key。至于Dict，无非就是把上面用来哈希的输入数据，从value变成了key而已。另一方面，表中每一格除了key本身，还需要存储哈希值和value。

#### 内建hash函数、哈希值对数组长取余

上面叙述中，哈希函数到底是什么样的始终没有提。另外，我们直接假定哈希函数的输出就是下标了。实际上中间还有一些细节。
首先，Python中所有用到散列的地方，基于的哈希函数都是内建的`hash`函数。这个函数可以将Python中任意不可变对象（int, float, tuple, str等）都转换成一个整数，这个过程就是哈希函数本身的工作。

事情还没完，若尝试

```python
>>> hash('hello')
1618767383509003088
```

你会发现，raw的哈希值是很大的。我们不可能真的申请这么大一个数组来保存这个哈希值吧。所以通常，还需要用这个值对数组长度进行取余。而这个`hash(x) % len`才是最终放入数组的下标值。

> 内建hash函数内部到底怎么计算哈希值，目前我还没研究过。泛泛来说，哈希函数计算哈希值可以有折叠法、平方法、除余法、基数转换法等等、这些方法可以参考《Python数据结构与算法》的P.276。

#### 自动扩容机制

因为Dict的底层还是一个数组，那么和List一样，就面临着，随着保存的项越来越多，会导致数组长度不够用，此时就需要自动扩容。
Dict因为是哈希表，一般不会像List那样真的等到一点空间都没有再扩容，那样的话在那之前就会有太多哈希冲突发生了。

Python规定，Dict之类的底层是哈希表的东西，==在哈希表中有`2/3`容量被占据后进行扩容。扩容时现申请新的大空间，然后将原空间中的数据根据新空间的长度进行重新计算哈希值并填入==。
初始情况下，Dict底层哈希表有8个格子供容纳数据。当填入5个数据，试图填入第6个时，Dict发生第一次扩容。==扩容默认扩大当前实际已有元素的4倍==，即`5 * 4 = 20`个格子。

此后若继续填充，则会在尝试填入第14个数据时进行扩容，扩成80个格子。
当哈希表内数据超过50000个后，扩容倍数将从4倍变成2倍，以防止过度浪费内存。

注意，上面所说的一个“格子”，正如之前所说，其实是一个`hash(key), key, value`的三元组。所以一个格子的大小，其实是三个引用的大小，即24字节。

> 以上是书上的描述，实际上，模仿List扩容机制的实验，做了下实验发现好像又不是这样。仅供参考吧。

### 自定义类的哈希

在Python自带的数据类型中，只有不可变数据类型满足可以被哈希，即`hash(x)`不报错。
对于自定义的类，只要能实现`__hash__`这个魔法方法，那么`hash(instance)`的时候就去调用这个方法，返回值就行了。

==另一方面，能不能哈希和是不是不可变对象之间不能画等号。内建类型只允许不可变对象被哈希，是考虑到哈希存储后，后续检索时如果对象本身改变了那么就无法检索到了，这个问题。而对于你自己的自定义类，系统不会考虑这一点。==所以一定要注意自己的类如果想让其可以被哈希，就一定得保证其是不可变的（除非你确定他不会被拿去放到set，dict中去）


# Python中的语法糖

迭代器和生成器都是让我们自定义的可迭代对象。

## 迭代器
严格来说，实现了`__next__`方法的类都是迭代器类。
通常，迭代器还会实现`__iter__`方法。
比如
```python
class MyIterator:
    def __init__(self, n):
        self.n = n
        self.i = 0

    def __iter__(self):
        return self

    def __next__(self):
        if self.i == self.n:
            raise StopIteration
        self.i += 1
        return self.i
```

在说明上面这段代码之前，先来看看迭代器是怎么用的。通常，迭代器总是用在for循环中，即
`for item in XX`(`XX`是`MyIterator`的实例)。

现在深入看一下这句话。这句话的实质其实是`for item in iter(XX)`。其中`iter`是Python内置的迭代器化函数。
又因为`MyIterator`类实现了`__iter__`方法，所以上述语句等价于
`for item in XX.__iter__()`。这也就要求了`__iter__`返回的必须是一个迭代器对象。

接着，开始迭代的时候，其实python不断调用上述返回的迭代器对象的`__next__`方法直到`StopIteration`这个异常发生。

上面这个类，将两个魔法方法都实现了。因为实现了`__next__`，所以他是一个迭代器。
又因为实现了`__iter__`并且返回的是`self`，所以他可以直接被写在`for`循环中。

事实上完全可以外包一层，先写某个类实现`__iter__`，然后在这个方法中返回`MyIterator(10)`（MyIterator实现了`__next__`）。

但是这里显然没什么必要，可以将两个角色组合在同一个类中。

在运行一次for循环的过程中，`__iter__`只被调用一次，而`__next__`被调用n次直到遇到StopIteration。

## 生成器
生成器就简单多了。就记住两种。

第一种函数式生成器，只需要在函数中将本来遍历取出的写上yield关键字即可。
有了yield之后，函数就是一个生成器了。大多数时候yield不和return混用。

第二种是表达式式生成器，和列表生成式很类似，只不过用小括号。如`(i for i in range(10))`。

## 装饰器
装饰器：最基本的形式是一个返回函数对象的函数。
作用：构建通用的"函数增强模板"。

总之记住，当定义带修饰器的函数如下之后：
```python
@xxx
def yyy():
    # do some thing
```
接下来调用`yyy()`时，调用的实质上是：
```python
xxx(yyy)()
```
这里的`xxx`，既可以是一个简单的函数名，也可以是一个带参数的函数返回，还可以是一个类名等。

下面从零开始梳理一下装饰器。加入我们有函数`bar`。
下面我想给他增加一个功能，在运行bar的业务逻辑之前打印`bar is running`这条信息。
再不修改bar函数本身的代码的前提下，可以这么干：
```python
def bar():
    print('bar!')

def en_bar():
    print('bar is running')
    bar()

bar = en_bar
```

如果此时还有一个`foo`函数，需要加强类似的功能，一模一样写一个`en_foo`就略显繁琐。
一个可行的做法是：
```python
def bar():
    print('bar!')
def foo():
    print('foo!')

def logged(func):
    def en_func(*args, **kwargs):
        print(f'{func.__name__} is running')
        func(*args, **kwargs)
    return en_func

bar = logged(bar)
foo = logged(foo)
```
logged实质上就是一个装饰器，其本身是一个函数并且返回的是一个函数对象。这个函数对象就是一个通用的功能增强模板。
通常为了最大程度支持被增强的函数，内层的`en_func`通常接收任意参数即`*args, **kwargs`。

再省一步，将上述`x = logged(x)`给去掉，就可以使用装饰器的语法表达：
```python
@logged
def bar():
    print(bar)
```
这样定义出来的bar函数与上面等价。

以上就是最简单的装饰器了。

### 带有参数的装饰器
注意到在装饰器语法表达中，`@xxx`中的`xxx`其实是一个函数对象。
掰开揉碎讲，其逻辑过程是，当你给出`@xxx`来修饰下方定义的`yyy`函数后，运行`yyy`函数时其实是运行了`xxx(yyy)`。

比如上面的logged本身就是一个函数对象。
既然如此，我们就可以通过定义一个"装饰器的装饰器"，即返回的函数对象本身是一个装饰器，来实现带有参数的装饰器功能。

比如：
```python
def level_logged(level):
    def logged(func):
        
        def en_func(*args, **kwargs):
            print(f'[{level}]{func.__name__} is running')
            return func(*args, **kwargs)
        
        return en_func
    return logged

@level_logged(level='INFO')
def bar():
    print('bar!')
```

### 类装饰器
类装饰器不是通过一个"返回函数的函数"实现，而是通过一个类实现。这就提供了更多灵活性给自定义装饰器。

具体来说，其实就是Python中类的魔法方法来实现类实例的函数化，即实现类中的`__call__`方法即可。
注意类定义时`__init__`方法需要接收被增强的函数对象作为参数。

就像上面所说的，`@xxx`修饰`yyy`函数时，执行`yyy(*args, **kwargs)`运行`yyy`函数就相当于执行`xxx(yyy)(*args, **kwargs)`。
当`xxx`是个类名时，显然`xxx(yyy)`就是在实例化，因此需要在`__init__`的输入参数中加上函数对象。

### functools.wraps
上面讲过，修饰器表达`@xxx`下面定义`yyy`函数，其实是代替了`yyy = xxx(yyy)`这句话。
而这个语句有一个小问题，就是原先的`yyy`函数被覆盖了。==虽说函数功能通常会被完整地抄到`xxx`的定义中，但是其他一些元信息会丢失。==

比如定义如下：
```python
def logged(func):
    def wrapper(*args, **kwargs):
        # do some thing
        func(*args, **kwargs)
    return wrapper

@logged
def bar():
    print('bar!')
```
此时如果查看`bar.__name__`，看到的将会是`wrapper`。因为实质上bar已经被狸猫换太子了。

如果想要留下原来的元信息，可采用如下方法：
```python
from functools import wraps
def logged(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        # do some thing
        func(*args, **kwargs)
    return wrapper
```

### 多重嵌套装饰器
一句话。
```python
@a
@b
@c
def f():
```
等价于
```python
f = a(b(c(f)))
```

## 上下文管理协议

Python中有一套机制叫做上下文管理。简单来说就是`with`关键字相关的使用。
和其他很多将自定义对象无缝嵌入Python语法的方式一样，要让自定义对象可以被`with`支持，需要在类定义中实现`__enter__`和`__exit__`两个魔法方法。

执行如下代码段时:

```python
with obj:
  xxx
# 上述代码等同于：
obj.__enter__()    # 触发enter方法
xxx    # 执行代码块中内容
obj.__exit__()    # 最后触发exit方法

with obj as f:
  xxx
# 上述代码等同于：
f = obj.__enter__()
xxx (这段代码里往往会用到f)
obj.__exit__()
```

而定义这两个魔法方法的范式如下：

```python
def __enter__(self):
  pass

def __exit__(exc_type, exc_val, exc_tb):
  pass
```

如上所示，enter方法并没有很多限制，就是一个普通的成员魔法方法，而你只要在里面实现一些执行代码块前要做的逻辑即可。

而exit方法会要求带有三个参数。如果上面的代码块无错误地执行完成了，那么这三个参数都是None。
相对的，若发生异常，则三个参数分别表示异常类、异常值以及异常跟踪信息。举个例子：

- 异常类： TypeError
- 异常值：name 'myName' is not defined
- 异常跟踪信息：Traceback (most recent call last): xxx

这三部分组成了Python的整个报错信息。
另外，`__exit__`方法需要一个bool类型的返回值。在代码块执行发生异常时，若返回True则表示异常在`__exit__`方法中被处理，不会传播出去；相反返回False则不处理而是直接将异常抛出。

# ⭐️Python 多线程与GIL

## ※进程和线程
一般意义上，我们知道进程是运行的程序的抽象。为了运行程序除了程序本身他还要维护很多其他信息。

在任意时刻一个CPU上只能运行一个进程，而由于CPU可以高速切换不同进程实例，所以即便只有一个CPU，对于用户来说似乎还是多进程在运行。

线程则是对进程的进一步轻量化。
一个进程可以包含多个不同的线程。同一个进程下不同线程间可以享用同一块地址空间，相同的全局变量等等。相对的，每个线程也有一些自己独有的信息，比如
程序计数器，堆栈等等。

进程和线程可维护的数据区别如下：
<img src="https://pic.leetcode-cn.com/1612667575-cWbpmB-os8-7.png" style="zoom:50%;" />

需要注意的是，虽然不同线程持有的信息可以分化，但是这种分化的独立性并不是很强（至少比不同进程间的分化弱）。
因此，一个线程理论上是可以读取、写入甚至删除另一个线程的所有信息。
这一块需要程序员自己控制，这也是为什么线程安全如此被重视。

相对的，线程-进程关系和进程-OS关系其实很像，但是进程间独立性更强。
对于进程间共享的内存内容，一定是只读的；而可写的内存内容，一定不是共享的。


## GIL
Python有多种实现，基于C的官方实现CPython的一个特点就是，所有程序都通过Python解释器这个进程执行，而且其规定了，任意一个时刻Python解释器只能执行一个线程。
这个其实就可以完全类比单CPU执行多进程的场景。虽然看起来是并发的，但是只是CPU切换得快，任意一个时刻都只有单个进程在跑。

而保证任意一个瞬间只有一个线程在跑的机制，就是GIL。使用Python解释器运行一次Python代码时，只会产生一个GIL。
换句话说，Python官方使用了最粗暴的机制保证了线程安全，即通过全局锁，只让一个线程运行。

具体来说，Python解释器运行步骤如下：
```text
1. 将GIL给到某个线程
2. 将上下文切换到对应线程
3. 运行
4. 结束运行，修改线程状态
5. 拿回GIL
```
在拿回GIL锁之前，线程状态可能会被修改为就绪态或者阻塞态。
如果是阻塞态，说明此时线程要进行I/O操作，而在其进行I/O操作的同时，拿回GIL锁后的解释器可以着手进行另一个线程的运行。

==因此，对于I/O密集型任务如Web访问、文件读取等，即线程经常会变成阻塞态的情况，Python的多线程机制可以起到一定的促进效率的作用。
但是对于CPU计算密集型任务，线程即使运行完成也只是变成就绪态，还要等下一次运行，那么这其实和单线程没有本质区别，因此发挥不了很大作用==。

### 为什么会有GIL

一个简单的知见：CPython开发初期用了很多C/C++库，而这些库都是线程不安全的。因为Python的初衷是要简单快速地编程，因此就粗暴地利用一把全局锁GIL强行实现了线程安全。

更加具体的说，基于C实现的CPython解释器在内存管理这方面没有做线程安全的考虑。比如举个引用计数的例子。我们知道Python中的变量都是通过引用计数来判定其是否应该继续留存在内存中。
在并发情况下，若没有并发控制，可能会有两个线程同时对某个共同变量的引用计数进行增减，但是因为是完全并发，所以可能增减操作相当于只进行了一次，从而导致各种问题如内存泄漏或者对象被提前释放等。

上述问题的一个解决办法是对所有对象都上一把锁。但是多锁又可能会引起死锁等更多问题。所以，使用最简单粗暴的办法，给解释器全局上一把锁，某个时刻只允许一个线程访问对象。

### 如何解决GIL带来的困扰
解决方案可以从如下几个角度来考虑

1. 使用进程级别的并发提升效率
   使用诸如`multiprocessing`模块等多进程手段，将并发提升到进程层面。当然这么做的缺点是系统开销更大
2. 使用其他不带GIL或者优化了GIL的解释器实现
   比如pypy, Jython等。
3. 利用Python可以与其他语言混合使用的特性
   结合Cython，Jython等模块，基于其他语言实现多线程部分。

### PyPy等解决方案简单介绍

首先说说Jython。Jython的实现中，不再使用一个暴力的全局锁GIL，而是在多线程场景下，对每个线程需要用的对象都设置一把锁。这样可以将锁的粒度降低到更细的层面。
但是显然，维护更多的锁并且保证不出现死锁的情况的成本也不低。更致命的是，这种方案也会损害单线程程序的性能。而后者可能才是更多人使用Python的主要方式。

接着是PyPy。PyPy是通过Python自身实现的Python解释器。首先需要说明，一般版本的PyPy并没有去除GIL，网上流传的说PyPy去除了GIL的，是PyPy的一个衍生版本，称为pypy-stm。其运用了一个叫做STM(software transactional memory)的技术保证了安全的线程并行。

> 但是令人遗憾的是，由于开发难度过大，PyPy的开发人员似乎已经在2019年放弃了进一步开发pypy-stm。所以目前这个项目可能处于烂尾状态。

简单描述一下STM的原理，就是说你的==线程代码中，绝大多数代码都还是互相独立，不会存在并发时有上述内存管理方面的问题。对于这些你确定互相独立的代码块，可以使用`TransactionQueue`之类的STM机制进行完全并发。==而这是安全的。

除了STM，PyPy还自带JIT (just in-time) 机制的解释方法。简单来说就是在解释器中设有一个缓存，将常用的字节码和二进制码维护在其中。这样，碰到常用的字节码时解释器就不用重新解释，直接读取缓存即可。从解释操作的层面进一步提升了Python程序运行的速度。当然这和线程并发没什么关系，这里就不多说了。

## Python协程

笼统地说，协程是线程内部的调度单位，又称为“用户级线程”因为协程层面的讨论都不涉及用户态和内核态的切换。通常可以用生成器来理解协程的运作流程。比如下面这段代码

```python
def generator():
    for num in range(3):
        print(f'Yielding Number {num}')
        yield num

def main():
    print('Start of Main...')
    for i in generator():
        print(f'Number is {i}')
    print('End of Main...')

main()
'''
STDOUT:
Start of Main...
Yielding Number 0
Number is 0
Yielding Number 1
Number is 1
Yielding Number 2
Number is 2
End of Main...
'''
```

上述代码很好理解，但是如果仔细分析一下运行流程，到底是怎样的？
首先，`main`函数开始执行后，来到了`for i in generator`语句。此时要求生成器对象返回一个数字。这时必然要转入`generator`函数运行。此函数开始执行后，先进入`num == 0`的第一轮循环，`yield`了`0`。但是请注意，此时generator函数执行就被挂起了，主线程又回过头去执行`main`函数。

换言之，==`generator`函数和`main`函数的两个执行逻辑可以视为同一个线程中的两个协程==。假设`main`和`generator`的两个协程称为A和B，最开始执行的是协程A，当要生成器返回数字时挂起协程A转到协程B。当协程B遇到`yield`，可以返回数字时，记录数字并线程再次回到协程A。

于是可以总结协程的几个特点：

- 协程就像是C语言中的todo关键字的作用，可以改变以往程序一条路走到底的执行方式，有秩序地在多个协程间反复横跳。
- 线程内的多个协程在任意同一时刻只有一个执行，其余被挂起。==所以本质上，协程是串行的，只不过提供了时间上非线性串行的可能==。
- 协程的切换仍需要切换寄存器上下文、栈等内容，但是和线程切换不同，协程切换不需要进入内核态，全程在用户态进行。因此协程的切换也最快。

更多协程与线程、进程的比较可以参考操作系统篇笔记。

### 为什么协程切换不用进入内核态

这个问题其实可以反过来问，即为什么线程切换需要进入内核态。
首先应该明确，线程切换和用户内核态转换之间并不是对等关系。==准确的定义应该是，当程序发生了系统调用，就需要从用户态进入内核态；系统调用完成后就从内核态返回用户态==。

线程的切换，发生的原因有很多，比如时间片用完，或者外部中断之类的。无论发生的原因是什么，触发线程切换的函数是实现在内核中的，是一个内核程序，因此调用这个函数是系统调用，因此会发生用户态->内核态的过程。

而协程的切换，是由程序员自己的代码触发的，比如上面的`yield`关键字。这不属于内核程序，因此自然就不用进入内核态。

# ⭐️Python内存管理

> https://www.zhihu.com/column/c_1273568922378719232  这系列文章从C源码层面分析，可以作为参考【TODO】

## 引用计数
在比较底层的语言比如C/C++中，程序员有时需要手动对变量进行整理，将不再使用的变量手动回收。
这里，回收是指去除变量名和数据之间的联系，并且将保存数据的那一部分内存空间清空。

在Python中显然不需要这么干。这主要是因为Python内部采用了引用计数机制来实时地维护所有程序中的变量。

所谓引用计数，是PyObject类的固有属性。我们知道Python中所有的对象，都是基于object这个基类，而这个类其实又是由C语言
实现的PyObject这个类。这个类中带有一个属性`obj_refcnt`进行引用计数的维护。

那么引用计数具体怎么用。==具体来说，当一个对象在代码中发生如下事件时，其引用计数会加一==：

- ==被创建（对于不可变对象来说是初次建立引用关系），如 a = 1==
- ==被引用，如 b = a==
- ==作为参数被传入函数==
- ==被放入某种容器数据结构比如list,dict等==

反之，如果发生如下事件则引用计数减一：

- ==被del==
- ==离开作用域==
- ==所在容器被销毁或者被从容器中删除==

使用内置的`sys.getrefcount`函数可以查看某个对象当前的引用计数。因为任意一个对象传入这个函数时根据规则计数都会+1，所以实际上返回的结果总是比实际的计数大1。

## 垃圾回收
上面我们知道了每个对象都自带引用计数。

当某个对象引用计数减小为0，那就说明已经没有任何引用指向这个对象，此时可以放心地回收这部分空间。
这就是基于引用计数进行垃圾回收的原理。

利用引用计数进行垃圾回收，好处在于逻辑很简单，同时具有实时性。但是也有一些缺点，比如需要额外维护引用计数，当容器引用层级较深时可能遍历其中对象比较耗时。
然而其最大的一个缺点是无法处理循环引用。这也意味着Python不能只用引用计数作为垃圾回收的依据。

### 循环引用
顾名思义，当a,b两个对象互相引用对方就是循环引用。循环引用也包括自己引用自己的情况。
这么搞会出什么问题？

首先，两个对象创建后的引用计数都是1，而在互相引用对方之后都变成了2。
此时如果del掉a,b两个对象名，那么计数减1。然而他们互相引用形成一个环，这个环外部没有对他们的任何引用但是因为这个环的存在，他们的计数无法减为0。
因为计数不能减为0，所以不能回收，因为不能回收，所以就发生了内存泄漏。

#### 弱引用

这里插播一个小概念。Python中可以使用`weakref`模块对对象进行弱引用。
所谓的弱引用，就是创建一个指向对象的引用但是不增加这个对象的引用计数。

换言之，当此对象的所有其他引用都已经失效，只剩下弱引用的时候，Python GC会将对象直接回收，并不会关心你的弱引用还存在。

### 解决方案：标记-清除算法
如上所述，单纯参考引用计数进行垃圾回收无法解决循环引用的问题，因此这里导入标记-清除算法作为补充。

这个算法的描述见参考
>https://zhuanlan.zhihu.com/p/83251959

简单来说，其实整体的引用可以看做一个以对象为节点，以引用为边的有向图。
标记-清除算法，顾名思义，分成标记和清除两个阶段。
标记阶段，GC会将所有“可达”和“不可达”对象通过算法标记区别。清除阶段，则是将那些“不可达”的对象作为垃圾进行回收。

具体工作流程是这样的：

1. 针对所有对象，先为其赋予一个`gc_ref`变量作为GC过程中使用的引用计数变量（因为现在只是在GC，不能去修改真的引用计数值），初始化为当前对象的引用计数值`ref_count`。初始化两个区域（本质上是两个链表），一个是可达的Object to Scan区，另一个是不可达的unreachable区。

2. 遍历每个对象，==将其引用的所有对象的`gc_ref -= 1`。注意，是将其引用的所有对象，而不是其自己的`gc_ref`减去1==。上述两个过程可以描述为下面图的变化过程：

   ![](https://pic1.zhimg.com/80/v2-0d5071093adaa02bc03fa3dfd91aa5bc_1440w.jpg)

   ![](https://pic2.zhimg.com/80/v2-d7314ead6b303f08a91687577c045585_1440w.jpg)

   3. 将所有`gc_ref`归零的对象移入unreachable区。

   4. ==从`gc_ref`尚未归零的对象出发进行图扫描。对于可以通过扫描到达的对象，即使其`gc_ref`归零并且被移入了unreachable区，还是将其移会object to scan区==。如图：

      ![](https://pic3.zhimg.com/80/v2-6fd40c055a6633c654acaf05f472c1b2_1440w.jpg)

   5. 此时，所有对象就被正确分成了可达与不可达两类。将不可达的那些进行GC即可。`gc_ref`这个GC用各个对象的临时变量可以回收。

### 分代回收
分代回收并不是一个独立的方案，可以看做是对标记-清除以及其他一些方法的优化。

由于程序的局部性，内存中的对象通常有80%-90%都是"短命"的，即被使用没多久后就被回收。
分代回收机制将内存块分成0，1，2三个世代。数字越大的世代，其对应的内存块越长寿。长寿的定义是，经历过的gc扫描次数多。
比如某个0世代的内存块经历一次gc扫描后没被回收，那么他就被归入1世代；同理，1世代再经过一次扫描仍然健在，就归入2世代。

显然，长寿的内存块，经历了这么多次gc扫描都没被当垃圾回收，其是垃圾的概率就相应小。
在这个前提下，==每次gc扫描可以优先扫描小的世代，从而提高扫描效率，这也是分代回收机制的核心所在==。

更具体的，分代回收为每个世代设置一个threshold，并且开始GC。
每当某个世代新增内存块数目超过threshold之后，gc就开始扫描这个世代以及所有更小世代，进行垃圾回收。

### Python进程退出时内存无法被回收?

有个面试题问到，python的进程退出后，内存是否被释放？答案都说，Python中的循环引用、以及引用自全局命名空间的对象等的内存不会被释放。初看觉得很不可思议，一个进程都退出了，怎么可能内存还不被释放呢。

其实是这样的，这道题想问的，是指Python自身通过GC机制进行内存回收。当Python进程退出，自然GC机制也就终止了。在那一刻，内存中剩余的循环引用的对象、基于C语言的`malloc`函数申请的内存等部分，自然是无法回收的。
然而从外部视角看，当下的所有操作系统，在一个进程退出后都会对分配给一个进程的内存空间进行回收。因此不存在说因为Python自己的GC机制不工作，就导致内存泄漏的事情发生。

换言之，==CPython在进程退出时，不会主动的进行GC，从而导致循环引用，`malloc`等情况的部分内存无法被优雅的释放。而这部分内存也并不会一直在那，而是会被操作系统回收==。

## 深浅拷贝与循环引用

> https://zhuanlan.zhihu.com/p/122501439

赋值 以及 深浅拷贝有什么区别，相信可以一句话说出来。比如下面这个例子：

```python
l1 = [1, 2, ['a']]
l2 = l1
l3 = copy.copy(l1)
l4 = copy.deepcopy(l1)
l1[1] = 3
l1[2].append('b')
print(l1, l2, l3, l4)
'''
输出：[1, 3, ['a', 'b']] [1, 3, ['a', 'b']] [1, 2, ['a', 'b']] [1, 2, ['a']]
'''
```

简单来说，赋值直接拷贝对象整体的一个引用，因此原对象中任何数据改变都会被赋值后对象体现出来。

浅拷贝，则是将对象中最上面的一层引用做一次拷贝。如`l3`初创时，其内部就是三个和`l1`不同的引用分别指向了`1, 2, ['a']`三个对象。对于不可变对象如`1, 2`，在`l1`中修改其值相当于是让`l1`相关引用指向新内存，自然不会影响`l3`中引用。
另一方面，对`l1[2]`这个列表修改时，并不是修改引用指向，而是修改了引用指向内存中的内容，因此指向同块内存的`l3`中相关值也变化。

深拷贝，则是递归地对可变对象内部进行拷贝直至递归到不可变对象。比如对于上例中的子列表，深拷贝到`l4`时，发现`l1[2]`这个引用指向一个可变对象子列表。所以`l4`这边直接新开一片内存，并进入子列表中获取其内容。如果内容还有可变对象，则继续递归进入，直至内容全是不可变的。然后依次将不可变对象的引用放到新内存中。从而实现了深拷贝中完全的独立拷贝。

### 带有循环引用的深拷贝

上面虽然解释了深拷贝的大概原理，但是存在这样一个问题：

```python
a = [1, 2]
b = [3, 4]
b.append(a)
a.append(b)
print(a)    # [1, 2, [3, 4, [...]]]
print(b)    # [3, 4, [1, 2, [...]]]
```

如果此时按照上面描述的递归算法去deepcopy一下a或者b，显然会无穷递归下去从而超出递归限制。但是实际上你用`copy.deepcopy`试一下就知道，并不会真的报错。说明内建的deepcopy函数是带有循环引用的处理机制的。

其实这个机制非常简单。
无限递归的问题出在，当我试图复制带有（带有`a`的）`b`的`a`时，第一次碰到`b`的时候好说，开辟一块新空间存放b中内容即可。而在递归进入`b`后发现`b`中还有`a`，按照之前规则，又需要开辟一块新空间给这层的`a`。但是实际上对`a`，我们最开始就已经开辟过一块空间了。此时如果拷贝函数能够知道已经有`a`这块空间，就不用重复开辟。

==具体的，我们在递归的deepcopy函数中设置一个memory，维护某被拷贝对象ID与新对象之间的关系。（当然仅限于可变对象）==
这样，当我们试图递归拷贝一个被拷贝对象时，只要检查其是否存在于memory中，若存在，说明之前已经有开辟过一块内存空间并且进行了一部分或者全部的拷贝，直接返回即可。

这个思想其实就是DFS中为了不走回头路，而设置一个visited哈希集是一个意思。



## Python中的堆和栈

> https://stackoverflow.com/questions/14546178/does-python-have-a-stack-heap-and-how-is-memory-managed
> https://zhuanlan.zhihu.com/p/166160468

这里说的堆和栈不是指算法中使用的那两种数据结构，而是进程内存中的那两个分工不同的内存区块。

在传统概念中，栈用于保存一些非静态的基本类型的局部变量。Java中对对象的引用也存放在栈中。栈由外界系统自动管理。
堆在C中主要特征是可以让程序员根据自己需要在程序中动态申请释放，Java中的堆则主要用于存放对象，并且Java的自动内存管理机制也会管理堆。

在Python中，其实没有明确的传统意义上的堆栈概念，因为其比Java更强调减轻程序员负担。
==CPython实现中讲到，Python具有一个private heap，保存了Python中所有要用到的对象（Python中不存在基本类型的概念，即便是int数也是一个具有多种属性和方法的对象）。这个private heap由Python的内存管理器全权控制。
另一方面，所有指向这些对象的引用，全部都保存在栈中。==

上述架构可以用这个图表示：

<img src="/Users/wyzypa/Pictures/TyporaImages/Python笔记.asset/image-20210823152839618.png" alt="image-20210823152839618" style="zoom:50%;" />

# Python执行流程

> https://blog.csdn.net/june_young_fan/article/details/79755392
> https://blog.csdn.net/helloxiaozhe/article/details/78104975
> https://zhuanlan.zhihu.com/p/68465488

## 编译型/解释型语言

程序员一般写偏近自然语言的各种高级语言代码，而计算机不认这些字符串，只能执行所有都是0和1表示的二进制代码。如何将高级代码翻译成二进制代码，这个过程大概可以分成两类，即编译或解释。

编译是指，在运行程序前，用编译器对程序代码进行编译，将高级代码转换为二进制代码。之后直接运行二进制代码即可。并且这个二进制代码可以多次被运行而不用重新编译。编译型语言代表有C，C++等。

> 顺便一提，编译型语言比如C的编译流程是这样的：
>
> 预处理（去掉注释、替换宏等、检查Syntax等）、编译、连接

解释是指，无需编译，在程序运行时，由解释器逐行解释高级代码，并转化为二进制代码后运行，简单来说就是边编译边运行。
显然，每次运行相同的程序都要进行重新的逐行解释。解释型语言代表有Ruby。

注意到，上面两种类型，我都没提到Java和Python之类的语言。这是因为，上面这种编译/解释型的分类并不是绝对的。实际上，==Java和Python我们都可以认为是一种“基于虚拟机的语言”==。

### 虚拟机语言

以Java为例，Java的高级代码文本文件会首先被Java编译为 字节码 文件，命令如`javac hello.java`。注意字节码并不是二进制代码，而是一种更加贴近机器底层的，类似汇编语言的格式。这些字节码文件也就是常见的.class文件了。
接着，运行如`java hello`，字节码被Java逐行解释并运行。可以说Java是一种，先编译，后解释的语言。

Python也类似。只不过当你使用`python xxx.py`运行一个Python文件时，解释器默认先做编译，后直接解释执行。而不是像Java，两部是分开的需要输入两次命令。
Python默认将字节码文件保存在`.pyc`文件中。这个相当于Java里的`.class`文件。

虽然Java和Python在逻辑上运行过程是类似的，但是Java两步走，很像C的先编译再运行，而Python一步走，像Ruby的直接逐行解释，所以不严格的，可以将Java归类成编译型，Python归为解释型。

#### why？

为什么不直接转二进制代码，而要多出一个字节码作为中介呢？这么做好处其实多多。
比如可移植性。因为字节码由解释器解释成二进制代码，即机器指令再去运行。所以不同架构的机器，我只要开发相应的解释器，就可以让字节码顺利执行。换言之，一份代码可以在不同机器上通用。

### 其他分类标准

除了以编译/解释型语言为标准对编程语言进行区分，还可以将编程语言分成动态/静态类型语言、强/弱类型语言等。

动/静态类型区分在是否需要显式声明变量类型。若变量类型是在运行过程中由引擎动态决定，则为动态语言；若在编码时就必须指出，则是静态类型。

强/弱类型的区分在于引擎是否会自动进行类型的转换。比如让一个数字加字符串的时候，强类型语言可能会抛出错误，而弱类型语言可能会直接将数字转成字符串相加。

==至于Python，如上所述，其是一种 编译·解释混合型的、动态类型的、强类型的语言。==

## Python程序执行流程

> https://devguide.python.org/compiler/

运行命令`python xxx.py`会发生什么呢？上面我们说，解释器会先编译再解释执行。而更细的，整个流程分成四大阶段。

解释器和一些周边内容构建起的Python体系架构如图：

<img src="https://imgconvert.csdnimg.cn/aHR0cDovL2ltYWdlczIwMTUuY25ibG9ncy5jb20vYmxvZy84Njk0MjYvMjAxNjAxLzg2OTQyNi0yMDE2MDExNTEzMTgxNDMwMy0yMDkzNzQ2MDY2LmpwZw?x-oss-process=image/format,png" alt="img" style="zoom:50%;" />

下面来详细说说解释器工作的四大阶段。

### 词法分析

和C类似，Python解释器首先对代码文件进行词法解析。即将整个文本文件整理成逻辑行并且将行内各个token单独分离出来。
显然这个阶段可以做诸如变量名合法性检查、关键字是否写错、括号是否合法等等。
完成这部分工作的解释器组件叫做Tokenizer。

### 语法分析

这个阶段，一个叫做Parser的组件将上个阶段得到的tokens重新解析，构建成一个Abstract Syntax Tree(AST)，即语法树。
在语法分析中，会检查一些语法性的错误。比如break在不在一个循环里，return在不在一个函数里之类的。

### 编译

终于到Compiler进行编译了。简单来说，Compiler将基于上面生成的AST，生成Control Flow Graph (CFG)。这是机器运行时可以直接进行解读的内容了。

==编译的本质，是将代码中用到的一些内容如变量、函数等建立为PyCodeObject对象，连同CFG中描述的各种对象之间的关系一起，存放进内存中。==
==之前说的“字节码”，本质上也是这些PyCodeObject。==

> Python内建了一个函数叫做compile。可以将一些Python代码文本给进行手动的编译，返回很多PyCodeObject。
>
> Python还内置了一个模块叫做dis。调用`dis.dis(某个PyCodeObject)`可以返回相应对象的文本形式的字节码具体内容。
> 注意PyCodeObject本质上是内存中的对象，因此手动通过def关键字定义一个函数后也可以dis这个函数看相关字节码。

### 执行

最后，Code Evaluator组件开始工作，将按照CFG指示，存取PyCodeObject们，从而执行计算。
Code Evaluator也是狭义上的 Python 虚拟机（PVM）。

注意，计算完成之后，所有PyCodeObject都会被解释器保存成`.pyc`文件从而被持久化下来。

### pyc的生成与使用

上面说，PVM执行完程序后，会将字节码写入`.pyc`文件保存到磁盘上从而实现持久化。
但实际使用Python的过程中，你不一定能发现有`.pyc`文件生成。这是为什么？

显然，`.pyc`文件想要解决的，是Python代码复用的一个问题，如Java的`.class`文件一样。
而Python解释器默认只有某个`.py`文件是作为模块被引用时才有被复用的价值。
所以，==仅当某个`.py`文件作为模块在其他脚本中被`import`，其`.pyc`文件才会被保存在与之相同路径下面==。（更新的Python中会在同路径下建立一个`__pycache__`目录用来存放`.pyc`）

另一方面，当某个Python程序运行到了`import xxx`的时候，他会优先寻找相关位置的`.pyc`文件进行加载，因为那样可以省去编译阶段。
不过为了加载正确代码，还==需要保证当前的`xxx.pyc`确实和当前的`xxx.py`是对应的。这个问题通过在`pyc`中加入一个生成时间戳解决。也就是说，每次试图使用`.pyc`时，解释器都会检查相应的`.py`文件的最近更新时间。如果此时间晚于`.pyc`中保存的生成时间戳，那么说明上一次编译后源代码文件被修改，因此需要重新编译而不是使用`.pyc`了==。

### 对类与函数编译策略的差异

这是Python中一个有意思的小特点。
Python对函数的编译，一句话总结就是，只编译不执行，只有函数被调用才会被执行。因此诸如

```python
def f():
  return a + b
```

这样的函数，定义一下解释器并不会报错。因为它只是将f函数进行编译，而不会执行从而发现未定义a和b两个变量的值。
通过dis查看一下字节码就知道，解释器默认将a和b视作两个global的变量了。

对于类，Python在编译时则遵循，一编译就执行的策略。注意，这里的执行，指的是类本身命名空间内的内容，不涉及类方法内部。
所以会有：

```python
class Test:
    print('Namespace of Test Class')
    def method1():
        return a + b
```

上述代码并不会报错，反而还会输出`Namespace of Test Class`这一段。但若print语句换成`a + b`的话，那就要报错了。因为即使是定义Test类时，这句话也会被执行。

综上，根据这两个特点，就会导致这样一个现象：
==对于互相引用的函数，定义顺序无所谓，只要最终代码中定义了，即使是在文件尾部定义的函数，也可以被文件头部定义的函数引用。
但是对于互相引用的类，若类A想引用类B，那么B必须定义在A之前。==

### 其他文件

除了`.pyc`文件，Python中有时还会遇到`.pyo`，`.pyd`，`.pyw`等文件。

- `.pyo`

  这种文件本质上和`.pyc`是一样的，即Python虚拟机（或者叫解释器的Code Evaluator）可执行的字节码。但两者不同之处在于，`.pyo`是Python编译器优化编译得到的产物（整体文件大小更小）。具体来说，在运行入口脚本时若加上`-O`参数如`python -O xxx.py`，此时生成的字节码文件就不是`.pyc`而是`.pyo`了。

  （`.pyo`文件由于其优化力度并不太大但是又有很多缺点比如安全性，所以已经成为历史。）

- `.pyd`

  Windows上程序运行有时候会要动态链接库（DLL）作为支持。
  而将一个Python程序打包成DLL时就会生成`.pyd`文件。换言之，`.pyd`文件是作为DLL供其他Python程序使用的形式。

- `.pyw`

  在Windows上用Python解释器执行字节码文件如`.pyc`时，默认会有一个cmd窗口弹出。
  如果在做一些GUI程序，不希望有cmd出现时，可以使用`.pyw`，其会屏蔽所有stdout和stderr的输出。
  这种文件生成要借助一些GUI框架。

# 其他

## Python2和Python3的区别

这个问题一下子就能想到的两个答案

1. print从语句变成了函数
2. 定义字符串时从Python2中混乱的各种编码格式，统一成了Python3中的Unicode

除此之外还有呢？下面再来补充几个

3. 迭代器相关

   ```
   Python2中一些内建的函数比如range, map, zip, dict.keys(), dict.items()等都是直接返回列表的，而Python3中这些东西返回的是迭代器。显然迭代器更好一些。
   此外，Python2的迭代器要求类实现next方法，而在Python3中，方法名变成了__next__，即，将迭代方法定义为魔法方法了。
   ```

4. nonlocal关键字

   ```
   这点确实今天才知道。。
   nonlocal关键字用于函数内部的内函数中。内函数开头处，若用nonlocal修饰一个变量x，则表明这个x不取用内函数内部的局部定义域，而取用外部的变量值。
   另一个类似的，声明全局变量的global倒是2，3里都有。
   ```

5. True和False的根本

   ```
   这点也是今天才知道。Python2中的True和False，本质上是两个解释器范围的全局变量。既然是全局变量，如果在代码中对他们的值进行改变，那么整个代码中的True或者False的意义就会改变，这很不合理吧。
   所以Python3中，True和False正式称为两个关键字，代表bool类型的值。
   ```

6. 程序文件的默认编码

   ```
   依稀记得Python2的脚本中，如果你什么都不干而在注释中直接写中文，是会报错的。因为Python2默认程序本身的编码格式是ASCII。
   Python3中默认编码改成了UTF-8，所以可直接写中文了。
   默认编码格式用  sys.getdefaultencoding()  查看。
   ```

7. 格式化输出字符串的形式

   ```
   Python2中还是类似于 'Name: %s' % name
   Python3中则引入了format函数，更新的3.7还支持了f-string。
   ```

8. 整数除法

   ```
   Python2中，整数除法沿用了其他C系语言的做法，即 1/2=0
   而Python3中，自动会转浮点数，所以 1/2=0.5
   ```

有这么多条差不多够了吧。其他还有一些，就不写了。

## 实例方法、类方法、静态方法

- 实例方法就是指Python类中定义的最多的那种普通的方法，不多说了。

- 类方法
  通过给方法加上`@classmethod`装饰器进行类方法的定义。类方法要求至少有一个指向类的参数，通常取名为`cls`。
  由于带有类本身作为参数，类方法中可以通过`cls`这个参数访问一些归属于类的类属性。
  ==在定义完之后，外部既可以通过该类名调用类方法，也可以通过类的某个实例对象调用类方法。由于两者都带有类本身的信息，所以调用时无需显式指明`cls`参数的值。==
==显然，类方法和雷属性是同一个级别的概念，因此对类属性的操作应当尽量实现在类方法中==。
  

例子：

```python
  class Person:
      MAX_AGE = 100
      def __init__(self, name, age):
          self.name = name
          self.age = age
          
      @classmethod
      def getMaxAge(cls):
          return cls.MAX_AGE
  
  if __name__ == '__main__':
      p = Person('Frank', 25)
      p.MAX_AGE = 101
      print(p.getMaxAge())     # 100
      print(Person.getMaxAge())    # 100
      Person.MAX_AGE = 101
      print(p.getMaxAge())    # 101
      print(Person.getMaxAge())    # 101
```

两个方法都可以返回Person类的类属成员变量`MAX_AGE`的值。

- 静态方法
  静态方法用`@staticmethod`装饰器修饰得到。静态方法对参数没有任何事先的要求。
  和类方法类似的，静态方法也既可以通过类名调用，又可以通过实例调用。
  ==从使用方式的角度来说，和上面类方法如出一辙，只不过方法定义时不必强制加`cls`参数了。自然，如果想在方法内对类属性、类方法等调用时，就要直呼类名了。
  可以将静态方法看做普通函数，只不过这个函数定义在了类的命名空间中而不是程序整体的全局空间中。==

### 从类的继承看三种方法的区别

表面形式上的区别上面已经说过了。现在来探探本质性的区别。

首先，实例方法是最具体化的概念。在实例方法中，既可以通过`self`参数对其他实例方法调用，也可以对类方法发起调用，还可以通过类名对类方法、静态方法发起调用。
在类方法中，不能通过`cls`调用某实例方法（毕竟实例方法要求给出一个self实例对象而你给的是一个类对象），但却可以通过`cls`变量调用其他类方法和静态方法。
静态方法则最为僵硬，因为其没有任何特殊参数，所以如果想要调用类方法，就只能直呼类名来调用，可以说实现逻辑和类本身没有什么关系。

在有类继承关系，比如B类继承自A类，完了B类实例b去调用各种方法时（假定B未重载任何方法），可以发现：
实例方法中如果用到实例属性，自然是用`b`的实例属性。
类方法中，`cls`的意义是B类了，所以自然访问的类属性也会变成B的雷属性。
静态方法因为所有东西都写死了（直呼类名、实例名，没有`self, cls`之类的特殊变量），因此即使从`b`或者`B`调用，用的还是和A一样的一套逻辑。

## `__new__`和`__init__`的联系与区别

先来说一下两个方法定义的一些规矩。
`__init__`见得太多了，它的第一个参数必须是`self`，代表的是实例自己。剩余参数可以由程序员自己指定。另外`__init__`方法可以但没必要返回任何东西。
另一方面，==`__new__`方法的第一个参数必须是`cls`。这也意味着`__new__`方法其实是一个类方法（类方法也是静态方法的一种）而不是普通的实例方法==（当然这么解释有点本末倒置，因为`cls`只是一个参数名，但是惯例上，第一个参数是`cls`的那就是类方法啦）。==同时，`__new__`方法还必须返回一个对象==。至于这个对象是什么。下面会说。

总体而言，下面是一个`__new__`和`__init__`定义的例子：

```python
#!/usr/bin/env python
class Person:
    
    def __new__(cls, *args, **kwargs):
        return_obj = super(Person, cls).__new__(cls)
        return return_obj

    def __init__(self, name, age):
        self.name = name
        self.age = age

if __name__ == '__main__':
    p = Person('Frank', 21)
```

上述代码可以按照预期正确运行。当在主体代码中调用`Person`类试图创建一个示例，其步骤是这样的：

1. 在创建示例之前，调用`Person.__new__`方法。因为这是一个类方法，所以在创建示例前就可以调用了。根据上面要求，这个方法会返回一个对象。这里的代码返回的，是Person父类的new出来的实例对象。因为没有显式指定Person父类，所以其继承与基类object类。
2. ==`__new__`中返回的对象，会被赋值给`__init__`的`self`参数，将其作为此次创建Person类实例的返回==。`__init__`中可以对这个实例进行进一步的初始化如定义属性，给各个属性赋初值等。

正如两个方法的名字所暗示的那样，`__new__`才是真正的创建方法，而`__init__`是初始化方法。两者的区别主要在于：

|                | `__new__`                                                    | `__init__`                                    |
| -------------- | ------------------------------------------------------------ | --------------------------------------------- |
| 调用时机       | 在实例创建前                                                 | 在示例创建后，接受`__new__`返回的内容作为self |
| 方法性质       | 类方法                                                       | 示例方法                                      |
| 是否可以不定义 | 可以，若不定义`__new__`方法，则自动调用父类的该方法，也就是`super(Class, cls).__new__(cls)`就是上面代码中干的事。 | 一般类必须要有`__init__`                      |

### `__new__`到底有什么用

一直以来的开发都只用了`__init__`，那么为何还需要有个`__new__`呢？
==一些场景，比如想要实现单例模式的时候就可以用`__new__`。==

> 单例模式
>
> 通常一个类通过多次实例化可以获得多个不同的互相独立的实例。单例模式则是指多次实例化同一个类，得到的实例始终只有一个。这样，可以在不同的地方实例化同个类来访问同一个实例，实现数据的共享等功能。
>
> 更多单例模式的内容见设计模式篇。

```python
class Singleton:
	def __new__(cls):
		if not hasattr(cls, 'instance'):
      cls.instance = super(Singleton, cls).__new__(cls)
    return cls.instance

obj1 = Singleton()
obj2 = Singleton()
print(obj1 is obj2)
```

按照一般思路,`obj1`和`obj2`是两次实例化得到的实例，最后一行肯定输出False。但是实际上，`__new__`方法在实例生成前被运行，而这个方法内部，又将返回的实例对象每次都指向了类`Singleton`内部保存的instance属性（第一次因为还没有，所以会用`Singleton`的父类的`__new__`创建一个）。
这就导致，无论你调用多少次`Singleton()`尝试去示例化这个类，最终拿到的实例都是同一个。

## global与nonlocal

这两个关键字都有种“将外部的变量放到内部用”的意味。global在Python中历史久远了，而nonlocal是最近的python3新版本中才引入。

两者本质性的区别在于作用范围不同。如果将一个Python文件的作用域建模成一个树形结构，那么global关键字声明的变量，将位于树的节点，并且渗透到树所有的节点中去。
即，在任意一个作用域，只要使用global修饰一个变量，那么这个变量就是在最顶层作用域上被声明的那个。
示例：

```python
global xxx
def main():
  global xxx
  xxx = yyy
```

相对的，nonlocal特指函数内部嵌套函数的情况，将外层函数中定义的一些变量给带到内层中使用的关键字。
和global不同，在外层函数的变量定义时无需增加nonlocal关键字修饰。
示例：

```python
def main():
  xxx = yyy
  def inter():
    nonlocal xxx
    xxx = zzz
```

## 代码doc相关内建函数

这里主要提`help`，`dir`，`locals`，`globals`这几个内建函数。这些函数都是用来输出一些Python相关的说明文本的利器。有点像docstring的用法。

- help

  help函数接受一个函数/方法对象或者类对象作为参数。
  当输入是一个函数时如`help(func)`时，主要会输出该函数的定义，还有就是函数中被多行注释标识出的说明文字。
  当输入是一个类时，则会输出这个类的多行注释说明文字，以及其下属的各个方法、属性的说明。

- dir

  调用dir函数时可以带参数或者不带参数。
  不带参数时，其返回刀当前这行代码为止，其所处位置的命名空间内所有有效的对象名。包括各种变量、类、带双下划线的隐藏变量等等。相当于`locals().keys()`。
  带参数时参数通常是一个类或者函数之类的对象，返回的是该对象以及其所有父类对象的所有属性的名称，形成的列表。

- locals和globals

  返回改代码行所在命名空间内，所有相关变量的名称以及其值。
  相关变量是指作用域。`locals`返回的就是局部作用域内的所有变量。而`globals`返回的则是整个程序全局作用域下的变量（不包括locals的那一部分。即只看最高层作用域，不关心内部的子作用域）